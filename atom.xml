<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://daxinqqq.github.io</id>
    <title>逸空blog</title>
    <updated>2022-01-06T06:34:32.544Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://daxinqqq.github.io"/>
    <link rel="self" href="https://daxinqqq.github.io/atom.xml"/>
    <subtitle>三两老友七八老酒，十村踏遍一生还在</subtitle>
    <logo>https://daxinqqq.github.io/images/avatar.png</logo>
    <icon>https://daxinqqq.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, 逸空blog</rights>
    <entry>
        <title type="html"><![CDATA[java 中的锁 -- 偏向锁、轻量级锁、自旋锁、重量级锁]]></title>
        <id>https://daxinqqq.github.io/post/java-zhong-de-suo-pian-xiang-suo-qing-liang-ji-suo-zi-xuan-suo-chong-liang-ji-suo/</id>
        <link href="https://daxinqqq.github.io/post/java-zhong-de-suo-pian-xiang-suo-qing-liang-ji-suo-zi-xuan-suo-chong-liang-ji-suo/">
        </link>
        <updated>2022-01-06T06:29:11.000Z</updated>
        <content type="html"><![CDATA[<p>之前做过一个测试，详情见这篇文章《多线程 +1操作的几种实现方式，及效率对比》，当时对这个测试结果很疑惑，反复执行过多次，发现结果是一样的:</p>
<ol>
<li>
<p>单线程下synchronized效率最高（当时感觉它的效率应该是最差才对）；</p>
</li>
<li>
<p>AtomicInteger效率最不稳定，不同并发情况下表现不一样：短时间低并发下，效率比synchronized高，有时甚至比LongAdder还高出一点，但是高并发下，性能还不如synchronized，不同情况下性能表现很不稳定；</p>
</li>
<li>
<p>LongAdder性能稳定，在各种并发情况下表现都不错，整体表现最好,短时间的低并发下比AtomicInteger性能差一点，长时间高并发下性能最高（可以让AtomicInteger下台了）；</p>
</li>
</ol>
<p>这篇文章我们就去揭秘，为什么会是这个测试结果！</p>
<h2 id="理解锁的基础知识">理解锁的基础知识</h2>
<p>如果想要透彻的理解java锁的来龙去脉，需要先了解以下基础知识。</p>
<h3 id="基础知识之一锁的类型">基础知识之一：锁的类型</h3>
<p>锁从宏观上分类，分为悲观锁与乐观锁。</p>
<h4 id="乐观锁">乐观锁</h4>
<p>乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新），如果失败则要重复读-比较-写的操作。</p>
<p>java中的乐观锁基本都是通过CAS操作实现的，CAS是一种更新的原子操作，比较当前值跟传入值是否一样，一样则更新，否则失败。</p>
<h4 id="悲观锁">悲观锁</h4>
<p>悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会block直到拿到锁。java中的悲观锁就是Synchronized,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，才会转换为悲观锁，如RetreenLock。</p>
<h3 id="基础知识之二java线程阻塞的代价">基础知识之二：java线程阻塞的代价</h3>
<p>java的线程是映射到操作系统原生线程之上的，如果要阻塞或唤醒一个线程就需要操作系统介入，需要在户态与核心态之间切换，这种切换会消耗大量的系统资源，因为用户态与内核态都有各自专用的内存空间，专用的寄存器等，用户态切换至内核态需要传递给许多变量、参数给内核，内核也需要保护好用户态在切换时的一些寄存器值、变量等，以便内核态调用结束后切换回用户态继续工作。</p>
<ol>
<li>如果线程状态切换是一个高频操作时，这将会消耗很多CPU处理时间；</li>
<li>如果对于那些需要同步的简单的代码块，获取锁挂起操作消耗的时间比用户代码执行的时间还要长，这种同步策略显然非常糟糕的。</li>
</ol>
<p>synchronized会导致争用不到锁的线程进入阻塞状态，所以说它是java语言中一个重量级的同步操纵，被称为重量级锁，为了缓解上述性能问题，JVM从1.5开始，引入了轻量锁与偏向锁，默认启用了自旋锁，他们都属于乐观锁。</p>
<p><strong>明确java线程切换的代价，是理解java中各种锁的优缺点的基础之一。</strong></p>
<h3 id="基础知识之三markword">基础知识之三：markword</h3>
<p>在介绍java锁之前，先说下什么是markword，markword是java对象数据结构中的一部分，要详细了解java对象的结构可以点击这里,这里只做markword的详细介绍，因为对象的markword和java各种类型的锁密切相关；</p>
<p>markword数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，它的<strong>最后2bit是锁状态标志位</strong>，用来标记当前对象的状态，对象的所处的状态，决定了markword存储的内容，如下表所示:</p>
<table>
<thead>
<tr>
<th>状态</th>
<th>标志位</th>
<th>存储内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>未锁定</td>
<td>01</td>
<td>对象哈希码、对象分代年龄</td>
</tr>
<tr>
<td>轻量级锁定</td>
<td>00</td>
<td>指向锁记录的指针</td>
</tr>
<tr>
<td>膨胀(重量级锁定)</td>
<td>10</td>
<td>执行重量级锁定的指针</td>
</tr>
<tr>
<td>GC标记</td>
<td>11</td>
<td>空(不需要记录信息)</td>
</tr>
<tr>
<td>可偏向</td>
<td>01</td>
<td>偏向线程ID、偏向时间戳、对象分代年龄</td>
</tr>
</tbody>
</table>
<p>32位虚拟机在不同状态下markword结构如下图所示：</p>
<figure data-type="image" tabindex="1"><img src="https://daxinqqq.github.io/post-images/1641450675863.png" alt="" loading="lazy"></figure>
<p>了解了markword结构，有助于后面了解java锁的加锁解锁过程；</p>
<h3 id="小结">小结</h3>
<p>前面提到了java的4种锁，他们分别是重量级锁、自旋锁、轻量级锁和偏向锁，<br>
不同的锁有不同特点，每种锁只有在其特定的场景下，才会有出色的表现，java中没有哪种锁能够在所有情况下都能有出色的效率，引入这么多锁的原因就是为了应对不同的情况；</p>
<p>前面讲到了重量级锁是悲观锁的一种，自旋锁、轻量级锁与偏向锁属于乐观锁，所以现在你就能够大致理解了他们的适用范围，但是具体如何使用这几种锁呢，就要看后面的具体分析他们的特性；</p>
<h2 id="java中的锁">java中的锁</h2>
<h3 id="自旋锁">自旋锁</h3>
<p>自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就<strong>避免用户线程和内核的切换的消耗</strong>。</p>
<p>但是线程自旋是需要消耗cup的，说白了就是让cup在做无用功，如果一直获取不到锁，那线程也不能一直占用cup自旋做无用功，所以需要设定一个自旋等待的最大时间。</p>
<p>如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。</p>
<h4 id="自旋锁的优缺点">自旋锁的优缺点</h4>
<p>自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会导致线程发生两次上下文切换！</p>
<p>但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用cpu做无用功，占着XX不XX，同时有大量线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要cup的线程又不能获取到cpu，造成cpu的浪费。所以这种情况下我们要关闭自旋锁；</p>
<h4 id="自旋锁时间阈值">自旋锁时间阈值</h4>
<p>自旋锁的目的是为了占着CPU的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。因此自旋的周期选的额外重要！</p>
<p>JVM对于自旋周期的选择，jdk1.5这个限度是一定的写死的，在1.6引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间，同时JVM还针对当前CPU的负荷情况做了较多的优化</p>
<ol>
<li>如果平均负载小于CPUs则一直自旋</li>
<li>如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞</li>
<li>如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞</li>
<li>如果CPU处于节电模式则停止自旋</li>
<li>自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差）</li>
<li>自旋时会适当放弃线程优先级之间的差异</li>
</ol>
<h4 id="自旋锁的开启">自旋锁的开启</h4>
<p>JDK1.6中-XX:+UseSpinning开启；<br>
-XX:PreBlockSpin=10 为自旋次数；<br>
JDK1.7后，去掉此参数，由jvm控制；</p>
<h3 id="重量级锁synchronized">重量级锁Synchronized</h3>
<h4 id="synchronized的作用">Synchronized的作用</h4>
<p>在JDK1.5之前都是使用synchronized关键字保证同步的，Synchronized的作用相信大家都已经非常熟悉了；</p>
<p>它可以把任意一个非NULL的对象当作锁。</p>
<ol>
<li>作用于方法时，锁住的是对象的实例(this)；</li>
<li>当作用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久带PermGen（jdk1.8则是metaspace），永久带是全局共享的，因此静态方法锁相当于类的一个全局锁，会锁所有调用该方法的线程；</li>
<li>synchronized作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。</li>
</ol>
<h4 id="synchronized的实现">Synchronized的实现</h4>
<p>实现如下图所示；</p>
<figure data-type="image" tabindex="2"><img src="https://daxinqqq.github.io/post-images/1641450714393.png" alt="" loading="lazy"></figure>
<p>它有多个队列，当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中。</p>
<ol>
<li>Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中；</li>
<li>Entry List：Contention List中那些有资格成为候选资源的线程被移动到Entry List中；</li>
<li>Wait Set：哪些调用wait方法被阻塞的线程被放置在这里；</li>
<li>OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck；</li>
<li>Owner：当前已经获取到所资源的线程被称为Owner；</li>
<li>!Owner：当前释放锁的线程。</li>
</ol>
<p>JVM每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList会被大量的并发线程进行CAS访问，为了降低对尾部元素的竞争，JVM会将一部分线程移动到EntryList中作为候选竞争线程。Owner线程会在unlock时，将ContentionList中的部分线程迁移到EntryList中，并指定EntryList中的某个线程为OnDeck线程（一般是最先进去的那个线程）。Owner线程并不直接把锁传递给OnDeck线程，而是把锁竞争的权利交给OnDeck，OnDeck需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM中，也把这种选择行为称之为“竞争切换”。</p>
<p>OnDeck线程获取到锁资源后会变为Owner线程，而没有得到锁资源的仍然停留在EntryList中。如果Owner线程被wait方法阻塞，则转移到WaitSet队列中，直到某个时刻通过notify或者notifyAll唤醒，会重新进去EntryList中。</p>
<p>处于ContentionList、EntryList、WaitSet中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux内核下采用pthread_mutex_lock内核函数实现的）。</p>
<p><strong>Synchronized是非公平锁。</strong> Synchronized在线程进入ContentionList时，等待的线程会先尝试自旋获取锁，如果获取不到就进入ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占OnDeck线程的锁资源。</p>
<h3 id="偏向锁">偏向锁</h3>
<p>Java偏向锁(Biased Locking)是Java6引入的一项多线程优化。<br>
偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。<br>
如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。</p>
<blockquote>
<p><em>它通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。</em></p>
</blockquote>
<h4 id="偏向锁的实现">偏向锁的实现</h4>
<h5 id="偏向锁获取过程">偏向锁获取过程：</h5>
<ol>
<li>访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。</li>
<li>如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。</li>
<li>如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。</li>
<li>如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word）</li>
<li>执行同步代码。</li>
</ol>
<blockquote>
<p>注意：第四步中到达安全点safepoint会导致stop the word，时间很短。</p>
</blockquote>
<h5 id="偏向锁的释放">偏向锁的释放：</h5>
<p>偏向锁的撤销在上述第四步骤中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。</p>
<h4 id="偏向锁的适用场景">偏向锁的适用场景</h4>
<p>始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作；<br>
在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用；</p>
<h5 id="查看停顿安全点停顿日志">查看停顿–安全点停顿日志</h5>
<p>要查看安全点停顿，可以打开安全点日志，通过设置JVM参数 -XX:+PrintGCApplicationStoppedTime 会打出系统停止的时间，添加-XX:+PrintSafepointStatistics -XX:PrintSafepointStatisticsCount=1 这两个参数会打印出详细信息，可以查看到使用偏向锁导致的停顿，时间非常短暂，但是争用严重的情况下，停顿次数也会非常多；</p>
<p>注意：安全点日志不能一直打开：<br>
\1. 安全点日志默认输出到stdout，一是stdout日志的整洁性，二是stdout所重定向的文件如果不在/dev/shm，可能被锁。<br>
\2. 对于一些很短的停顿，比如取消偏向锁，打印的消耗比停顿本身还大。<br>
\3. 安全点日志是在安全点内打印的，本身加大了安全点的停顿时间。</p>
<p>所以安全日志应该只在问题排查时打开。<br>
如果在生产系统上要打开，再再增加下面四个参数：<br>
-XX:+UnlockDiagnosticVMOptions -XX: -DisplayVMOutput -XX:+LogVMOutput -XX:LogFile=/dev/shm/vm.log<br>
打开Diagnostic（只是开放了更多的flag可选，不会主动激活某个flag），关掉输出VM日志到stdout，输出到独立文件,/dev/shm目录（内存文件系统）。</p>
<figure data-type="image" tabindex="3"><img src="https://daxinqqq.github.io/post-images/1641450751660.png" alt="" loading="lazy"></figure>
<p>此日志分三部分：<br>
第一部分是时间戳，VM Operation的类型<br>
第二部分是线程概况，被中括号括起来<br>
total: 安全点里的总线程数<br>
initially_running: 安全点开始时正在运行状态的线程数<br>
wait_to_block: 在VM Operation开始前需要等待其暂停的线程数</p>
<p>第三部分是到达安全点时的各个阶段以及执行操作所花的时间，其中最重要的是vmop</p>
<ul>
<li>spin: 等待线程响应safepoint号召的时间；</li>
<li>block: 暂停所有线程所用的时间；</li>
<li>sync: 等于 spin+block，这是从开始到进入安全点所耗的时间，可用于判断进入安全点耗时；</li>
<li>cleanup: 清理所用时间；</li>
<li>vmop: 真正执行VM Operation的时间。</li>
</ul>
<p>可见，那些很多但又很短的安全点，全都是RevokeBias， 高并发的应用会禁用掉偏向锁。</p>
<h4 id="jvm开启关闭偏向锁">jvm开启/关闭偏向锁</h4>
<ul>
<li>开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0</li>
<li>关闭偏向锁：-XX:-UseBiasedLocking</li>
</ul>
<h3 id="轻量级锁">轻量级锁</h3>
<p>轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁；<br>
轻量级锁的加锁过程：</p>
<ol>
<li>
<p>在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。这时候线程堆栈与对象头的状态如图：</p>
<figure data-type="image" tabindex="4"><img src="https://daxinqqq.github.io/post-images/1641450775376.jpeg" alt="" loading="lazy"></figure>
</li>
<li>
<p>拷贝对象头中的Mark Word复制到锁记录中；</p>
</li>
<li>
<p>拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。如果更新成功，则执行步骤4，否则执行步骤5。</p>
</li>
<li>
<p>如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态，这时候线程堆栈与对象头的状态如图所示。</p>
<figure data-type="image" tabindex="5"><img src="https://daxinqqq.github.io/post-images/1641450798760.jpeg" alt="" loading="lazy"></figure>
</li>
<li>
<p>如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，轻量级锁就要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。 而当前线程便尝试使用自旋来获取锁，自旋就是为了不让线程阻塞，而采用循环去获取锁的过程。</p>
</li>
</ol>
<h4 id="轻量级锁的释放">轻量级锁的释放</h4>
<p><strong>释放锁线程视角</strong>：由轻量锁切换到重量锁，是发生在轻量锁释放锁的期间，之前在获取锁的时候它拷贝了锁对象头的markword，在释放锁的时候如果它发现在它持有锁的期间有其他线程来尝试获取锁了，并且该线程对markword做了修改，两者比对发现不一致，则切换到重量锁。</p>
<p>因为重量级锁被修改了，所有display mark word和原来的markword不一样了。</p>
<p>怎么补救，就是进入mutex前，compare一下obj的markword状态。确认该markword是否被其他线程持有。</p>
<p>此时如果线程已经释放了markword，那么通过CAS后就可以直接进入线程，无需进入mutex，就这个作用。</p>
<p><strong>尝试获取锁线程视角</strong>：如果线程尝试获取锁的时候，轻量锁正被其他线程占有，那么它就会修改markword，修改重量级锁，表示该进入重量锁了。</p>
<p>还有一个注意点：等待轻量锁的线程不会阻塞，它会一直自旋等待锁，并如上所说修改markword。</p>
<p>这就是自旋锁，尝试获取锁的线程，在没有获得锁的时候，不被挂起，而转而去执行一个空循环，即自旋。在若干个自旋后，如果还没有获得锁，则才被挂起，获得锁，则执行代码。</p>
<h2 id="总结">总结</h2>
<figure data-type="image" tabindex="6"><img src="https://daxinqqq.github.io/post-images/1641450824461.jpeg" alt="" loading="lazy"></figure>
<p>synchronized的执行过程：</p>
<ol>
<li>
<p>检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁</p>
</li>
<li>
<p>如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1</p>
</li>
<li>
<p>如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。</p>
</li>
<li>
<p>当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁</p>
</li>
<li>
<p>如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。</p>
</li>
<li>
<p>如果自旋成功则依然处于轻量级状态。</p>
</li>
<li>
<p>如果自旋失败，则升级为重量级锁。</p>
</li>
</ol>
<p>上面几种锁都是JVM自己内部实现，当我们执行synchronized同步块的时候jvm会根据启用的锁和当前线程的争用情况，决定如何执行同步操作；</p>
<p>在所有的锁都启用的情况下线程进入临界区时会先去获取偏向锁，如果已经存在偏向锁了，则会尝试获取轻量级锁，启用自旋锁，如果自旋也没有获取到锁，则使用重量级锁，没有获取到锁的线程阻塞挂起，直到持有锁的线程执行完同步块唤醒他们；</p>
<p>偏向锁是在无锁争用的情况下使用的，也就是同步开在当前线程没有执行完之前，没有其它线程会执行该同步块，一旦有了第二个线程的争用，偏向锁就会升级为轻量级锁，如果轻量级锁自旋到达阈值后，没有获取到锁，就会升级为重量级锁；</p>
<p>如果线程争用激烈，那么应该禁用偏向锁。</p>
<h1 id="锁优化">锁优化</h1>
<p>以上介绍的锁不是我们代码中能够控制的，但是借鉴上面的思想，我们可以优化我们自己线程的加锁操作；</p>
<h2 id="减少锁的时间">减少锁的时间</h2>
<p>不需要同步执行的代码，能不放在同步快里面执行就不要放在同步快内，可以让锁尽快释放；</p>
<h2 id="减少锁的粒度">减少锁的粒度</h2>
<p>**它的思想是将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。**它的思想也是用空间来换时间；</p>
<p>java中很多数据结构都是采用这种方法提高并发操作的效率：</p>
<h3 id="concurrenthashmap">ConcurrentHashMap</h3>
<p>java中的ConcurrentHashMap在jdk1.8之前的版本，使用一个Segment 数组</p>
<pre><code class="language-java">Segment&lt; K,V &gt;[] segments1
</code></pre>
<p>Segment继承自ReenTrantLock，所以每个Segment就是个可重入锁，每个Segment 有一个HashEntry&lt; K,V &gt;数组用来存放数据，put操作时，先确定往哪个Segment放数据，只需要锁定这个Segment，执行put，其它的Segment不会被锁定；所以数组中有多少个Segment就允许同一时刻多少个线程存放数据，这样增加了并发能力。</p>
<h3 id="longadder">LongAdder</h3>
<p>LongAdder 实现思路也类似ConcurrentHashMap，LongAdder有一个根据当前并发状况动态改变的Cell数组，Cell对象里面有一个long类型的value用来存储值;<br>
开始没有并发争用的时候或者是cells数组正在初始化的时候，会使用cas来将值累加到成员变量的base上，在并发争用的情况下，LongAdder会初始化cells数组，在Cell数组中选定一个Cell加锁，数组有多少个cell，就允许同时有多少线程进行修改，最后将数组中每个Cell中的value相加，在加上base的值，就是最终的值；cell数组还能根据当前线程争用情况进行扩容，初始长度为2，每次扩容会增长一倍，直到扩容到大于等于cpu数量就不再扩容，这也就是为什么LongAdder比cas和AtomicInteger效率要高的原因，后面两者都是volatile+cas实现的，他们的竞争维度是1，LongAdder的竞争维度为“Cell个数+1”为什么要+1？因为它还有一个base，如果竞争不到锁还会尝试将数值加到base上；</p>
<h3 id="linkedblockingqueue">LinkedBlockingQueue</h3>
<p>LinkedBlockingQueue也体现了这样的思想，在队列头入队，在队列尾出队，入队和出队使用不同的锁，相对于LinkedBlockingArray只有一个锁效率要高；</p>
<p>*<strong>拆锁的粒度不能无限拆，最多可以将一个锁拆为当前cup数量个锁即可；*</strong></p>
<h2 id="锁粗化">锁粗化</h2>
<p>大部分情况下我们是要让锁的粒度最小化，锁的粗化则是要增大锁的粒度;<br>
在以下场景下需要粗化锁的粒度：<br>
假如有一个循环，循环内的操作需要加锁，我们应该把锁放到循环外面，否则每次进出循环，都进出一次临界区，效率是非常差的；</p>
<h2 id="使用读写锁">使用读写锁</h2>
<p>ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可以并发读，写操作使用写锁，只能单线程写；</p>
<h2 id="读写分离">读写分离</h2>
<p>CopyOnWriteArrayList 、CopyOnWriteArraySet<br>
CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。<br>
　CopyOnWrite并发容器用于读多写少的并发场景，因为，读的时候没有锁，但是对其进行更改的时候是会加锁的，否则会导致多个线程同时复制出多个副本，各自修改各自的；</p>
<h2 id="使用cas">使用cas</h2>
<p>如果需要同步的操作执行速度非常快，并且线程竞争并不激烈，这时候使用cas效率会更高，因为加锁会导致线程的上下文切换，如果上下文切换的耗时比同步操作本身更耗时，且线程对资源的竞争不激烈，使用volatiled+cas操作会是非常高效的选择；</p>
<h2 id="消除缓存行的伪共享">消除缓存行的伪共享</h2>
<p>除了我们在代码中使用的同步锁和jvm自己内置的同步锁外，还有一种隐藏的锁就是缓存行，它也被称为性能杀手。<br>
在多核cup的处理器中，每个cup都有自己独占的一级缓存、二级缓存，甚至还有一个共享的三级缓存，为了提高性能，cpu读写数据是以缓存行为最小单元读写的；32位的cpu缓存行为32字节，64位cup的缓存行为64字节，这就导致了一些问题。<br>
例如，多个不需要同步的变量因为存储在连续的32字节或64字节里面，当需要其中的一个变量时，就将它们作为一个缓存行一起加载到某个cup-1私有的缓存中（虽然只需要一个变量，但是cpu读取会以缓存行为最小单位，将其相邻的变量一起读入），被读入cpu缓存的变量相当于是对主内存变量的一个拷贝，也相当于变相的将在同一个缓存行中的几个变量加了一把锁，这个缓存行中任何一个变量发生了变化，当cup-2需要读取这个缓存行时，就需要先将cup-1中被改变了的整个缓存行更新回主存（即使其它变量没有更改），然后cup-2才能够读取，而cup-2可能需要更改这个缓存行的变量与cpu-1已经更改的缓存行中的变量是不一样的，所以这相当于给几个毫不相关的变量加了一把同步锁；<br>
为了防止伪共享，不同jdk版本实现方式是不一样的：</p>
<ol>
<li>
<p>在jdk1.7之前会 将需要独占缓存行的变量前后添加一组long类型的变量，依靠这些无意义的数组的填充做到一个变量自己独占一个缓存行；</p>
</li>
<li>
<p>在jdk1.7因为jvm会将这些没有用到的变量优化掉，所以采用继承一个声明了好多long变量的类的方式来实现；</p>
</li>
<li>
<p>在jdk1.8中通过添加sun.misc.Contended注解来解决这个问题，若要使该注解有效必须在jvm中添加以下参数：<br>
-XX:-RestrictContended</p>
</li>
</ol>
<p>sun.misc.Contended注解会在变量<strong>前面</strong>添加<strong>128字节</strong>的padding将当前变量与其他变量进行隔离；<br>
关于什么是缓存行，jdk是如何避免缓存行的，网上有非常多的解释，在这里就不再深入讲解了；</p>
<p>其它方式等待着大家一起补充</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[一整套Java线上故障排查技巧]]></title>
        <id>https://daxinqqq.github.io/post/yi-zheng-tao-java-xian-shang-gu-zhang-pai-cha-ji-qiao/</id>
        <link href="https://daxinqqq.github.io/post/yi-zheng-tao-java-xian-shang-gu-zhang-pai-cha-ji-qiao/">
        </link>
        <updated>2022-01-04T08:33:30.000Z</updated>
        <content type="html"><![CDATA[<p><strong>线上故障主要会包括 CPU、磁盘、内存以及网络问题，而大多数故障可能会包含不止一个层面的问题，所以进行排查时候尽量四个方面依次排查一遍。</strong></p>
<p>同时例如 jstack、jmap 等工具也是不囿于一个方面的问题的，基本上出问题就是 df、free、top 三连，然后依次 jstack、jmap 伺候，具体问题具体分析即可。</p>
<h3 id="cpu">CPU</h3>
<p>一般来讲我们首先会排查 CPU 方面的问题。CPU 异常往往还是比较好定位的。原因包括业务逻辑问题(死循环)、频繁 GC 以及上下文切换过多。</p>
<p>而最常见的往往是业务逻辑(或者框架逻辑)导致的，可以使用 jstack 来分析对应的堆栈情况。</p>
<p><strong>①使用 jstack 分析 CPU 问题</strong></p>
<p>我们先用 ps 命令找到对应进程的 pid（如果你有好几个目标进程，可以先用 top 看一下哪个占用比较高）。</p>
<p>接着用top -H -p pid来找到 CPU 使用率比较高的一些线程：</p>
<figure data-type="image" tabindex="1"><img src="https://daxinqqq.github.io/post-images/1641288338395.png" alt="" loading="lazy"></figure>
<p>然后将占用最高的 pid 转换为 16 进制 printf '%x\n' pid 得到 nid：</p>
<figure data-type="image" tabindex="2"><img src="https://daxinqqq.github.io/post-images/1641288379259.png" alt="" loading="lazy"></figure>
<p>接着直接在 jstack 中找到相应的堆栈信息 jstack pid |grep 'nid' -C5 –color：</p>
<figure data-type="image" tabindex="3"><img src="https://daxinqqq.github.io/post-images/1641288405011.png" alt="" loading="lazy"></figure>
<p>可以看到我们已经找到了 nid 为 0x42 的堆栈信息，接着只要仔细分析一番即可。</p>
<p>当然更常见的是我们对整个 jstack 文件进行分析，通常我们会比较关注 WAITING 和 TIMED_WAITING 的部分，BLOCKED 就不用说了。</p>
<p>我们可以使用命令 cat jstack.log | grep &quot;java.lang.Thread.State&quot; | sort -nr | uniq -c 来对 jstack 的状态有一个整体的把握，如果 WAITING 之类的特别多，那么多半是有问题啦。</p>
<figure data-type="image" tabindex="4"><img src="https://daxinqqq.github.io/post-images/1641288447244.png" alt="" loading="lazy"></figure>
<p><strong>②频繁 GC</strong></p>
<p>当然我们还是会使用 jstack 来分析问题，但有时候我们可以先确定下 GC 是不是太频繁。</p>
<p>使用 jstat -gc pid 1000 命令来对 GC 分代变化情况进行观察，1000 表示采样间隔（ms），S0C/S1C、S0U/S1U、EC/EU、OC/OU、MC/MU 分别代表两个 Survivor 区、Eden 区、老年代、元数据区的容量和使用量。</p>
<p>YGC/YGT、FGC/FGCT、GCT 则代表 YoungGc、FullGc 的耗时和次数以及总耗时。</p>
<p>如果看到 GC 比较频繁，再针对 GC 方面做进一步分析，具体可以参考一下 GC章节的描述。</p>
<figure data-type="image" tabindex="5"><img src="https://daxinqqq.github.io/post-images/1641288507015.png" alt="" loading="lazy"></figure>
<p><strong>③上下文切换</strong></p>
<p>针对频繁上下文问题，我们可以使用 vmstat 命令来进行查看：</p>
<figure data-type="image" tabindex="6"><img src="https://daxinqqq.github.io/post-images/1641288529713.png" alt="" loading="lazy"></figure>
<p>cs（context switch）一列则代表了上下文切换的次数。如果我们希望对特定的 pid 进行监控那么可以使用 pidstat -w pid 命令，cswch 和 nvcswch 表示自愿及非自愿切换。</p>
<figure data-type="image" tabindex="7"><img src="https://daxinqqq.github.io/post-images/1641288582244.png" alt="" loading="lazy"></figure>
<h3 id="磁盘">磁盘</h3>
<p>磁盘问题和 CPU 一样是属于比较基础的。首先是磁盘空间方面，我们直接使用 df -hl 来查看文件系统状态：</p>
<figure data-type="image" tabindex="8"><img src="https://daxinqqq.github.io/post-images/1641288624060.png" alt="" loading="lazy"></figure>
<p>更多时候，磁盘问题还是性能上的问题。我们可以通过 iostat iostat -d -k -x 来进行分析：</p>
<figure data-type="image" tabindex="9"><img src="https://daxinqqq.github.io/post-images/1641288662211.png" alt="" loading="lazy"></figure>
<p>最后一列 %util 可以看到每块磁盘写入的程度，而 rrqpm/s 以及 wrqm/s 分别表示读写速度，一般就能帮助定位到具体哪块磁盘出现问题了。</p>
<p>另外我们还需要知道是哪个进程在进行读写，一般来说开发自己心里有数，或者用 iotop 命令来进行定位文件读写的来源。</p>
<figure data-type="image" tabindex="10"><img src="https://daxinqqq.github.io/post-images/1641288700829.png" alt="" loading="lazy"></figure>
<p>不过这边拿到的是 tid，我们要转换成 pid，可以通过 readlink 来找到 pidreadlink -f /proc/*/task/tid/../..。</p>
<figure data-type="image" tabindex="11"><img src="https://daxinqqq.github.io/post-images/1641288744880.png" alt="" loading="lazy"></figure>
<p>找到 pid 之后就可以看这个进程具体的读写情况 cat /proc/pid/io：</p>
<figure data-type="image" tabindex="12"><img src="https://daxinqqq.github.io/post-images/1641288783733.png" alt="" loading="lazy"></figure>
<p>我们还可以通过 lsof 命令来确定具体的文件读写情况 lsof -p pid：</p>
<figure data-type="image" tabindex="13"><img src="https://daxinqqq.github.io/post-images/1641288822982.png" alt="" loading="lazy"></figure>
<h3 id="内存">内存</h3>
<p>内存问题排查起来相对比 CPU 麻烦一些，场景也比较多。主要包括 OOM、GC 问题和堆外内存。</p>
<p>一般来讲，我们会先用 free 命令先来检查一发内存的各种情况：</p>
<figure data-type="image" tabindex="14"><img src="https://daxinqqq.github.io/post-images/1641288864352.png" alt="" loading="lazy"></figure>
<p><strong>堆内内存</strong></p>
<p>内存问题大多还都是堆内内存问题。表象上主要分为 OOM 和 Stack Overflow。</p>
<p><strong>①OOM</strong></p>
<p>JMV 中的内存不足，OOM 大致可以分为以下几种：</p>
<p><strong>Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: unable to create new native thread</strong></p>
<p>这个意思是没有足够的内存空间给线程分配 Java 栈，基本上还是线程池代码写的有问题，比如说忘记 shutdown，所以说应该首先从代码层面来寻找问题，使用 jstack 或者 jmap。</p>
<p>如果一切都正常，JVM 方面可以通过指定 Xss 来减少单个 thread stack 的大小。</p>
<p>另外也可以在系统层面，可以通过修改 /etc/security/limits.confnofile 和 nproc 来增大 os 对线程的限制。</p>
<figure data-type="image" tabindex="15"><img src="https://daxinqqq.github.io/post-images/1641289064759.png" alt="" loading="lazy"></figure>
<p><strong>Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space</strong></p>
<p>这个意思是堆的内存占用已经达到 -Xmx 设置的最大值，应该是最常见的的 OOM 错误了。</p>
<p>解决思路仍然是先应该在代码中找，怀疑存在内存泄漏，通过 jstack 和 jmap 去定位问题。如果说一切都正常，才需要通过调整 Xmx 的值来扩大内存。</p>
<p><strong>Caused by: java.lang.OutOfMemoryError: Meta space</strong></p>
<p>这个意思是元数据区的内存占用已经达到 XX:MaxMetaspaceSize 设置的最大值，排查思路和上面的一致，参数方面可以通过 XX:MaxPermSize 来进行调整（这里就不说 1.8 以前的永久代了）。</p>
<p><strong>②Stack Overflow</strong></p>
<p>栈内存溢出，这个大家见到也比较多。</p>
<p><strong>Exception in thread &quot;main&quot; java.lang.StackOverflowError</strong></p>
<p>表示线程栈需要的内存大于 Xss 值，同样也是先进行排查，参数方面通过Xss来调整，但调整的太大可能又会引起 OOM。</p>
<p><strong>③使用 JMAP 定位代码内存泄漏</strong></p>
<p>上述关于 OOM 和 Stack Overflow 的代码排查方面，我们一般使用 JMAP jmap -dump:format=b,file=filename pid 来导出 dump 文件：</p>
<figure data-type="image" tabindex="16"><img src="https://daxinqqq.github.io/post-images/1641289649992.png" alt="" loading="lazy"></figure>
<p>通过 mat（Eclipse Memory Analysis Tools）导入 dump 文件进行分析，内存泄漏问题一般我们直接选 Leak Suspects 即可，mat 给出了内存泄漏的建议。</p>
<p>另外也可以选择 Top Consumers 来查看最大对象报告。和线程相关的问题可以选择 thread overview 进行分析。</p>
<p>除此之外就是选择 Histogram 类概览来自己慢慢分析，大家可以搜搜 mat 的相关教程。</p>
<figure data-type="image" tabindex="17"><img src="https://daxinqqq.github.io/post-images/1641289695960.png" alt="" loading="lazy"></figure>
<p>日常开发中，代码产生内存泄漏是比较常见的事，并且比较隐蔽，需要开发者更加关注细节。</p>
<p>比如说每次请求都 new 对象，导致大量重复创建对象；进行文件流操作但未正确关闭；手动不当触发 GC；ByteBuffer 缓存分配不合理等都会造成代码 OOM。</p>
<p>另一方面，我们可以在启动参数中指定 -XX:+HeapDumpOnOutOfMemoryError 来保存 OOM 时的 dump 文件。</p>
<p><strong>④GC 问题和线程</strong></p>
<p>GC 问题除了影响 CPU 也会影响内存，排查思路也是一致的。一般先使用 jstat 来查看分代变化情况，比如 youngGC 或者 FullGC 次数是不是太多呀；EU、OU 等指标增长是不是异常呀等。</p>
<p>线程的话太多而且不被及时 GC 也会引发 OOM，大部分就是之前说的 unable to create new native thread。</p>
<p>除了 jstack 细细分析 dump 文件外，我们一般先会看下总体线程，通过 pstreee -p pid |wc -l。</p>
<figure data-type="image" tabindex="18"><img src="https://daxinqqq.github.io/post-images/1641289740445.png" alt="" loading="lazy"></figure>
<p>或者直接通过查看 /proc/pid/task 的数量即为线程数量。</p>
<figure data-type="image" tabindex="19"><img src="https://daxinqqq.github.io/post-images/1641289780280.png" alt="" loading="lazy"></figure>
<p><strong>堆外内存</strong></p>
<p>如果碰到堆外内存溢出，那可真是太不幸了。首先堆外内存溢出表现就是物理常驻内存增长快，报错的话视使用方式都不确定。</p>
<p>如果由于使用 Netty 导致的，那错误日志里可能会出现 OutOfDirectMemoryError 错误，如果直接是 DirectByteBuffer，那会报 OutOfMemoryError: Direct buffer memory。</p>
<p>堆外内存溢出往往是和 NIO 的使用相关，一般我们先通过 pmap 来查看下进程占用的内存情况 pmap -x pid | sort -rn -k3 | head -30，这段意思是查看对应 pid 倒序前 30 大的内存段。</p>
<p>这边可以再一段时间后再跑一次命令看看内存增长情况，或者和正常机器比较可疑的内存段在哪里。</p>
<figure data-type="image" tabindex="20"><img src="https://daxinqqq.github.io/post-images/1641289821014.png" alt="" loading="lazy"></figure>
<p>我们如果确定有可疑的内存端，需要通过 gdb 来分析 gdb --batch --pid {pid} -ex &quot;dump memory filename.dump {内存起始地址} {内存起始地址+内存块大小}&quot;。</p>
<figure data-type="image" tabindex="21"><img src="https://daxinqqq.github.io/post-images/1641289861916.png" alt="" loading="lazy"></figure>
<p>获取 dump 文件后可用 heaxdump 进行查看 hexdump -C filename | less，不过大多数看到的都是二进制乱码。</p>
<p>NMT 是 Java7U40 引入的 HotSpot 新特性，配合 jcmd 命令我们就可以看到具体内存组成了。</p>
<p>需要在启动参数中加入 -XX:NativeMemoryTracking=summary 或者 -XX:NativeMemoryTracking=detail，会有略微性能损耗。</p>
<p>一般对于堆外内存缓慢增长直到爆炸的情况来说，可以先设一个基线 jcmd pid VM.native_memory baseline。</p>
<figure data-type="image" tabindex="22"><img src="https://daxinqqq.github.io/post-images/1641289917384.png" alt="" loading="lazy"></figure>
<p>然后等放一段时间后再去看看内存增长的情况，通过 jcmd pid VM.native_memory detail.diff(summary.diff) 做一下 summary 或者 detail 级别的 diff。</p>
<figure data-type="image" tabindex="23"><img src="https://daxinqqq.github.io/post-images/1641289958069.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="24"><img src="https://daxinqqq.github.io/post-images/1641290000036.png" alt="" loading="lazy"></figure>
<p>可以看到 jcmd 分析出来的内存十分详细，包括堆内、线程以及 GC（所以上述其他内存异常其实都可以用 nmt 来分析），这边堆外内存我们重点关注 Internal 的内存增长，如果增长十分明显的话那就是有问题了。</p>
<p>detail 级别的话还会有具体内存段的增长情况，如下图：</p>
<figure data-type="image" tabindex="25"><img src="https://daxinqqq.github.io/post-images/1641290040155.png" alt="" loading="lazy"></figure>
<p>此外在系统层面，我们还可以使用 strace 命令来监控内存分配 strace -f -e &quot;brk,mmap,munmap&quot; -p pid。</p>
<p>这边内存分配信息主要包括了 pid 和内存地址：</p>
<figure data-type="image" tabindex="26"><img src="https://daxinqqq.github.io/post-images/1641290081032.jpeg" alt="" loading="lazy"></figure>
<p>不过其实上面那些操作也很难定位到具体的问题点，关键还是要看错误日志栈，找到可疑的对象，搞清楚它的回收机制，然后去分析对应的对象。</p>
<p>比如 DirectByteBuffer 分配内存的话，是需要 Full GC 或者手动 system.gc 来进行回收的（所以最好不要使用-XX:+DisableExplicitGC）。</p>
<p>那么其实我们可以跟踪一下 DirectByteBuffer 对象的内存情况，通过 jmap -histo:live pid 手动触发 Full GC 来看看堆外内存有没有被回收。</p>
<p>如果被回收了，那么大概率是堆外内存本身分配的太小了，通过 -XX:MaxDirectMemorySize 进行调整。</p>
<p>如果没有什么变化，那就要使用 jmap 去分析那些不能被 GC 的对象，以及和 DirectByteBuffer 之间的引用关系了。</p>
<h3 id="gc-问题">GC 问题</h3>
<p>堆内内存泄漏总是和 GC 异常相伴。不过 GC 问题不只是和内存问题相关，还有可能引起 CPU 负载、网络问题等系列并发症，只是相对来说和内存联系紧密些，所以我们在此单独总结一下 GC 相关问题。</p>
<p>我们在 CPU 章介绍了使用 jstat 来获取当前 GC 分代变化信息。</p>
<p>而更多时候，我们是通过 GC 日志来排查问题的，在启动参数中加上 -verbose:gc，-XX:+PrintGCDetails，-XX:+PrintGCDateStamps，-XX:+PrintGCTimeStamps 来开启 GC 日志。</p>
<p>常见的 Young GC、Full GC 日志含义在此就不做赘述了。针对 GC 日志，我们就能大致推断出 youngGC 与 Full GC 是否过于频繁或者耗时过长，从而对症下药。</p>
<p>我们下面将对 G1 垃圾收集器来做分析，这边也建议大家使用 G1-XX:+UseG1GC。</p>
<p><strong>①youngGC 过频繁</strong></p>
<p>youngGC 频繁一般是短周期小对象较多，先考虑是不是 Eden 区/新生代设置的太小了，看能否通过调整 -Xmn、-XX:SurvivorRatio 等参数设置来解决问题。</p>
<p>如果参数正常，但是 youngGC 频率还是太高，就需要使用 Jmap 和 MAT 对 dump 文件进行进一步排查了。</p>
<p><strong>②youngGC 耗时过长</strong></p>
<p>耗时过长问题就要看 GC 日志里耗时耗在哪一块了。以 G1 日志为例，可以关注 Root Scanning、Object Copy、Ref Proc 等阶段。</p>
<p>Ref Proc 耗时长，就要注意引用相关的对象。Root Scanning 耗时长，就要注意线程数、跨代引用。</p>
<p>Object Copy 则需要关注对象生存周期。而且耗时分析它需要横向比较，就是和其他项目或者正常时间段的耗时比较。</p>
<p>比如说图中的 Root Scanning 和正常时间段比增长较多，那就是起的线程太多了。</p>
<figure data-type="image" tabindex="27"><img src="https://daxinqqq.github.io/post-images/1641290136784.png" alt="" loading="lazy"></figure>
<p>③<strong>触发 Full GC</strong></p>
<p>G1 中更多的还是 mixedGC，但 mixedGC 可以和 youngGC 思路一样去排查。</p>
<p>触发 Full GC 了一般都会有问题，G1 会退化使用 Serial 收集器来完成垃圾的清理工作，暂停时长达到秒级别，可以说是半跪了。</p>
<p>FullGC 的原因可能包括以下这些，以及参数调整方面的一些思路：</p>
<ul>
<li>
<p><strong>并发阶段失败：</strong> 在并发标记阶段，MixGC 之前老年代就被填满了，那么这时候 G1 就会放弃标记周期。</p>
<p>这种情况，可能就需要增加堆大小，或者调整并发标记线程数 -XX:ConcGCThreads。</p>
</li>
<li>
<p><strong>晋升失败：</strong> 在 GC 的时候没有足够的内存供存活/晋升对象使用，所以触发了 Full GC。</p>
<p>这时候可以通过 -XX:G1ReservePercent 来增加预留内存百分比，减少 -XX:InitiatingHeapOccupancyPercent 来提前启动标记，-XX:ConcGCThreads 来增加标记线程数也是可以的。</p>
</li>
<li>
<p><strong>大对象分配失败：</strong> 大对象找不到合适的 Region 空间进行分配，就会进行 Full GC，这种情况下可以增大内存或者增大 -XX:G1HeapRegionSize。</p>
</li>
<li>
<p><strong>程序主动执行 System.gc()：</strong> 不要随便写就对了。</p>
</li>
</ul>
<p>另外，我们可以在启动参数中配置 -XX:HeapDumpPath=/xxx/dump.hprof 来 dump fullGC 相关的文件，并通过 jinfo 来进行 GC 前后的 dump：</p>
<pre><code>jinfo -flag +HeapDumpBeforeFullGC pid 
jinfo -flag +HeapDumpAfterFullGC pid
</code></pre>
<p>这样得到两份 dump 文件，对比后主要关注被 GC 掉的问题对象来定位问题。</p>
<h3 id="网络">网络</h3>
<p>涉及到网络层面的问题一般都比较复杂，场景多，定位难，成为了大多数开发的噩梦，应该是最复杂的了。</p>
<p>这里会举一些例子，并从 TCP 层、应用层以及工具的使用等方面进行阐述。</p>
<p><strong>①超时</strong></p>
<p>超时错误大部分处在应用层面，所以这块着重理解概念。超时大体可以分为连接超时和读写超时，某些使用连接池的客户端框架还会存在获取连接超时和空闲连接清理超时。</p>
<p><strong>读写超时：</strong> readTimeout/writeTimeout，有些框架叫做 so_timeout 或者 socketTimeout，均指的是数据读写超时。</p>
<p>注意这边的超时大部分是指逻辑上的超时。soa 的超时指的也是读超时。读写超时一般都只针对客户端设置。</p>
<p><strong>连接超时：</strong> connectionTimeout，客户端通常指与服务端建立连接的最大时间。</p>
<p>服务端这边 connectionTimeout 就有些五花八门了，Jetty 中表示空闲连接清理时间，Tomcat 则表示连接维持的最大时间。</p>
<p><strong>其他：</strong> 包括连接获取超时 connectionAcquireTimeout 和空闲连接清理超时 idleConnectionTimeout。多用于使用连接池或队列的客户端或服务端框架。</p>
<p>我们在设置各种超时时间中，需要确认的是尽量保持客户端的超时小于服务端的超时，以保证连接正常结束。</p>
<p>在实际开发中，我们关心最多的应该是接口的读写超时了。如何设置合理的接口超时是一个问题。</p>
<p>如果接口超时设置的过长，那么有可能会过多地占用服务端的 TCP 连接。而如果接口设置的过短，那么接口超时就会非常频繁。</p>
<p>服务端接口明明 RT 降低，但客户端仍然一直超时又是另一个问题。这个问题其实很简单，客户端到服务端的链路包括网络传输、排队以及服务处理等，每一个环节都可能是耗时的原因。</p>
<p><strong>②TCP 队列溢出</strong></p>
<p>TCP 队列溢出是个相对底层的错误，它可能会造成超时、RST 等更表层的错误。因此错误也更隐蔽，所以我们单独说一说。</p>
<figure data-type="image" tabindex="28"><img src="https://daxinqqq.github.io/post-images/1641290190768.jpeg" alt="" loading="lazy"></figure>
<p>如上图所示，这里有两个队列：</p>
<ul>
<li><strong>syns queue（半连接队列）</strong></li>
<li><strong>accept queue（全连接队列）</strong></li>
</ul>
<p>三次握手，在 server 收到 client 的 syn 后，把消息放到 syns queue，回复 syn+ack 给 client，server 收到 client 的 ack。</p>
<p>如果这时 accept queue 没满，那就从 syns queue 拿出暂存的信息放入 accept queue 中，否则按 tcp_abort_on_overflow 指示的执行。</p>
<p>tcp_abort_on_overflow 0 表示如果三次握手第三步的时候 accept queue 满了那么 server 扔掉 client 发过来的 ack。</p>
<p>tcp_abort_on_overflow 1 则表示第三步的时候如果全连接队列满了，server 发送一个 RST 包给 client，表示废掉这个握手过程和这个连接，意味着日志里可能会有很多 connection reset/connection reset by peer。</p>
<p>那么在实际开发中，我们怎么能快速定位到 TCP 队列溢出呢？</p>
<p>netstat 命令，执行 netstat -s | egrep &quot;listen|LISTEN&quot;：</p>
<figure data-type="image" tabindex="29"><img src="https://daxinqqq.github.io/post-images/1641290389359.jpeg" alt="" loading="lazy"></figure>
<p>如上图所示，overflowed 表示全连接队列溢出的次数，sockets dropped 表示半连接队列溢出的次数。</p>
<p>ss 命令，执行 ss -lnt：</p>
<figure data-type="image" tabindex="30"><img src="https://daxinqqq.github.io/post-images/1641290466177.jpeg" alt="" loading="lazy"></figure>
<p>上面看到 Send-Q 表示第三列的 Listen 端口上的全连接队列最大为 5，第一列 Recv-Q 为全连接队列当前使用了多少。</p>
<p><strong>接着我们看看怎么设置全连接、半连接队列大小吧：</strong> 全连接队列的大小取决于 min（backlog，somaxconn）。</p>
<p>Backlog 是在 Socket 创建的时候传入的，somaxconn 是一个 OS 级别的系统参数。而半连接队列的大小取决于 max（64, /proc/sys/net/ipv4/tcp_max_syn_backlog）。</p>
<p>在日常开发中，我们往往使用 Servlet 容器作为服务端，所以我们有时候也需要关注容器的连接队列大小。</p>
<p>在 Tomcat 中 backlog 叫做 acceptCount，在 Jetty 里面则是 acceptQueueSize。</p>
<p><strong>③RST 异常</strong></p>
<p>RST 包表示连接重置，用于关闭一些无用的连接，通常表示异常关闭，区别于四次挥手。</p>
<p>在实际开发中，我们往往会看到 connection reset/connection reset by peer 错误，这种情况就是 RST 包导致的。</p>
<p><strong>端口不存在：</strong> 如果像不存在的端口发出建立连接 SYN 请求，那么服务端发现自己并没有这个端口则会直接返回一个 RST 报文，用于中断连接。</p>
<p><strong>主动代替 FIN 终止连接：</strong> 一般来说，正常的连接关闭都是需要通过 FIN 报文实现，然而我们也可以用 RST 报文来代替 FIN，表示直接终止连接。</p>
<p>实际开发中，可设置 SO_LINGER 数值来控制，这种往往是故意的，来跳过 TIMED_WAIT，提供交互效率，不闲就慎用。</p>
<p><strong>客户端或服务端有一边发生了异常，该方向对端发送 RST 以告知关闭连接：</strong> 我们上面讲的 TCP 队列溢出发送 RST 包其实也是属于这一种。</p>
<p>这种往往是由于某些原因，一方无法再能正常处理请求连接了（比如程序崩了，队列满了），从而告知另一方关闭连接。</p>
<p><strong>接收到的 TCP 报文不在已知的 TCP 连接内：</strong> 比如，一方机器由于网络实在太差 TCP 报文失踪了，另一方关闭了该连接，然后过了许久收到了之前失踪的 TCP 报文，但由于对应的 TCP 连接已不存在，那么会直接发一个 RST 包以便开启新的连接。</p>
<p>一方长期未收到另一方的确认报文，在一定时间或重传次数后发出 RST 报文</p>
<p>这种大多也和网络环境相关了，网络环境差可能会导致更多的 RST 报文。</p>
<p>之前说过 RST 报文多会导致程序报错，在一个已关闭的连接上读操作会报 connection reset，而在一个已关闭的连接上写操作则会报 connection reset by peer。</p>
<p>通常我们可能还会看到 broken pipe 错误，这是管道层面的错误，表示对已关闭的管道进行读写，往往是在收到 RST，报出 connection reset 错后继续读写数据报的错，这个在 glibc 源码注释中也有介绍。</p>
<p>我们在排查故障时候怎么确定有 RST 包的存在呢？当然是使用 tcpdump 命令进行抓包，并使用 wireshark 进行简单分析了。</p>
<p>tcpdump -i en0 tcp -w xxx.cap，en0 表示监听的网卡：</p>
<figure data-type="image" tabindex="31"><img src="https://daxinqqq.github.io/post-images/1641290633798.jpeg" alt="" loading="lazy"></figure>
<p>接下来我们通过 wireshark 打开抓到的包，可能就能看到如下图所示，红色的就表示 RST 包了。</p>
<figure data-type="image" tabindex="32"><img src="https://daxinqqq.github.io/post-images/1641290661781.jpeg" alt="" loading="lazy"></figure>
<p><strong>④TIME_WAIT 和 CLOSE_WAIT</strong></p>
<p>TIME_WAIT 和 CLOSE_WAIT 是啥意思相信大家都知道。</p>
<p>在线上时，我们可以直接用命令 netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'来查看 time-wait 和 close_wait 的数量。</p>
<p>用 ss 命令会更快 ss -ant | awk '{++S[$1]} END {for(a in S) print a, S[a]}'：</p>
<figure data-type="image" tabindex="33"><img src="https://daxinqqq.github.io/post-images/1641290690851.png" alt="" loading="lazy"></figure>
<p><strong>TIME_WAIT：</strong>  time_wait 的存在一是为了丢失的数据包被后面连接复用，二是为了在 2MSL 的时间范围内正常关闭连接。</p>
<p>它的存在其实会大大减少 RST 包的出现。过多的 time_wait 在短连接频繁的场景比较容易出现。</p>
<p>这种情况可以在服务端做一些内核参数调优：</p>
<pre><code>#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭
net.ipv4.tcp_tw_reuse = 1
#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭
net.ipv4.tcp_tw_recycle = 1
</code></pre>
<p>当然我们不要忘记在 NAT 环境下因为时间戳错乱导致数据包被拒绝的坑了，另外的办法就是改小 tcp_max_tw_buckets，超过这个数的 time_wait 都会被干掉，不过这也会导致报 time wait bucket table overflow 的错。</p>
<p><strong>CLOSE_WAIT：</strong> close_wait 往往都是因为应用程序写的有问题，没有在 ACK 后再次发起 FIN 报文。</p>
<p>close_wait 出现的概率甚至比 time_wait 要更高，后果也更严重。往往是由于某个地方阻塞住了，没有正常关闭连接，从而渐渐地消耗完所有的线程。</p>
<p>想要定位这类问题，最好是通过 jstack 来分析线程堆栈来排查问题，具体可参考上述章节。这里仅举一个例子。</p>
<p>开发同学说应用上线后 CLOSE_WAIT 就一直增多，直到挂掉为止，jstack 后找到比较可疑的堆栈是大部分线程都卡在了 countdownlatch.await 方法。</p>
<p>找开发同学了解后得知使用了多线程但是确没有 catch 异常，修改后发现异常仅仅是最简单的升级 SDK 后常出现的 class not found。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[对比Java标准NIO库，Netty如何实现更高性能？]]></title>
        <id>https://daxinqqq.github.io/post/dui-bi-java-biao-zhun-nio-ku-netty-ru-he-shi-xian-geng-gao-xing-neng/</id>
        <link href="https://daxinqqq.github.io/post/dui-bi-java-biao-zhun-nio-ku-netty-ru-he-shi-xian-geng-gao-xing-neng/">
        </link>
        <updated>2021-03-12T09:43:57.000Z</updated>
        <content type="html"><![CDATA[<p>从性能角度，Netty在基础的NIO等类库上进行了很多改进：</p>
<ul>
<li>更优雅的Reactor模式实现、灵活的线程模型、利用EventLoop等创新性的机制可以非常高效的管理成百上千的Channel。</li>
<li>充分利用了Java的Zero-Copy机制，并且从多角度降低内存分配和回收的开销。例如，使用池化的Direct Buffer等技术，提高IO性能的同时，减少了对象的创建和销毁；利用反射等技术直接操纵SelectionKey，使用数组而非Java容器等。</li>
<li>使用更多本地代码。例如，直接利用JNI调用OPEN SSL等方式，获得比Java内建SSL引擎更好的性能。</li>
<li>在通信协议，序列化等其他角度的优化。</li>
</ul>
<p>总结，Netty并没有Java核心类库那些强烈的通用性、跨平台等各种负担，针对性能等特定目标和Linux等特定环境，采取了一些极致的优化手段。</p>
<h2 id="扩展">扩展：</h2>
<h3 id="netty">Netty:</h3>
<p>​	Netty是一个异步的，基于事件Client/Server的网络框架，目标是提供一种简单、快速构建网络应用的方式，同时保证高吞吐量、低延时、高可靠性。</p>
<h3 id="与java-nio框架对比">与Java NIO框架对比：</h3>
<p>​	Java的标准类库，由于其基础性、通用性的定位，往往更关注于技术模型上的抽象，而不是从一线开发者角度思考。Java NIO的设计也是，开发者需要深入掌握线程、IO、网络等相关概念，学习、开发成本大。</p>
<p>​	Netty通过精巧设计的事件机制，将业务逻辑与无关技术逻辑进行隔离，并通过抽象，一定程度的填补了基础平台和业务开发的鸿沟，更有利于最佳实践的普及。</p>
<p>除了核心的事件机制，Netty还提供了其他的功能：</p>
<ul>
<li>从网络协议的角度，Netty除了支持传输层的UDP、TCP、SCTP协议，也支持HTTP(S)、WebSocket等多种应用层协议，并不是单一协议的API。</li>
<li>在应用中，需要将数据从Java对象转换成各种应用的数据格式，或者进行反向转换，Netty提供了一系列扩展的编解码框架，与应用场景无缝衔接，并且性能良好。</li>
<li>它扩展了Java NIO Buffer，提供了自己的ByteBuf实现，并且深度支持Direct Buffer等技术，甚至hack了Java内部对Direct Buffer的分配和销毁等。同时，Netty也提供了更加完善的Scatter/Gather机制实现。</li>
</ul>
<p>可以看到，Netty的能力范围大大超过了Java核心类库中的NIO等API，可以说是一个从应用视角出发的产物。</p>
<h3 id="netty入门代码浅析">Netty入门代码浅析：</h3>
<figure data-type="image" tabindex="1"><img src="https://daxinqqq.github.io/post-images/1615542476300.png" alt="" loading="lazy"></figure>
<ul>
<li><strong>ServerBootstrap</strong>：服务器端程序的入口，这是Netty为简化网络程序配置和关闭等生命周期管理，所引入的Bootstrapping机制。通常我们要做的创建Channel、绑定端口、注册Handler等，都可以通过这个统一的入口，以Fluent API等形式完成，简化了API使用。与之对应，Bootstrap则是客户端的入口。</li>
<li><strong>Channel</strong>：作为一个基于NIO的扩展框架，Channel和Selector等概念仍然是Netty的基础组件，但是针对应用开发需求，提供了相对易用的抽象。</li>
<li><strong>EventLoop</strong>：这是Netty处理事件的核心机制。例子使用了EventLoopGroup。在NIO中通常要做的几件事，如注册感兴趣的事件，调度相应的Handler等，都是EventLoop负责。</li>
<li><strong>ChannelFuture</strong>：这是Netty实现异步IO的基础之一，保证了同一个Channel操作的调用顺序。Netty扩展了Java标准的Future，提供了针对自己场景特有的Future定义。</li>
<li><strong>ChannelHandler</strong>：这是应用开发者<strong>放置业务逻辑的主要地方</strong>。</li>
<li><strong>ChannelPipeline</strong>：它是ChannelHandler链条的容器，每个Channel创建后，自动被分配到一个ChannelPipeline。在上面的代码中，通过ServerBootstrap注册了ChannelInitializer，并且实现了initChannel方法，在该方法中承担了向ChannelPipeline安装其他Channel的任务。</li>
</ul>
<p><strong>可以参考下图，忽略InBound/OutBound Handler的细节，理解这几个基本单元的操作流程和对应关系：</strong><br>
<img src="https://daxinqqq.github.io/post-images/1615542389163.png" alt="" loading="lazy"></p>
<p>对比Java标准NIO的代码，Netty提供了相对高层次的封装，减少了对Selector等细节的操作，而EventLoop、Pipeline等机制简化了编程模型，开发者不用担心并发等问题，一定程度上简化了应用代码的开发。并且这一切并没有以可靠性、可扩展性为代价，反而将其大幅度提高。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MySQL数据库设计开发规范]]></title>
        <id>https://daxinqqq.github.io/post/mysql-shu-ju-ku-she-ji-kai-fa-gui-fan/</id>
        <link href="https://daxinqqq.github.io/post/mysql-shu-ju-ku-she-ji-kai-fa-gui-fan/">
        </link>
        <updated>2021-03-11T10:45:07.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1-规范背景与目的"><strong>1. 规范背景与目的</strong></h2>
<p>MySQL数据库与 Oracle、 SQL Server 等数据库相比，有其内核上的优势与劣势。我们在使用MySQL数据库的时候需要遵循一定规范，扬长避短。本规范旨在帮助或指导RD、QA、OP等技术人员做出适合线上业务的数据库设计。在数据库变更和处理流程、数据库表设计、SQL编写等方面予以规范，从而为公司业务系统稳定、健康地运行提供保障。</p>
<h2 id="2-设计规范"><strong>2. 设计规范</strong></h2>
<h3 id="21-数据库设计"><strong>2.1 数据库设计</strong></h3>
<p>以下所有规范会按照【高危】、【强制】、【建议】三个级别进行标注，遵守优先级从高到低。<br>
对于不满足【高危】和【强制】两个级别的设计，DBA会强制打回要求修改。</p>
<h3 id="211-库名"><strong>2.1.1 库名</strong></h3>
<ol>
<li>【强制】库的名称必须控制在32个字符以内，相关模块的表名与表名之间尽量提现join的关系，如user表和user_login表。</li>
<li>【强制】库的名称格式：业务系统名称_子系统名，同一模块使用的表名尽量使用统一前缀。</li>
<li>【强制】一般分库名称命名格式是库通配名_编号，编号从0开始递增，比如db_goods _001以时间进行分库的名称格式是&quot;库通配名_时间&quot;</li>
<li>【强制】创建数据库时必须显式指定字符集，并且字符集只能是utf8或者utf8mb4。创建数据库SQL举例：create database db1 default character set utf8;。</li>
</ol>
<h3 id="212-表结构"><strong>2.1.2 表结构</strong></h3>
<ol>
<li>【强制】表和列的名称必须控制在32个字符以内，表名只能使用字母、数字和下划线，一律小写。</li>
<li>【强制】表名要求模块名强相关，如师资系统采用&quot;sz&quot;作为前缀，渠道系统采用&quot;qd&quot;作为前缀等。</li>
<li>【强制】创建表时必须显式指定字符集为utf8或utf8mb4。</li>
<li>【强制】创建表时必须显式指定表存储引擎类型，如无特殊需求，一律为InnoDB。当需要使用除InnoDB/MyISAM/Memory以外的存储引擎时，必须通过DBA审核才能在生产环境中使用。因为Innodb表支持事务、行锁、宕机恢复、MVCC等关系型数据库重要特性，为业界使用最多的MySQL存储引擎。而这是其他大多数存储引擎不具备的，因此首推InnoDB。</li>
<li>【强制】建表必须有comment</li>
<li>【建议】建表时关于主键：(1)强制要求主键为id，类型为int或bigint，且为auto_increment(2)，建议设为其他字段如user_id，order_id建立unique key索引。因为如果设为主键且主键值为随机插入，则会导致innodb内部page分裂和大量随机I/O，性能下降。</li>
<li>【强制】核心表（如用户表，金钱相关的表）必须有行数据的创建时间字段create_time和最后更新时间字段update_time，便于查问题。</li>
<li>【建议】表中所有字段必须都是NOT NULL属性，业务可以根据需要定义DEFAULT值。因为使用NULL值会存在每一行都会占用额外存储空间、数据迁移容易出错、聚合函数计算结果偏差等问题。</li>
<li>【建议】建议对表里的blob、text等大字段，垂直拆分到其他表里，仅在需要读这些对象的时候才去select。</li>
<li>【建议】反范式设计：把经常需要join查询的字段，在其他表里冗余一份。如user_name属性在user_account，user_login_log等表里冗余一份，减少join查询。</li>
<li>【强制】中间表用于保留中间结果集，名称必须以tmp_开头。备份表用于备份或抓取源表快照，名称必须以bak_开头。中间表和备份表定期清理。</li>
<li>【强制】对于超过100W行的大表进行alter table，必须经过DBA审核，并在业务低峰期执行。因为alter table会产生表锁，期间阻塞对于该表的所有写入，对于业务可能会产生极大影响。</li>
</ol>
<h3 id="213-列数据类型优化"><strong>2.1.3 列数据类型优化</strong></h3>
<ol>
<li>【建议】表中的自增列（auto_increment属性），推荐使用bigint类型。因为无符号int存储范围为-2147483648~2147483647（大约21亿左右），溢出后会导致报错。</li>
<li>【建议】业务中选择性很少的状态status、类型type等字段推荐使用tinytint或者smallint类型节省存储空间。</li>
<li>【建议】业务中IP地址字段推荐使用int类型，不推荐用char(15)。因为int只占4字节，可以用如下函数相互转换，而char(15)占用至少15字节。一旦表数据行数到了1亿，那么要多用1.1G存储空间。 SQL：select inet_aton('192.168.2.12'); select inet_ntoa(3232236044); PHP: ip2long('192.168.2.12'); long2ip(3530427185);</li>
<li>【建议】不推荐使用enum，set。 因为它们浪费空间，且枚举值写死了，变更不方便。推荐使用tinyint或smallint。</li>
<li>【建议】不推荐使用blob，text等类型。它们都比较浪费硬盘和内存空间。在加载表数据时，会读取大字段到内存里从而浪费内存空间，影响系统性能。建议和PM、RD沟通，是否真的需要这么大字段。Innodb中当一行记录超过8098字节时，会将该记录中选取最长的一个字段将其768字节放在原始page里，该字段余下内容放在overflow-page里。不幸的是在compact行格式下，原始page和overflow-page都会加载。</li>
<li>【强制】存储金钱的字段，强制使用decimal类型。</li>
<li>【建议】文本数据尽量用varchar存储。因为varchar是变长存储，比char更省空间。MySQL server层规定一行所有文本最多存65535字节，因此在utf8字符集下最多存21844个字符，超过会自动转换为mediumtext字段。而text在utf8字符集下最多存21844个字符，mediumtext最多存2<sup>24/3个字符，longtext最多存2</sup>32个字符。一般建议用varchar类型，字符数不要超过2700。</li>
<li>【建议】时间类型尽量选取timestamp。因为datetime占用8字节，timestamp仅占用4字节，但是范围为1970-01-01 00:00:01到2038-01-01 00:00:00。更为高阶的方法，选用int来存储时间，使用SQL函数unix_timestamp()和from_unixtime()来进行转换。</li>
</ol>
<p>详细存储大小参加下图：<br>
<img src="https://cf.jd.com/download/attachments/222235418/worddav383b50cba105e8be3ca04216dba26386.png?version=1&amp;modificationDate=1571024595000&amp;api=v2" alt="img" loading="lazy"></p>
<h3 id="214-索引设计"><strong>2.1.4 索引设计</strong></h3>
<ol>
<li>【强制】InnoDB表必须主键为id int/bigint auto_increment,且主键值禁止被更新。</li>
<li>【建议】主键的名称以&quot;pk_&quot;开头，唯一键以&quot;uk_&quot;或&quot;uq_&quot;开头，普通索引以&quot;idx_&quot;开头，一律使用小写格式，以表名/字段的名称或缩写作为后缀。</li>
<li>【强制】InnoDB和MyISAM存储引擎表，索引类型必须为BTREE；MEMORY表可以根据需要选择HASH或者BTREE类型索引。</li>
<li>【强制】单个索引中每个索引记录的长度不能超过64KB。</li>
<li>【建议】单个表上的索引个数不能超过7个。</li>
<li>【建议】在建立索引时，多考虑建立联合索引，并把区分度最高的字段放在最前面。如列userid的区分度可由select count(distinct userid)计算出来。</li>
<li>【建议】在多表join的SQL里，保证被驱动表的连接列上有索引，这样join执行效率最高。</li>
<li>【建议】建表或加索引时，保证表里互相不存在冗余索引。对于MySQL来说，如果表里已经存在key(a,b)，则key(a)为冗余索引，需要删除。</li>
</ol>
<h3 id="215-分库分表-分区表"><strong>2.1.5 分库分表、分区表</strong></h3>
<ol>
<li>【强制】分区表的分区字段（partition-key）必须有索引，或者是组合索引的首列。</li>
<li>【强制】单个分区表中的分区（包括子分区）个数不能超过1024。</li>
<li>【强制】上线前RD或者DBA必须指定分区表的创建、清理策略。</li>
<li>【强制】访问分区表的SQL必须包含分区键。</li>
<li>【建议】单个分区文件不超过2G，总大小不超过50G。建议总分区数不超过20个。</li>
<li>【强制】对于分区表执行alter table操作，必须在业务低峰期执行。</li>
<li>【强制】采用分库策略的，库的数量不能超过1024</li>
<li>【强制】采用分表策略的，表的数量不能超过4096</li>
<li>【建议】单个分表不超过500W行，ibd文件大小不超过2G，这样才能让数据分布式变得性能更佳。</li>
<li>【建议】水平分表尽量用取模方式，日志、报表类数据建议采用日期进行分表。</li>
</ol>
<h3 id="216-字符集"><strong>2.1.6 字符集</strong></h3>
<ol>
<li>【强制】数据库本身库、表、列所有字符集必须保持一致，为utf8或utf8mb4。</li>
<li>【强制】前端程序字符集或者环境变量中的字符集，与数据库、表的字符集必须一致，统一为utf8。</li>
</ol>
<h3 id="217-程序层dao设计建议"><strong>2.1.7 程序层DAO设计建议</strong></h3>
<ol>
<li>【建议】新的代码不要用model，推荐使用手动拼SQL+绑定变量传入参数的方式。因为model虽然可以使用面向对象的方式操作db，但是其使用不当很容易造成生成的SQL非常复杂，且model层自己做的强制类型转换性能较差，最终导致数据库性能下降。</li>
<li>【建议】前端程序连接MySQL或者redis，必须要有连接超时和失败重连机制，且失败重试必须有间隔时间。</li>
<li>【建议】前端程序报错里尽量能够提示MySQL或redis原生态的报错信息，便于排查错误。</li>
<li>【建议】对于有连接池的前端程序，必须根据业务需要配置初始、最小、最大连接数，超时时间以及连接回收机制，否则会耗尽数据库连接资源，造成线上事故。</li>
<li>【建议】对于log或history类型的表，随时间增长容易越来越大，因此上线前RD或者DBA必须建立表数据清理或归档方案。</li>
<li>【建议】在应用程序设计阶段，RD必须考虑并规避数据库中主从延迟对于业务的影响。尽量避免从库短时延迟（20秒以内）对业务造成影响，建议强制一致性的读开启事务走主库，或更新后过一段时间再去读从库。</li>
<li>【建议】多个并发业务逻辑访问同一块数据（innodb表）时，会在数据库端产生行锁甚至表锁导致并发下降，因此建议更新类SQL尽量基于主键去更新。</li>
<li>【建议】业务逻辑之间加锁顺序尽量保持一致，否则会导致死锁。</li>
<li>【建议】对于单表读写比大于10:1的数据行或单个列，可以将热点数据放在缓存里（如mecache或redis），加快访问速度，降低MySQL压力。</li>
</ol>
<h3 id="218-一个规范的建表语句示例"><strong>2.1.8 一个规范的建表语句示例</strong></h3>
<p>一个较为规范的建表语句为：<br>
CREATE TABLE tt_test_user_1225_bk (<br>
<code>id</code> bigint(11) NOT NULL AUTO_INCREMENT COMMENT '主键id',<br>
<code>user_id</code> bigint(11) NOT NULL COMMENT '用户id',<br>
<code>username</code> varchar(45) NOT NULL COMMENT '真实姓名',<br>
<code>email</code> varchar(30) NOT NULL COMMENT '用户邮箱',<br>
<code>nickname</code> varchar(45) NOT NULL COMMENT '昵称',<br>
<code>avatar</code> int(11) NOT NULL COMMENT '头像',<br>
<code>birthday</code> date NOT NULL COMMENT '生日',<br>
<code>sex</code> tinyint(4) DEFAULT '0' COMMENT '性别',<br>
<code>short_introduce</code> varchar(150) DEFAULT NULL COMMENT '一句话介绍自己，最多50个汉字',<br>
<code>user_resume</code> varchar(300) NOT NULL COMMENT '用户提交的简历存放地址',<br>
<code>user_register_ip</code> int NOT NULL COMMENT '用户注册时的源ip',<br>
<code>create_time</code> timestamp NULL DEFAULT CURRENT_TIMESTAMP COMMENT '用户记录创建的时间',<br>
<code>update_time</code> timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '用户资料修改的时间',<br>
<code>user_review_status</code> tinyint NOT NULL COMMENT '用户资料审核状态，1为通过，2为审核中，3为未通过，4为还未提交审核',<br>
PRIMARY KEY (<code>id</code>),<br>
UNIQUE KEY <code>uq_idx_user_id</code> (<code>user_id</code>),<br>
KEY <code>idx_username</code>(<code>username</code>),<br>
KEY <code>idx_create_time</code>(<code>create_time</code>,<code>user_review_status</code>)<br>
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='网站用户基本信息';</p>
<h2 id="22-sql编写"><strong>2.2 SQL编写</strong></h2>
<h3 id="221-dml语句"><strong>2.2.1 DML语句</strong></h3>
<ol>
<li>【强制】SELECT语句必须指定具体字段名称，禁止写成*。因为select *会将不该读的数据也从MySQL里读出来，造成网卡压力。且表字段一旦更新，但model层没有来得及更新的话，系统会报错。</li>
<li>【强制】insert语句指定具体字段名称，不要写成insert into t1 values(…)，道理同上。</li>
<li>【建议】insert into…values(XX),(XX),(XX)…。这里XX的值不要超过5000个。值过多虽然上线很很快，但会引起主从同步延迟。</li>
<li>【建议】SELECT语句不要使用UNION，推荐使用UNION ALL，并且UNION子句个数限制在5个以内。因为union all不需要去重，节省数据库资源，提高性能。</li>
<li>【建议】in值列表限制在500以内。例如select… where userid in(….500个以内…)，这么做是为了减少底层扫描，减轻数据库压力从而加速查询。</li>
<li>【建议】事务里批量更新数据需要控制数量，进行必要的sleep，做到少量多次。</li>
<li>【强制】事务涉及的表必须全部是innodb表。否则一旦失败不会全部回滚，且易造成主从库同步中断。</li>
<li>【强制】写入和事务发往主库，只读SQL发往从库。</li>
<li>【强制】除静态表或小表（100行以内），DML语句必须有where条件，且使用索引查找。</li>
<li>【强制】生产环境禁止使用hint，如sql_no_cache，force index，ignore key，straight join等。因为hint是用来强制SQL按照某个执行计划来执行，但随着数据量变化我们无法保证自己当初的预判是正确的，因此我们要相信MySQL优化器！</li>
<li>【强制】where条件里等号左右字段类型必须一致，否则无法利用索引。</li>
<li>【建议】SELECT|UPDATE|DELETE|REPLACE要有WHERE子句，且WHERE子句的条件必需使用索引查找。</li>
<li>【强制】生产数据库中强烈不推荐大表上发生全表扫描，但对于100行以下的静态表可以全表扫描。查询数据量不要超过表行数的25%，否则不会利用索引。</li>
<li>【强制】WHERE 子句中禁止只使用全模糊的LIKE条件进行查找，必须有其他等值或范围查询条件，否则无法利用索引。</li>
<li>【建议】索引列不要使用函数或表达式，否则无法利用索引。如where length(name)='Admin'或where user_id+2=10023。</li>
<li>【建议】减少使用or语句，可将or语句优化为union，然后在各个where条件上建立索引。如where a=1 or b=2优化为where a=1… union …where b=2, key(a),key(b)(a和b为非主键列)。</li>
<li>【建议】分页查询，当limit起点较高时，可先用过滤条件进行过滤。如select a,b,c from t1 limit 10000,20;优化为: select a,b,c from t1 where id&gt;10000 limit 20;。</li>
</ol>
<h3 id="222-多表连接"><strong>2.2.2 多表连接</strong></h3>
<ol>
<li>【强制】禁止跨db的join语句。因为这样可以减少模块间耦合，为数据库拆分奠定坚实基础。</li>
<li>【强制】禁止在业务的更新类SQL语句中使用join，比如update t1 join t2…。</li>
<li>【建议】不建议使用子查询，建议将子查询SQL拆开结合程序多次查询，或使用join来代替子查询。</li>
<li>【强制】线上环境，禁止多表join。</li>
<li>【建议】多表连接查询推荐使用别名，且SELECT列表中要用别名引用字段，数据库.表格式，如select a from db1.table1 alias1 where …。</li>
<li>【建议】在多表join中，尽量选取结果集较小的表作为驱动表，来join其他表。</li>
</ol>
<h3 id="223-事务"><strong>2.2.3 事务</strong></h3>
<ol>
<li>【建议】事务中INSERT|UPDATE|DELETE|REPLACE语句操作的行数控制在2000以内，以及WHERE子句中IN列表的传参个数控制在500以内。</li>
<li>【建议】批量操作数据时，需要控制事务处理间隔时间，进行必要的sleep，一般建议值5-10秒。</li>
<li>【建议】对于有auto_increment属性字段的表的插入操作，并发需要控制在200以内。</li>
<li>【强制】程序设计必须考虑&quot;数据库事务隔离级别&quot;带来的影响，包括脏读、不可重复读和幻读。线上建议事务隔离级别为repeatable-read。</li>
<li>【建议】事务里包含SQL不超过5个（支付业务除外）。因为过长的事务会导致锁数据较久，MySQL内部缓存、连接消耗过多等雪崩问题。</li>
<li>【建议】事务里更新语句尽量基于主键或unique key，如update … where id=XX; 否则会产生 间隙锁，内部扩大锁定范围，导致系统性能下降，产生死锁。</li>
<li>【建议】尽量把一些典型外部调用移出事务，如调用webservice，访问文件存储等，从而避免事务过长。</li>
<li>【建议】对于MySQL主从延迟严格敏感的select语句，请开启事务强制访问主库。</li>
</ol>
<h3 id="224-排序和分组"><strong>2.2.4 排序和分组</strong></h3>
<ol>
<li>【建议】减少使用order by，和业务沟通能不排序就不排序，或将排序放到程序端去做。order by、group by、distinct这些语句较为耗费CPU，数据库的CPU资源是极其宝贵的。</li>
<li>【建议】order by、group by、distinct这些SQL尽量利用索引直接检索出排序好的数据。如where a=1 order by可以利用key(a,b)。</li>
<li>【建议】包含了order by、group by、distinct这些查询的语句，where条件过滤出来的结果集请保持在1000行以内，否则SQL会很慢。</li>
</ol>
<h3 id="225-线上禁止使用的sql语句"><strong>2.2.5 线上禁止使用的SQL语句</strong></h3>
<ol>
<li>【高危】禁用update|delete t1 … where a=XX limit XX; 这种带limit的更新语句。因为会导致主从不一致，导致数据错乱。建议加上order by PK。</li>
<li>【高危】禁止使用关联子查询，如update t1 set … where name in(select name from user where…);效率极其低下。</li>
<li>【强制】禁用procedure、function、trigger、views、event、外键约束。因为他们消耗数据库资源，降低数据库实例可扩展性。推荐都在程序端实现。</li>
<li>【强制】禁用insert into …on duplicate key update…在高并发环境下，会造成主从不一致。</li>
<li>【强制】禁止联表更新语句，如update t1,t2 where t1.id=t2.id…。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[常用的分布式ID设计方案]]></title>
        <id>https://daxinqqq.github.io/post/chang-yong-de-fen-bu-shi-id-she-ji-fang-an/</id>
        <link href="https://daxinqqq.github.io/post/chang-yong-de-fen-bu-shi-id-she-ji-fang-an/">
        </link>
        <updated>2021-03-11T10:10:16.000Z</updated>
        <content type="html"><![CDATA[<h2 id="分布式id定义">分布式ID定义：</h2>
<ul>
<li>全局唯一，区别于单点系统的唯一，全局要求分布式系统内唯一。</li>
<li>有序性，通常需要保证生成的ID是有序递增的。例如，数据库存储等场景中，有序ID便于确定数据位置，往往更加高效。</li>
</ul>
<h2 id="典型方案">典型方案：</h2>
<ul>
<li>
<p>基于数据库自增序列实现。好处是简单易用，但在扩展性和可靠性等方面存在局限。</p>
</li>
<li>
<p>基于Twitter早期开源的Snowflake的实现，以及相关改动方案。其结构定义：整体长度通常为64（1+41+10+12=64）位，适合使用long类型存储。</p>
<ul>
<li>
<p>头部是1位的正负标识位。</p>
</li>
<li>
<p>紧跟的高位标识是41位时间戳，通常使用System.currentTimeMillis()。</p>
</li>
<li>
<p>后面是10位的workerID，标准定义是5位数据中心+5位机器ID组成了机器编号，以区分不同的机器节点。</p>
</li>
<li>
<p>最后的12位就是单位毫秒内可生成的序列号的数目的理论极限。</p>
</li>
</ul>
</li>
<li>
<p>Redis、Zookeeper、MongoDB等中间件，也都有各种唯一ID解决方案。其中一些设计也可以算作是Snowflake方案的变种。例如，MongoDB的ObjectId提供了一个12 byte（96位）的ID定义，其中32位用于记录以秒为单位的事件，机器ID则为24位，16位用作进程ID，24位随机起始的计数序列。</p>
</li>
<li>
<p>国内大厂开源的一些分布式ID实现。</p>
</li>
</ul>
<p><strong>注：Snowflake并不受冬令时切换影响。Snowflake算法的Java实现，大都是依赖于System.currentTimeMillis()，这个函数会返回当前时间和1970年1月1号UTC事件相差的毫秒数，这个数值与夏/冬令时并没有关系。</strong></p>
<h2 id="扩展">扩展：</h2>
<h3 id="除了唯一和有序分布式系统通常还会额外希望分布式id保证">除了唯一和有序，分布式系统通常还会额外希望分布式ID保证：</h3>
<ul>
<li>有意义，包含更多信息，例如时间、业务等信息。这点和有序性存在一定关联，如果ID中包含时间，本身就可以保证一定的顺序。ID中包含额外信息，在分布式数据存储等场合中，有助于进一步优化数据访问的效率。</li>
<li>高可用性，这是分布式系统的必然要求，上面的方案中，有的是真正意义的分布式，有的还是传统主从的思路，这一点取决于我们业务对扩展性和性能等方面的要求。</li>
<li>紧凑性，ID的大小可能受到实际应用的制约，例如数据库存储往往对长ID不友好，太长的ID会降低Mysql等数据库索引的性能；编程语言在处理时也可能受数据类型长度限制。</li>
</ul>
<p>在具体生产环境中，还有可能提出对QPS等方面的具体要求，尤其是在国内一线大厂的业务规模下，更是需要考虑峰值业务场景的数量级层次要求。</p>
<h3 id="主流方案优缺点分析">主流方案优缺点分析：</h3>
<p>​	对于数据库自增方案，除了实现简单，它生成的ID还能够保证固定步长的递增，使用很方便。</p>
<p>​	但是，每获取一个ID就会触发数据库的写请求，是一个代价高昂的操作，构建高扩展性、高性能解决方案比较复杂，更不要说扩容等场景的难度了。同时，保证数据库高可用性也存在挑战，数据库可能发生宕机，即使采取主从热备等措施，也可能出现ID重复等问题。</p>
<p>​	实际大厂往往构建了多层的复合架构，例如美团公开的数据库方案Leaf-Segment，引入了起到缓存等作用的Leaf层，对数据库操作则是通过数据库中间件提供的批量操作，这样既能保证性能、扩展性，也能保证高可用。但是，这种方案对基础架构层面的要求很多，未必适合普通业务规模的需求。</p>
<p>​	与其相比，Snowflake的好处是算法简单，依赖也很少，生成的序列可预测，性能也非常好，Twetter的峰值超过10w/s。但是，它也存在一些不足：</p>
<ul>
<li>
<p>时钟偏斜问题（Clock Skew）：普通的计算机系统时钟并不能保证长久的一致性，可能发生时钟回拨等问题，这就会导致时间戳不准确，进而产生重复ID。针对这一点，Twetter曾经在文档中建议开启NTP。个人建议可以考虑同时将stepback设置为0，以禁止回调。从设计编码角度考虑，可以缓存历史时间戳，然后在序列生成之前进行校验，针对不合理情况进行重试、等待或报错。</p>
</li>
<li>
<p>序列号的可预测性是把双刃剑，虽然简化了一些工程问题，但很多场景不适合可预测的ID。很容易被黑客猜测并利用。</p>
</li>
<li>
<p>ID设计阶段需要谨慎考虑暴露出的信息。例如，Erlang版本的flake实现基于MAC地址计算WorkerID，在安全敏感的领域往往是不被允许的。</p>
</li>
<li>
<p>从理论上说，类似Snowflake的方案由于时间数据位数的限制，存在与2038年问题相似的理论极限。</p>
</li>
</ul>
]]></content>
    </entry>
</feed>