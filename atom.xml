<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://daxinqqq.github.io</id>
    <title>藏拙</title>
    <updated>2022-01-27T10:55:12.458Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://daxinqqq.github.io"/>
    <link rel="self" href="https://daxinqqq.github.io/atom.xml"/>
    <subtitle>三两老友七八老酒，十村踏遍一生还在</subtitle>
    <logo>https://daxinqqq.github.io/images/avatar.png</logo>
    <icon>https://daxinqqq.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, 藏拙</rights>
    <entry>
        <title type="html"><![CDATA[红黑树之原理详解]]></title>
        <id>https://daxinqqq.github.io/post/hong-hei-shu-zhi-yuan-li-xiang-jie/</id>
        <link href="https://daxinqqq.github.io/post/hong-hei-shu-zhi-yuan-li-xiang-jie/">
        </link>
        <updated>2022-01-27T09:43:57.000Z</updated>
        <content type="html"><![CDATA[<h3 id="r-b-tree简介"><strong>R-B Tree简介</strong></h3>
<p>R-B Tree，全称是Red-Black Tree，又称为“红黑树”，它一种特殊的二叉查找树。红黑树的每个节点上都有存储位表示节点的颜色，可以是红(Red)或黑(Black)。</p>
<p><strong>红黑树的特性</strong>:<br>
<strong>（1）每个节点或者是黑色，或者是红色。</strong><br>
<strong>（2）根节点是黑色。</strong><br>
<strong>（3）每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]</strong><br>
<strong>（4）如果一个节点是红色的，则它的子节点必须是黑色的。</strong><br>
<strong>（5）从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。</strong></p>
<p><strong>注意</strong>：<br>
(01) 特性(3)中的叶子节点，是只为空(NIL或null)的节点。<br>
(02) 特性(5)，确保没有一条路径会比其他路径长出俩倍。因而，红黑树是相对是接近平衡的二叉树。</p>
<p>红黑树示意图如下：</p>
<figure data-type="image" tabindex="1"><img src="https://daxinqqq.github.io/post-images/1643276746713.jpeg" alt="" loading="lazy"></figure>
<h3 id="红黑树的应用"><strong>红黑树的应用</strong></h3>
<p>红黑树的应用比较广泛，主要是用它来存储有序的数据，它的时间复杂度是O(lgn)，效率非常之高。<br>
例如，Java集合中的TreeSet和TreeMap，C++ STL中的set、map，以及Linux虚拟内存的管理，都是通过红黑树去实现的。</p>
<h3 id="红黑树的时间复杂度和相关证明"><strong>红黑树的时间复杂度和相关证明</strong></h3>
<p><strong>红黑树的时间复杂度为: O(lgn)</strong><br>
下面通过“<em>数学归纳法</em>”对红黑树的时间复杂度进行证明。</p>
<p>定理：<strong>一棵含有n个节点的红黑树的高度至多为2log(n+1)</strong>.</p>
<p>证明：<br>
&quot;一棵含有n个节点的红黑树的高度至多为2log(n+1)&quot; 的<strong>逆否命题</strong>是 &quot;高度为h的红黑树，它的包含的内节点个数至少为 2h/2-1个&quot;。<br>
我们只需要证明逆否命题，即可证明原命题为真；即只需证明 &quot;高度为h的红黑树，它的包含的内节点个数至少为 2h/2-1个&quot;。</p>
<p>从某个节点x出发（不包括该节点）到达一个叶节点的任意一条路径上，黑色节点的个数称为该节点的黑高度(x's black height)，记为<strong>bh(x)</strong>。关于bh(x)有两点需要说明：<br>
第1点：根据红黑树的&quot;<strong>特性(5)</strong> ，即<em>从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点</em>&quot;可知，从节点x出发到达的所有的叶节点具有相同数目的黑节点。<strong>这也就意味着，bh(x)的值是唯一的</strong>！<br>
第2点：根据红黑色的&quot;特性(4)，即<em>如果一个节点是红色的，则它的子节点必须是黑色的</em>&quot;可知，从节点x出发达到叶节点&quot;所经历的黑节点数目&quot;&gt;= &quot;所经历的红节点的数目&quot;。假设x是根节点，则可以得出结论&quot;<strong>bh(x) &gt;= h/2</strong>&quot;。进而，我们只需证明 &quot;高度为h的红黑树，它的包含的黑节点个数至少为 2bh(x)-1个&quot;即可。</p>
<p>到这里，我们将需要证明的定理已经由<br>
<strong>&quot;一棵含有n个节点的红黑树的高度至多为2log(n+1)&quot;</strong><br>
转变成只需要证明<br>
<strong>&quot;高度为h的红黑树，它的包含的内节点个数至少为 2bh(x)-1个&quot;。</strong></p>
<p>下面通过&quot;数学归纳法&quot;开始论证高度为h的红黑树，它的包含的内节点个数至少为 2bh(x)-1个&quot;。</p>
<p>(01) 当树的高度h=0时，<br>
内节点个数是0，bh(x) 为0，2bh(x)-1 也为 0。显然，原命题成立。</p>
<p>(02) 当h&gt;0，且树的高度为 h-1 时，它包含的节点个数至少为 2bh(x)-1-1。这个是根据(01)推断出来的！</p>
<p>下面，由树的高度为 h-1 的已知条件推出“树的高度为 h 时，它所包含的节点树为 2bh(x)-1”。</p>
<p>当树的高度为 h 时，<br>
对于节点x(x为根节点)，其黑高度为bh(x)。<br>
对于节点x的左右子树，它们黑高度为 bh(x) 或者 bh(x)-1。<br>
根据(02)的已知条件，我们已知 &quot;x的左右子树，即高度为 h-1 的节点，它包含的节点至少为 2bh(x)-1-1 个&quot;；</p>
<p>所以，节点x所包含的节点至少为 ( 2bh(x)-1-1 ) + ( 2bh(x)-1-1 ) + 1 = 2^bh(x)-1。即节点x所包含的节点至少为 2bh(x)-1。<br>
因此，原命题成立。</p>
<p>由(01)、(02)得出，&quot;高度为h的红黑树，它的包含的内节点个数至少为 2^bh(x)-1个&quot;。<br>
因此，“一棵含有n个节点的红黑树的高度至多为2log(n+1)”。</p>
<h3 id="红黑树的基本操作一-左旋和右旋"><strong>红黑树的基本操作(一) 左旋和右旋</strong></h3>
<p>红黑树的基本操作是<strong>添加</strong>、<strong>删除</strong>。在对红黑树进行添加或删除之后，都会用到旋转方法。为什么呢？道理很简单，添加或删除红黑树中的节点之后，红黑树就发生了变化，可能不满足红黑树的5条性质，也就不再是一颗红黑树了，而是一颗普通的树。而通过旋转，可以使这颗树重新成为红黑树。简单点说，旋转的目的是让树保持红黑树的特性。<br>
旋转包括两种：<strong>左旋</strong> 和 <strong>右旋</strong>。下面分别对它们进行介绍。</p>
<p><strong>1. 左旋</strong></p>
<figure data-type="image" tabindex="2"><img src="https://daxinqqq.github.io/post-images/1643276804679.jpeg" alt="" loading="lazy"></figure>
<p>对x进行左旋，意味着&quot;将x变成一个左节点&quot;。</p>
<p>左旋的伪代码《算法导论》：参考上面的示意图和下面的伪代码，理解“红黑树T的节点x进行左旋”是如何进行的。</p>
<pre><code class="language-swift">LEFT-ROTATE(T, x)  
 y ← right[x]            // 前提：这里假设x的右孩子为y。下面开始正式操作
 right[x] ← left[y]      // 将 “y的左孩子” 设为 “x的右孩子”，即 将β设为x的右孩子
 p[left[y]] ← x          // 将 “x” 设为 “y的左孩子的父亲”，即 将β的父亲设为x
 p[y] ← p[x]             // 将 “x的父亲” 设为 “y的父亲”
 if p[x] = nil[T]       
 then root[T] ← y                 // 情况1：如果 “x的父亲” 是空节点，则将y设为根节点
 else if x = left[p[x]]  
           then left[p[x]] ← y    // 情况2：如果 x是它父节点的左孩子，则将y设为“x的父节点的左孩子”
           else right[p[x]] ← y   // 情况3：(x是它父节点的右孩子) 将y设为“x的父节点的右孩子”
 left[y] ← x             // 将 “x” 设为 “y的左孩子”
 p[x] ← y                // 将 “x的父节点” 设为 “y”
</code></pre>
<p>理解左旋之后，看看下面一个更鲜明的例子。你可以先不看右边的结果，自己尝试一下。</p>
<figure data-type="image" tabindex="3"><img src="https://daxinqqq.github.io/post-images/1643276839446.jpeg" alt="" loading="lazy"></figure>
<p><strong>2. 右旋</strong></p>
<figure data-type="image" tabindex="4"><img src="https://daxinqqq.github.io/post-images/1643276862581.jpeg" alt="" loading="lazy"></figure>
<p>对x进行左旋，意味着&quot;将x变成一个左节点&quot;。</p>
<p>右旋的伪代码《算法导论》：参考上面的示意图和下面的伪代码，理解“红黑树T的节点y进行右旋”是如何进行的。</p>
<pre><code class="language-swift">RIGHT-ROTATE(T, y)  
 x ← left[y]             // 前提：这里假设y的左孩子为x。下面开始正式操作
 left[y] ← right[x]      // 将 “x的右孩子” 设为 “y的左孩子”，即 将β设为y的左孩子
 p[right[x]] ← y         // 将 “y” 设为 “x的右孩子的父亲”，即 将β的父亲设为y
 p[x] ← p[y]             // 将 “y的父亲” 设为 “x的父亲”
 if p[y] = nil[T]       
 then root[T] ← x                 // 情况1：如果 “y的父亲” 是空节点，则将x设为根节点
 else if y = right[p[y]]  
           then right[p[y]] ← x   // 情况2：如果 y是它父节点的右孩子，则将x设为“y的父节点的左孩子”
           else left[p[y]] ← x    // 情况3：(y是它父节点的左孩子) 将x设为“y的父节点的左孩子”
 right[x] ← y            // 将 “y” 设为 “x的右孩子”
 p[y] ← x                // 将 “y的父节点” 设为 “x”
</code></pre>
<p>理解右旋之后，看看下面一个更鲜明的例子。你可以先不看右边的结果，自己尝试一下。</p>
<figure data-type="image" tabindex="5"><img src="https://daxinqqq.github.io/post-images/1643276965802.jpeg" alt="" loading="lazy"></figure>
<p><strong>旋转总结</strong>：</p>
<p>(01) 左旋 和 右旋 是相对的两个概念，原理类似。理解一个也就理解了另一个。</p>
<p>(02) 下面谈谈如何区分 左旋 和 右旋。<br>
在实际应用中，若没有彻底理解 左旋 和 右旋，可能会将它们混淆。下面谈谈我对如何区分 左旋 和 右旋 的理解。</p>
<p><strong>3. 区分 左旋 和 右旋</strong></p>
<p>仔细观察上面&quot;左旋&quot;和&quot;右旋&quot;的示意图。我们能清晰的发现，它们是对称的。无论是左旋还是右旋，被旋转的树，在旋转前是二叉查找树，并且旋转之后仍然是一颗二叉查找树。</p>
<figure data-type="image" tabindex="6"><img src="https://daxinqqq.github.io/post-images/1643276973434.jpeg" alt="" loading="lazy"></figure>
<p><strong>左旋示例图</strong>(以x为节点进行左旋)：</p>
<pre><code class="language-rust">                               z
   x                          /                  
  / \      --(左旋)--&gt;       x
 y   z                      /
                           y
</code></pre>
<p>对x进行左旋，意味着，将“x的右孩子”设为“x的父亲节点”；即，将 x变成了一个左节点(x成了为z的左孩子)！。 因此，<strong>左旋中的“左”，意味着“被旋转的节点将变成一个左节点”</strong>。</p>
<p><strong>右旋示例图</strong>(以x为节点进行右旋)：</p>
<pre><code class="language-rust">                              y
   x                           \                 
  / \      --(右旋)--&gt;           x
 y   z                            \
                                   z
</code></pre>
<p>对x进行右旋，意味着，将“x的左孩子”设为“x的父亲节点”；即，将 x变成了一个右节点(x成了为y的右孩子)！ 因此，<strong>右旋中的“右”，意味着“被旋转的节点将变成一个右节点”</strong>。</p>
<h3 id="红黑树的基本操作二-添加"><strong>红黑树的基本操作(二) 添加</strong></h3>
<p>将一个节点插入到红黑树中，需要执行哪些步骤呢？首先，将红黑树当作一颗二叉查找树，将节点插入；然后，将节点着色为红色；最后，通过旋转和重新着色等方法来修正该树，使之重新成为一颗红黑树。详细描述如下：</p>
<p><strong>第一步: 将红黑树当作一颗二叉查找树，将节点插入。</strong><br>
红黑树本身就是一颗二叉查找树，将节点插入后，该树仍然是一颗二叉查找树。也就意味着，树的键值仍然是有序的。此外，无论是左旋还是右旋，若旋转之前这棵树是二叉查找树，旋转之后它一定还是二叉查找树。这也就意味着，任何的旋转和重新着色操作，都不会改变它仍然是一颗二叉查找树的事实。<br>
好吧？那接下来，我们就来想方设法的旋转以及重新着色，使这颗树重新成为红黑树！</p>
<p><strong>第二步：将插入的节点着色为&quot;红色&quot;。</strong><br>
为什么着色成红色，而不是黑色呢？为什么呢？在回答之前，我们需要重新温习一下红黑树的特性：<br>
(1) 每个节点或者是黑色，或者是红色。<br>
(2) 根节点是黑色。<br>
(3) 每个叶子节点是黑色。 [注意：这里叶子节点，是指为空的叶子节点！]<br>
(4) 如果一个节点是红色的，则它的子节点必须是黑色的。<br>
(5) 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。<br>
将插入的节点着色为红色，不会违背&quot;特性(5)&quot;！少违背一条特性，就意味着我们需要处理的情况越少。接下来，就要努力的让这棵树满足其它性质即可；满足了的话，它就又是一颗红黑树了。o(∩∩)o...哈哈</p>
<p><strong>第三步: 通过一系列的旋转或着色等操作，使之重新成为一颗红黑树。</strong><br>
第二步中，将插入节点着色为&quot;红色&quot;之后，不会违背&quot;特性(5)&quot;。那它到底会违背哪些特性呢？<br>
对于&quot;特性(1)&quot;，显然不会违背了。因为我们已经将它涂成红色了。<br>
对于&quot;特性(2)&quot;，显然也不会违背。在第一步中，我们是将红黑树当作二叉查找树，然后执行的插入操作。而根据二叉查找数的特点，插入操作不会改变根节点。所以，根节点仍然是黑色。<br>
对于&quot;特性(3)&quot;，显然不会违背了。这里的叶子节点是指的空叶子节点，插入非空节点并不会对它们造成影响。<br>
对于&quot;特性(4)&quot;，是有可能违背的！<br>
那接下来，想办法使之&quot;满足特性(4)&quot;，就可以将树重新构造成红黑树了。</p>
<p>下面看看代码到底是怎样实现这三步的。</p>
<p>添加操作的伪代码《算法导论》</p>
<pre><code class="language-swift">RB-INSERT(T, z)  
 y ← nil[T]                        // 新建节点“y”，将y设为空节点。
 x ← root[T]                       // 设“红黑树T”的根节点为“x”
 while x ≠ nil[T]                  // 找出要插入的节点“z”在二叉树T中的位置“y”
     do y ← x                      
        if key[z] &lt; key[x]  
           then x ← left[x]  
           else x ← right[x]  
 p[z] ← y                          // 设置 “z的父亲” 为 “y”
 if y = nil[T]                     
    then root[T] ← z               // 情况1：若y是空节点，则将z设为根
    else if key[z] &lt; key[y]        
            then left[y] ← z       // 情况2：若“z所包含的值” &lt; “y所包含的值”，则将z设为“y的左孩子”
            else right[y] ← z      // 情况3：(“z所包含的值” &gt;= “y所包含的值”)将z设为“y的右孩子” 
 left[z] ← nil[T]                  // z的左孩子设为空
 right[z] ← nil[T]                 // z的右孩子设为空。至此，已经完成将“节点z插入到二叉树”中了。
 color[z] ← RED                    // 将z着色为“红色”
 RB-INSERT-FIXUP(T, z)             // 通过RB-INSERT-FIXUP对红黑树的节点进行颜色修改以及旋转，让树T仍然是一颗红黑树
</code></pre>
<p>结合伪代码以及为代码上面的说明，先理解RB-INSERT。理解了RB-INSERT之后，我们接着对 RB-INSERT-FIXUP的伪代码进行说明。</p>
<p>添加修正操作的伪代码《算法导论》</p>
<pre><code class="language-php">RB-INSERT-FIXUP(T, z)
while color[p[z]] = RED                                                  // 若“当前节点(z)的父节点是红色”，则进行以下处理。
    do if p[z] = left[p[p[z]]]                                           // 若“z的父节点”是“z的祖父节点的左孩子”，则进行以下处理。
          then y ← right[p[p[z]]]                                        // 将y设置为“z的叔叔节点(z的祖父节点的右孩子)”
               if color[y] = RED                                         // Case 1条件：叔叔是红色
                  then color[p[z]] ← BLACK                    ▹ Case 1   //  (01) 将“父节点”设为黑色。
                       color[y] ← BLACK                       ▹ Case 1   //  (02) 将“叔叔节点”设为黑色。
                       color[p[p[z]]] ← RED                   ▹ Case 1   //  (03) 将“祖父节点”设为“红色”。
                       z ← p[p[z]]                            ▹ Case 1   //  (04) 将“祖父节点”设为“当前节点”(红色节点)
                  else if z = right[p[z]]                                // Case 2条件：叔叔是黑色，且当前节点是右孩子
                          then z ← p[z]                       ▹ Case 2   //  (01) 将“父节点”作为“新的当前节点”。
                               LEFT-ROTATE(T, z)              ▹ Case 2   //  (02) 以“新的当前节点”为支点进行左旋。
                          color[p[z]] ← BLACK                 ▹ Case 3   // Case 3条件：叔叔是黑色，且当前节点是左孩子。(01) 将“父节点”设为“黑色”。
                          color[p[p[z]]] ← RED                ▹ Case 3   //  (02) 将“祖父节点”设为“红色”。
                          RIGHT-ROTATE(T, p[p[z]])            ▹ Case 3   //  (03) 以“祖父节点”为支点进行右旋。
       else (same as then clause with &quot;right&quot; and &quot;left&quot; exchanged)      // 若“z的父节点”是“z的祖父节点的右孩子”，将上面的操作中“right”和“left”交换位置，然后依次执行。
color[root[T]] ← BLACK
</code></pre>
<p>根据被插入节点的父节点的情况，可以将&quot;当节点z被着色为红色节点，并插入二叉树&quot;划分为三种情况来处理。<br>
① 情况说明：被插入的节点是根节点。<br>
处理方法：直接把此节点涂为黑色。<br>
② 情况说明：被插入的节点的父节点是黑色。<br>
处理方法：什么也不需要做。节点被插入后，仍然是红黑树。<br>
③ 情况说明：被插入的节点的父节点是红色。<br>
处理方法：那么，该情况与红黑树的“特性(5)”相冲突。这种情况下，被插入节点是一定存在非空祖父节点的；进一步的讲，被插入节点也一定存在叔叔节点(即使叔叔节点为空，我们也视之为存在，空节点本身就是黑色节点)。理解这点之后，我们依据&quot;叔叔节点的情况&quot;，将这种情况进一步划分为3种情况(Case)。</p>
<p><img src="%E7%BA%A2%E9%BB%91%E6%A0%91%E4%B9%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3.assets/%E5%8F%94%E5%8F%94%E8%8A%82%E7%82%B9.png" alt="叔叔节点" loading="lazy"><br>
<img src="https://daxinqqq.github.io/post-images/1643276995602.png" alt="" loading="lazy"></p>
<p>上面三种情况(Case)处理问题的核心思路都是：将红色的节点移到根节点；然后，将根节点设为黑色。下面对它们详细进行介绍。</p>
<p><strong>1. (Case 1)叔叔是红色</strong></p>
<p><strong>1.1 现象说明</strong><br>
当前节点(即，被插入节点)的父节点是红色，且当前节点的祖父节点的另一个子节点（叔叔节点）也是红色。</p>
<p><strong>1.2 处理策略</strong><br>
(01) 将“父节点”设为黑色。<br>
(02) 将“叔叔节点”设为黑色。<br>
(03) 将“祖父节点”设为“红色”。<br>
(04) 将“祖父节点”设为“当前节点”(红色节点)；即，之后继续对“当前节点”进行操作。</p>
<p><strong>下面谈谈为什么要这样处理。</strong>(建议理解的时候，通过下面的图进行对比)<br>
“当前节点”和“父节点”都是红色，违背“特性(4)”。所以，将“父节点”设置“黑色”以解决这个问题。<br>
但是，将“父节点”由“红色”变成“黑色”之后，违背了“特性(5)”：因为，包含“父节点”的分支的黑色节点的总数增加了1。  解决这个问题的办法是：将“祖父节点”由“黑色”变成红色，同时，将“叔叔节点”由“红色”变成“黑色”。关于这里，说明几点：第一，为什么“祖父节点”之前是黑色？这个应该很容易想明白，因为在变换操作之前，该树是红黑树，“父节点”是红色，那么“祖父节点”一定是黑色。 第二，为什么将“祖父节点”由“黑色”变成红色，同时，将“叔叔节点”由“红色”变成“黑色”；能解决“包含‘父节点’的分支的黑色节点的总数增加了1”的问题。这个道理也很简单。“包含‘父节点’的分支的黑色节点的总数增加了1” 同时也意味着 “包含‘祖父节点’的分支的黑色节点的总数增加了1”，既然这样，我们通过将“祖父节点”由“黑色”变成“红色”以解决“包含‘祖父节点’的分支的黑色节点的总数增加了1”的问题； 但是，这样处理之后又会引起另一个问题“包含‘叔叔’节点的分支的黑色节点的总数减少了1”，现在我们已知“叔叔节点”是“红色”，将“叔叔节点”设为“黑色”就能解决这个问题。 所以，将“祖父节点”由“黑色”变成红色，同时，将“叔叔节点”由“红色”变成“黑色”；就解决了该问题。<br>
按照上面的步骤处理之后：当前节点、父节点、叔叔节点之间都不会违背红黑树特性，但祖父节点却不一定。若此时，祖父节点是根节点，直接将祖父节点设为“黑色”，那就完全解决这个问题了；若祖父节点不是根节点，那我们需要将“祖父节点”设为“新的当前节点”，接着对“新的当前节点”进行分析。</p>
<p><strong>1.3 示意图</strong></p>
<figure data-type="image" tabindex="7"><img src="https://daxinqqq.github.io/post-images/1643277006969.jpeg" alt="" loading="lazy"></figure>
<p><strong>2. (Case 2)叔叔是黑色，且当前节点是右孩子</strong></p>
<p><strong>2.1 现象说明</strong><br>
当前节点(即，被插入节点)的父节点是红色，叔叔节点是黑色，且当前节点是其父节点的右孩子</p>
<p><strong>2.2 处理策略</strong><br>
(01) 将“父节点”作为“新的当前节点”。<br>
(02) 以“新的当前节点”为支点进行左旋。</p>
<p><strong>下面谈谈为什么要这样处理。</strong>(建议理解的时候，通过下面的图进行对比)<br>
首先，将“父节点”作为“新的当前节点”；接着，以“新的当前节点”为支点进行左旋。 为了便于理解，我们先说明第(02)步，再说明第(01)步；为了便于说明，我们设置“父节点”的代号为F(Father)，“当前节点”的代号为S(Son)。<br>
为什么要“以F为支点进行左旋”呢？根据已知条件可知：S是F的右孩子。而之前我们说过，我们处理红黑树的核心思想：将红色的节点移到根节点；然后，将根节点设为黑色。既然是“将红色的节点移到根节点”，那就是说要不断的将破坏红黑树特性的红色节点上移(即向根方向移动)。 而S又是一个右孩子，因此，我们可以通过“左旋”来将S上移！<br>
按照上面的步骤(以F为支点进行左旋)处理之后：若S变成了根节点，那么直接将其设为“黑色”，就完全解决问题了；若S不是根节点，那我们需要执行步骤(01)，即“将F设为‘新的当前节点’”。那为什么不继续以S为新的当前节点继续处理，而需要以F为新的当前节点来进行处理呢？这是因为“左旋”之后，F变成了S的“子节点”，即S变成了F的父节点；而我们处理问题的时候，需要从下至上(由叶到根)方向进行处理；也就是说，必须先解决“孩子”的问题，再解决“父亲”的问题；所以，我们执行步骤(01)：将“父节点”作为“新的当前节点”。</p>
<p><strong>2.2 示意图</strong></p>
<figure data-type="image" tabindex="8"><img src="https://daxinqqq.github.io/post-images/1643277014986.jpeg" alt="" loading="lazy"></figure>
<p><strong>3. (Case 3)叔叔是黑色，且当前节点是左孩子</strong></p>
<p><strong>3.1 现象说明</strong><br>
当前节点(即，被插入节点)的父节点是红色，叔叔节点是黑色，且当前节点是其父节点的左孩子</p>
<p><strong>3.2 处理策略</strong><br>
(01) 将“父节点”设为“黑色”。<br>
(02) 将“祖父节点”设为“红色”。<br>
(03) 以“祖父节点”为支点进行右旋。</p>
<p><strong>下面谈谈为什么要这样处理。</strong>(建议理解的时候，通过下面的图进行对比)<br>
为了便于说明，我们设置“当前节点”为S(Original Son)，“兄弟节点”为B(Brother)，“叔叔节点”为U(Uncle)，“父节点”为F(Father)，祖父节点为G(Grand-Father)。<br>
S和F都是红色，违背了红黑树的“特性(4)”，我们可以将F由“红色”变为“黑色”，就解决了“违背‘特性(4)’”的问题；但却引起了其它问题：违背特性(5)，因为将F由红色改为黑色之后，所有经过F的分支的黑色节点的个数增加了1。那我们如何解决“所有经过F的分支的黑色节点的个数增加了1”的问题呢？ 我们可以通过“将G由黑色变成红色”，同时“以G为支点进行右旋”来解决。</p>
<p><strong>2.3 示意图</strong></p>
<figure data-type="image" tabindex="9"><img src="https://daxinqqq.github.io/post-images/1643277023087.jpeg" alt="" loading="lazy"></figure>
<p>提示：上面的进行Case 3处理之后，再将节点&quot;120&quot;当作当前节点，就变成了Case 2的情况。</p>
<h3 id="红黑树的基本操作三-删除"><strong>红黑树的基本操作(三) 删除</strong></h3>
<p>将红黑树内的某一个节点删除。需要执行的操作依次是：首先，将红黑树当作一颗二叉查找树，将该节点从二叉查找树中删除；然后，通过&quot;旋转和重新着色&quot;等一系列来修正该树，使之重新成为一棵红黑树。详细描述如下：</p>
<p><strong>第一步：将红黑树当作一颗二叉查找树，将节点删除。</strong><br>
这和&quot;删除常规二叉查找树中删除节点的方法是一样的&quot;。分3种情况：<br>
① 被删除节点没有儿子，即为叶节点。那么，直接将该节点删除就OK了。<br>
② 被删除节点只有一个儿子。那么，直接删除该节点，并用该节点的唯一子节点顶替它的位置。<br>
③ 被删除节点有两个儿子。那么，先找出它的后继节点；然后把“它的后继节点的内容”复制给“该节点的内容”；之后，删除“它的后继节点”。在这里，后继节点相当于替身，在将后继节点的内容复制给&quot;被删除节点&quot;之后，再将后继节点删除。这样就巧妙的将问题转换为&quot;删除后继节点&quot;的情况了，下面就考虑后继节点。 在&quot;被删除节点&quot;有两个非空子节点的情况下，它的后继节点不可能是双子非空。既然&quot;的后继节点&quot;不可能双子都非空，就意味着&quot;该节点的后继节点&quot;要么没有儿子，要么只有一个儿子。若没有儿子，则按&quot;情况① &quot;进行处理；若只有一个儿子，则按&quot;情况② &quot;进行处理。</p>
<p><strong>第二步：通过&quot;旋转和重新着色&quot;等一系列来修正该树，使之重新成为一棵红黑树。</strong><br>
因为&quot;第一步&quot;中删除节点之后，可能会违背红黑树的特性。所以需要通过&quot;旋转和重新着色&quot;来修正该树，使之重新成为一棵红黑树。</p>
<p>删除操作的伪代码《算法导论》</p>
<pre><code class="language-swift">RB-DELETE(T, z)
if left[z] = nil[T] or right[z] = nil[T]         
   then y ← z                                  // 若“z的左孩子” 或 “z的右孩子”为空，则将“z”赋值给 “y”；
   else y ← TREE-SUCCESSOR(z)                  // 否则，将“z的后继节点”赋值给 “y”。
if left[y] ≠ nil[T]
   then x ← left[y]                            // 若“y的左孩子” 不为空，则将“y的左孩子” 赋值给 “x”；
   else x ← right[y]                           // 否则，“y的右孩子” 赋值给 “x”。
p[x] ← p[y]                                    // 将“y的父节点” 设置为 “x的父节点”
if p[y] = nil[T]                               
   then root[T] ← x                            // 情况1：若“y的父节点” 为空，则设置“x” 为 “根节点”。
   else if y = left[p[y]]                    
           then left[p[y]] ← x                 // 情况2：若“y是它父节点的左孩子”，则设置“x” 为 “y的父节点的左孩子”
           else right[p[y]] ← x                // 情况3：若“y是它父节点的右孩子”，则设置“x” 为 “y的父节点的右孩子”
if y ≠ z                                    
   then key[z] ← key[y]                        // 若“y的值” 赋值给 “z”。注意：这里只拷贝z的值给y，而没有拷贝z的颜色！！！
        copy y's satellite data into z         
if color[y] = BLACK                            
   then RB-DELETE-FIXUP(T, x)                  // 若“y为黑节点”，则调用
return y
</code></pre>
<p>结合伪代码以及为代码上面的说明，先理解RB-DELETE。理解了RB-DELETE之后，接着对 RB-DELETE-FIXUP的伪代码进行说明</p>
<pre><code class="language-php">RB-DELETE-FIXUP(T, x)
while x ≠ root[T] and color[x] = BLACK  
    do if x = left[p[x]]      
          then w ← right[p[x]]                                             // 若 “x”是“它父节点的左孩子”，则设置 “w”为“x的叔叔”(即x为它父节点的右孩子)                                          
               if color[w] = RED                                           // Case 1: x是“黑+黑”节点，x的兄弟节点是红色。(此时x的父节点和x的兄弟节点的子节点都是黑节点)。
                  then color[w] ← BLACK                        ▹  Case 1   //   (01) 将x的兄弟节点设为“黑色”。
                       color[p[x]] ← RED                       ▹  Case 1   //   (02) 将x的父节点设为“红色”。
                       LEFT-ROTATE(T, p[x])                    ▹  Case 1   //   (03) 对x的父节点进行左旋。
                       w ← right[p[x]]                         ▹  Case 1   //   (04) 左旋后，重新设置x的兄弟节点。
               if color[left[w]] = BLACK and color[right[w]] = BLACK       // Case 2: x是“黑+黑”节点，x的兄弟节点是黑色，x的兄弟节点的两个孩子都是黑色。
                  then color[w] ← RED                          ▹  Case 2   //   (01) 将x的兄弟节点设为“红色”。
                       x ←  p[x]                               ▹  Case 2   //   (02) 设置“x的父节点”为“新的x节点”。
                  else if color[right[w]] = BLACK                          // Case 3: x是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的左孩子是红色，右孩子是黑色的。
                          then color[left[w]] ← BLACK          ▹  Case 3   //   (01) 将x兄弟节点的左孩子设为“黑色”。
                               color[w] ← RED                  ▹  Case 3   //   (02) 将x兄弟节点设为“红色”。
                               RIGHT-ROTATE(T, w)              ▹  Case 3   //   (03) 对x的兄弟节点进行右旋。
                               w ← right[p[x]]                 ▹  Case 3   //   (04) 右旋后，重新设置x的兄弟节点。
                        color[w] ← color[p[x]]                 ▹  Case 4   // Case 4: x是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的右孩子是红色的。(01) 将x父节点颜色 赋值给 x的兄弟节点。
                        color[p[x]] ← BLACK                    ▹  Case 4   //   (02) 将x父节点设为“黑色”。
                        color[right[w]] ← BLACK                ▹  Case 4   //   (03) 将x兄弟节点的右子节设为“黑色”。
                        LEFT-ROTATE(T, p[x])                   ▹  Case 4   //   (04) 对x的父节点进行左旋。
                        x ← root[T]                            ▹  Case 4   //   (05) 设置“x”为“根节点”。
       else (same as then clause with &quot;right&quot; and &quot;left&quot; exchanged)        // 若 “x”是“它父节点的右孩子”，将上面的操作中“right”和“left”交换位置，然后依次执行。
color[x] ← BLACK
</code></pre>
<p>下面对删除函数进行分析。在分析之前，我们再次温习一下红黑树的几个特性：<br>
(1) 每个节点或者是黑色，或者是红色。<br>
(2) 根节点是黑色。<br>
(3) 每个叶子节点是黑色。 [注意：这里叶子节点，是指为空的叶子节点！]<br>
(4) 如果一个节点是红色的，则它的子节点必须是黑色的。<br>
(5) 从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。</p>
<p>前面我们将&quot;删除红黑树中的节点&quot;大致分为两步，在第一步中&quot;将红黑树当作一颗二叉查找树，将节点删除&quot;后，可能违反&quot;特性(2)、(4)、(5)&quot;三个特性。第二步需要解决上面的三个问题，进而保持红黑树的全部特性。<br>
为了便于分析，我们假设&quot;x包含一个额外的黑色&quot;(x原本的颜色还存在)，这样就不会违反&quot;特性(5)&quot;。为什么呢？<br>
通过RB-DELETE算法，我们知道：删除节点y之后，x占据了原来节点y的位置。 既然删除y(y是黑色)，意味着减少一个黑色节点；那么，再在该位置上增加一个黑色即可。这样，当我们假设&quot;x包含一个额外的黑色&quot;，就正好弥补了&quot;删除y所丢失的黑色节点&quot;，也就不会违反&quot;特性(5)&quot;。 因此，假设&quot;x包含一个额外的黑色&quot;(x原本的颜色还存在)，这样就不会违反&quot;特性(5)&quot;。<br>
现在，x不仅包含它原本的颜色属性，x还包含一个额外的黑色。即x的颜色属性是&quot;红+黑&quot;或&quot;黑+黑&quot;，它违反了&quot;特性(1)&quot;。</p>
<p>现在，我们面临的问题，由解决&quot;违反了特性(2)、(4)、(5)三个特性&quot;转换成了&quot;解决违反特性(1)、(2)、(4)三个特性&quot;。RB-DELETE-FIXUP需要做的就是通过算法恢复红黑树的特性(1)、(2)、(4)。RB-DELETE-FIXUP的思想是：将x所包含的额外的黑色不断沿树上移(向根方向移动)，直到出现下面的姿态：<br>
a) x指向一个&quot;红+黑&quot;节点。此时，将x设为一个&quot;黑&quot;节点即可。<br>
b) x指向根。此时，将x设为一个&quot;黑&quot;节点即可。<br>
c) 非前面两种姿态。</p>
<p>将上面的姿态，可以概括为3种情况。<br>
① 情况说明：x是“红+黑”节点。<br>
处理方法：直接把x设为黑色，结束。此时红黑树性质全部恢复。<br>
② 情况说明：x是“黑+黑”节点，且x是根。<br>
处理方法：什么都不做，结束。此时红黑树性质全部恢复。<br>
③ 情况说明：x是“黑+黑”节点，且x不是根。<br>
处理方法：这种情况又可以划分为4种子情况。这4种子情况如下表所示：</p>
<p><img src="%E7%BA%A2%E9%BB%91%E6%A0%91%E4%B9%8B%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3.assets/%E7%BA%A2%E9%BB%91%E6%A0%91%E5%88%A0%E9%99%A4.png" alt="红黑树删除" loading="lazy"><br>
<img src="https://daxinqqq.github.io/post-images/1643277047719.png" alt="" loading="lazy"></p>
<p><strong>1. (Case 1)x是&quot;黑+黑&quot;节点，x的兄弟节点是红色</strong></p>
<p><strong>1.1 现象说明</strong><br>
x是&quot;黑+黑&quot;节点，x的兄弟节点是红色。(此时x的父节点和x的兄弟节点的子节点都是黑节点)。</p>
<p><strong>1.2 处理策略</strong><br>
(01) 将x的兄弟节点设为“黑色”。<br>
(02) 将x的父节点设为“红色”。<br>
(03) 对x的父节点进行左旋。<br>
(04) 左旋后，重新设置x的兄弟节点。</p>
<p><strong>下面谈谈为什么要这样处理。</strong>(建议理解的时候，通过下面的图进行对比)<br>
这样做的目的是将“Case 1”转换为“Case 2”、“Case 3”或“Case 4”，从而进行进一步的处理。对x的父节点进行左旋；左旋后，为了保持红黑树特性，就需要在左旋前“将x的兄弟节点设为黑色”，同时“将x的父节点设为红色”；左旋后，由于x的兄弟节点发生了变化，需要更新x的兄弟节点，从而进行后续处理。</p>
<p><strong>1.3 示意图</strong></p>
<figure data-type="image" tabindex="10"><img src="https://daxinqqq.github.io/post-images/1643277054504.jpeg" alt="" loading="lazy"></figure>
<p><strong>2. (Case 2) x是&quot;黑+黑&quot;节点，x的兄弟节点是黑色，x的兄弟节点的两个孩子都是黑色</strong></p>
<p><strong>2.1 现象说明</strong><br>
x是“黑+黑”节点，x的兄弟节点是黑色，x的兄弟节点的两个孩子都是黑色。</p>
<p><strong>2.2 处理策略</strong><br>
(01) 将x的兄弟节点设为“红色”。<br>
(02) 设置“x的父节点”为“新的x节点”。</p>
<p><strong>下面谈谈为什么要这样处理。</strong>(建议理解的时候，通过下面的图进行对比)<br>
这个情况的处理思想：是将“x中多余的一个黑色属性上移(往根方向移动)”。 x是“黑+黑”节点，我们将x由“黑+黑”节点 变成 “黑”节点，多余的一个“黑”属性移到x的父节点中，即x的父节点多出了一个黑属性(若x的父节点原先是“黑”，则此时变成了“黑+黑”；若x的父节点原先时“红”，则此时变成了“红+黑”)。 此时，需要注意的是：所有经过x的分支中黑节点个数没变化；但是，所有经过x的兄弟节点的分支中黑色节点的个数增加了1(因为x的父节点多了一个黑色属性)！为了解决这个问题，我们需要将“所有经过x的兄弟节点的分支中黑色节点的个数减1”即可，那么就可以通过“将x的兄弟节点由黑色变成红色”来实现。<br>
经过上面的步骤(将x的兄弟节点设为红色)，多余的一个颜色属性(黑色)已经跑到x的父节点中。我们需要将x的父节点设为“新的x节点”进行处理。若“新的x节点”是“黑+红”，直接将“新的x节点”设为黑色，即可完全解决该问题；若“新的x节点”是“黑+黑”，则需要对“新的x节点”进行进一步处理。</p>
<p><strong>2.3 示意图</strong></p>
<figure data-type="image" tabindex="11"><img src="https://daxinqqq.github.io/post-images/1643277060854.jpeg" alt="" loading="lazy"></figure>
<p><strong>3. (Case 3)x是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的左孩子是红色，右孩子是黑色的</strong></p>
<p><strong>3.1 现象说明</strong><br>
x是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的左孩子是红色，右孩子是黑色的。</p>
<p><strong>3.2 处理策略</strong><br>
(01) 将x兄弟节点的左孩子设为“黑色”。<br>
(02) 将x兄弟节点设为“红色”。<br>
(03) 对x的兄弟节点进行右旋。<br>
(04) 右旋后，重新设置x的兄弟节点。</p>
<p><strong>下面谈谈为什么要这样处理。</strong>(建议理解的时候，通过下面的图进行对比)<br>
我们处理“Case 3”的目的是为了将“Case 3”进行转换，转换成“Case 4”,从而进行进一步的处理。转换的方式是对x的兄弟节点进行右旋；为了保证右旋后，它仍然是红黑树，就需要在右旋前“将x的兄弟节点的左孩子设为黑色”，同时“将x的兄弟节点设为红色”；右旋后，由于x的兄弟节点发生了变化，需要更新x的兄弟节点，从而进行后续处理。</p>
<p><strong>3.3 示意图</strong></p>
<figure data-type="image" tabindex="12"><img src="https://daxinqqq.github.io/post-images/1643277066754.jpeg" alt="" loading="lazy"></figure>
<p><strong>4. (Case 4)x是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的右孩子是红色的，x的兄弟节点的左孩子任意颜色</strong></p>
<p><strong>4.1 现象说明</strong><br>
x是“黑+黑”节点，x的兄弟节点是黑色；x的兄弟节点的右孩子是红色的，x的兄弟节点的左孩子任意颜色。</p>
<p><strong>4.2 处理策略</strong><br>
(01) 将x父节点颜色 赋值给 x的兄弟节点。<br>
(02) 将x父节点设为“黑色”。<br>
(03) 将x兄弟节点的右子节设为“黑色”。<br>
(04) 对x的父节点进行左旋。<br>
(05) 设置“x”为“根节点”。</p>
<p><strong>下面谈谈为什么要这样处理。</strong>(建议理解的时候，通过下面的图进行对比)<br>
我们处理“Case 4”的目的是：去掉x中额外的黑色，将x变成单独的黑色。处理的方式是“：进行颜色修改，然后对x的父节点进行左旋。下面，我们来分析是如何实现的。<br>
为了便于说明，我们设置“当前节点”为S(Original Son)，“兄弟节点”为B(Brother)，“兄弟节点的左孩子”为BLS(Brother's Left Son)，“兄弟节点的右孩子”为BRS(Brother's Right Son)，“父节点”为F(Father)。<br>
我们要对F进行左旋。但在左旋前，我们需要调换F和B的颜色，并设置BRS为黑色。为什么需要这里处理呢？因为左旋后，F和BLS是父子关系，而我们已知BL是红色，如果F是红色，则违背了“特性(4)”；为了解决这一问题，我们将“F设置为黑色”。 但是，F设置为黑色之后，为了保证满足“特性(5)”，即为了保证左旋之后：<br>
第一，“同时经过根节点和S的分支的黑色节点个数不变”。<br>
若满足“第一”，只需要S丢弃它多余的颜色即可。因为S的颜色是“黑+黑”，而左旋后“同时经过根节点和S的分支的黑色节点个数”增加了1；现在，只需将S由“黑+黑”变成单独的“黑”节点，即可满足“第一”。<br>
第二，“同时经过根节点和BLS的分支的黑色节点数不变”。<br>
若满足“第二”，只需要将“F的原始颜色”赋值给B即可。之前，我们已经将“F设置为黑色”(即，将B的颜色&quot;黑色&quot;，赋值给了F)。至此，我们算是调换了F和B的颜色。<br>
第三，“同时经过根节点和BRS的分支的黑色节点数不变”。<br>
在“第二”已经满足的情况下，若要满足“第三”，只需要将BRS设置为“黑色”即可。<br>
经过，上面的处理之后。红黑树的特性全部得到的满足！接着，我们将x设为根节点，就可以跳出while循环(参考伪代码)；即完成了全部处理。</p>
<p>至此，我们就完成了Case 4的处理。理解Case 4的核心，是了解如何“去掉当前节点额外的黑色”。</p>
<p><strong>4.3 示意图</strong></p>
<figure data-type="image" tabindex="13"><img src="https://daxinqqq.github.io/post-images/1643277072970.jpeg" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[java 中的锁 -- 偏向锁、轻量级锁、自旋锁、重量级锁]]></title>
        <id>https://daxinqqq.github.io/post/java-zhong-de-suo-pian-xiang-suo-qing-liang-ji-suo-zi-xuan-suo-chong-liang-ji-suo/</id>
        <link href="https://daxinqqq.github.io/post/java-zhong-de-suo-pian-xiang-suo-qing-liang-ji-suo-zi-xuan-suo-chong-liang-ji-suo/">
        </link>
        <updated>2022-01-06T06:29:11.000Z</updated>
        <content type="html"><![CDATA[<p>之前做过一个测试，详情见这篇文章《多线程 +1操作的几种实现方式，及效率对比》，当时对这个测试结果很疑惑，反复执行过多次，发现结果是一样的:</p>
<ol>
<li>
<p>单线程下synchronized效率最高（当时感觉它的效率应该是最差才对）；</p>
</li>
<li>
<p>AtomicInteger效率最不稳定，不同并发情况下表现不一样：短时间低并发下，效率比synchronized高，有时甚至比LongAdder还高出一点，但是高并发下，性能还不如synchronized，不同情况下性能表现很不稳定；</p>
</li>
<li>
<p>LongAdder性能稳定，在各种并发情况下表现都不错，整体表现最好,短时间的低并发下比AtomicInteger性能差一点，长时间高并发下性能最高（可以让AtomicInteger下台了）；</p>
</li>
</ol>
<p>这篇文章我们就去揭秘，为什么会是这个测试结果！</p>
<h2 id="理解锁的基础知识">理解锁的基础知识</h2>
<p>如果想要透彻的理解java锁的来龙去脉，需要先了解以下基础知识。</p>
<h3 id="基础知识之一锁的类型">基础知识之一：锁的类型</h3>
<p>锁从宏观上分类，分为悲观锁与乐观锁。</p>
<h4 id="乐观锁">乐观锁</h4>
<p>乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新），如果失败则要重复读-比较-写的操作。</p>
<p>java中的乐观锁基本都是通过CAS操作实现的，CAS是一种更新的原子操作，比较当前值跟传入值是否一样，一样则更新，否则失败。</p>
<h4 id="悲观锁">悲观锁</h4>
<p>悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会block直到拿到锁。java中的悲观锁就是Synchronized,AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，才会转换为悲观锁，如RetreenLock。</p>
<h3 id="基础知识之二java线程阻塞的代价">基础知识之二：java线程阻塞的代价</h3>
<p>java的线程是映射到操作系统原生线程之上的，如果要阻塞或唤醒一个线程就需要操作系统介入，需要在户态与核心态之间切换，这种切换会消耗大量的系统资源，因为用户态与内核态都有各自专用的内存空间，专用的寄存器等，用户态切换至内核态需要传递给许多变量、参数给内核，内核也需要保护好用户态在切换时的一些寄存器值、变量等，以便内核态调用结束后切换回用户态继续工作。</p>
<ol>
<li>如果线程状态切换是一个高频操作时，这将会消耗很多CPU处理时间；</li>
<li>如果对于那些需要同步的简单的代码块，获取锁挂起操作消耗的时间比用户代码执行的时间还要长，这种同步策略显然非常糟糕的。</li>
</ol>
<p>synchronized会导致争用不到锁的线程进入阻塞状态，所以说它是java语言中一个重量级的同步操纵，被称为重量级锁，为了缓解上述性能问题，JVM从1.5开始，引入了轻量锁与偏向锁，默认启用了自旋锁，他们都属于乐观锁。</p>
<p><strong>明确java线程切换的代价，是理解java中各种锁的优缺点的基础之一。</strong></p>
<h3 id="基础知识之三markword">基础知识之三：markword</h3>
<p>在介绍java锁之前，先说下什么是markword，markword是java对象数据结构中的一部分，要详细了解java对象的结构可以点击这里,这里只做markword的详细介绍，因为对象的markword和java各种类型的锁密切相关；</p>
<p>markword数据的长度在32位和64位的虚拟机（未开启压缩指针）中分别为32bit和64bit，它的<strong>最后2bit是锁状态标志位</strong>，用来标记当前对象的状态，对象的所处的状态，决定了markword存储的内容，如下表所示:</p>
<table>
<thead>
<tr>
<th>状态</th>
<th>标志位</th>
<th>存储内容</th>
</tr>
</thead>
<tbody>
<tr>
<td>未锁定</td>
<td>01</td>
<td>对象哈希码、对象分代年龄</td>
</tr>
<tr>
<td>轻量级锁定</td>
<td>00</td>
<td>指向锁记录的指针</td>
</tr>
<tr>
<td>膨胀(重量级锁定)</td>
<td>10</td>
<td>执行重量级锁定的指针</td>
</tr>
<tr>
<td>GC标记</td>
<td>11</td>
<td>空(不需要记录信息)</td>
</tr>
<tr>
<td>可偏向</td>
<td>01</td>
<td>偏向线程ID、偏向时间戳、对象分代年龄</td>
</tr>
</tbody>
</table>
<p>32位虚拟机在不同状态下markword结构如下图所示：</p>
<figure data-type="image" tabindex="1"><img src="https://daxinqqq.github.io/post-images/1641450675863.png" alt="" loading="lazy"></figure>
<p>了解了markword结构，有助于后面了解java锁的加锁解锁过程；</p>
<h3 id="小结">小结</h3>
<p>前面提到了java的4种锁，他们分别是重量级锁、自旋锁、轻量级锁和偏向锁，<br>
不同的锁有不同特点，每种锁只有在其特定的场景下，才会有出色的表现，java中没有哪种锁能够在所有情况下都能有出色的效率，引入这么多锁的原因就是为了应对不同的情况；</p>
<p>前面讲到了重量级锁是悲观锁的一种，自旋锁、轻量级锁与偏向锁属于乐观锁，所以现在你就能够大致理解了他们的适用范围，但是具体如何使用这几种锁呢，就要看后面的具体分析他们的特性；</p>
<h2 id="java中的锁">java中的锁</h2>
<h3 id="自旋锁">自旋锁</h3>
<p>自旋锁原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持有锁的线程释放锁后即可立即获取锁，这样就<strong>避免用户线程和内核的切换的消耗</strong>。</p>
<p>但是线程自旋是需要消耗cup的，说白了就是让cup在做无用功，如果一直获取不到锁，那线程也不能一直占用cup自旋做无用功，所以需要设定一个自旋等待的最大时间。</p>
<p>如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁，就会导致其它争用锁的线程在最大等待时间内还是获取不到锁，这时争用线程会停止自旋进入阻塞状态。</p>
<h4 id="自旋锁的优缺点">自旋锁的优缺点</h4>
<p>自旋锁尽可能的减少线程的阻塞，这对于锁的竞争不激烈，且占用锁时间非常短的代码块来说性能能大幅度的提升，因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗，这些操作会导致线程发生两次上下文切换！</p>
<p>但是如果锁的竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁了，因为自旋锁在获取锁前一直都是占用cpu做无用功，占着XX不XX，同时有大量线程在竞争一个锁，会导致获取锁的时间很长，线程自旋的消耗大于线程阻塞挂起操作的消耗，其它需要cup的线程又不能获取到cpu，造成cpu的浪费。所以这种情况下我们要关闭自旋锁；</p>
<h4 id="自旋锁时间阈值">自旋锁时间阈值</h4>
<p>自旋锁的目的是为了占着CPU的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。因此自旋的周期选的额外重要！</p>
<p>JVM对于自旋周期的选择，jdk1.5这个限度是一定的写死的，在1.6引入了适应性自旋锁，适应性自旋锁意味着自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间，同时JVM还针对当前CPU的负荷情况做了较多的优化</p>
<ol>
<li>如果平均负载小于CPUs则一直自旋</li>
<li>如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞</li>
<li>如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞</li>
<li>如果CPU处于节电模式则停止自旋</li>
<li>自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差）</li>
<li>自旋时会适当放弃线程优先级之间的差异</li>
</ol>
<h4 id="自旋锁的开启">自旋锁的开启</h4>
<p>JDK1.6中-XX:+UseSpinning开启；<br>
-XX:PreBlockSpin=10 为自旋次数；<br>
JDK1.7后，去掉此参数，由jvm控制；</p>
<h3 id="重量级锁synchronized">重量级锁Synchronized</h3>
<h4 id="synchronized的作用">Synchronized的作用</h4>
<p>在JDK1.5之前都是使用synchronized关键字保证同步的，Synchronized的作用相信大家都已经非常熟悉了；</p>
<p>它可以把任意一个非NULL的对象当作锁。</p>
<ol>
<li>作用于方法时，锁住的是对象的实例(this)；</li>
<li>当作用于静态方法时，锁住的是Class实例，又因为Class的相关数据存储在永久带PermGen（jdk1.8则是metaspace），永久带是全局共享的，因此静态方法锁相当于类的一个全局锁，会锁所有调用该方法的线程；</li>
<li>synchronized作用于一个对象实例时，锁住的是所有以该对象为锁的代码块。</li>
</ol>
<h4 id="synchronized的实现">Synchronized的实现</h4>
<p>实现如下图所示；</p>
<figure data-type="image" tabindex="2"><img src="https://daxinqqq.github.io/post-images/1641450714393.png" alt="" loading="lazy"></figure>
<p>它有多个队列，当多个线程一起访问某个对象监视器的时候，对象监视器会将这些线程存储在不同的容器中。</p>
<ol>
<li>Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中；</li>
<li>Entry List：Contention List中那些有资格成为候选资源的线程被移动到Entry List中；</li>
<li>Wait Set：哪些调用wait方法被阻塞的线程被放置在这里；</li>
<li>OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为OnDeck；</li>
<li>Owner：当前已经获取到所资源的线程被称为Owner；</li>
<li>!Owner：当前释放锁的线程。</li>
</ol>
<p>JVM每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList会被大量的并发线程进行CAS访问，为了降低对尾部元素的竞争，JVM会将一部分线程移动到EntryList中作为候选竞争线程。Owner线程会在unlock时，将ContentionList中的部分线程迁移到EntryList中，并指定EntryList中的某个线程为OnDeck线程（一般是最先进去的那个线程）。Owner线程并不直接把锁传递给OnDeck线程，而是把锁竞争的权利交给OnDeck，OnDeck需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM中，也把这种选择行为称之为“竞争切换”。</p>
<p>OnDeck线程获取到锁资源后会变为Owner线程，而没有得到锁资源的仍然停留在EntryList中。如果Owner线程被wait方法阻塞，则转移到WaitSet队列中，直到某个时刻通过notify或者notifyAll唤醒，会重新进去EntryList中。</p>
<p>处于ContentionList、EntryList、WaitSet中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux内核下采用pthread_mutex_lock内核函数实现的）。</p>
<p><strong>Synchronized是非公平锁。</strong> Synchronized在线程进入ContentionList时，等待的线程会先尝试自旋获取锁，如果获取不到就进入ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占OnDeck线程的锁资源。</p>
<h3 id="偏向锁">偏向锁</h3>
<p>Java偏向锁(Biased Locking)是Java6引入的一项多线程优化。<br>
偏向锁，顾名思义，它会偏向于第一个访问锁的线程，如果在运行过程中，同步锁只有一个线程访问，不存在多线程争用的情况，则线程是不需要触发同步的，这种情况下，就会给线程加一个偏向锁。<br>
如果在运行过程中，遇到了其他线程抢占锁，则持有偏向锁的线程会被挂起，JVM会消除它身上的偏向锁，将锁恢复到标准的轻量级锁。</p>
<blockquote>
<p><em>它通过消除资源无竞争情况下的同步原语，进一步提高了程序的运行性能。</em></p>
</blockquote>
<h4 id="偏向锁的实现">偏向锁的实现</h4>
<h5 id="偏向锁获取过程">偏向锁获取过程：</h5>
<ol>
<li>访问Mark Word中偏向锁的标识是否设置成1，锁标志位是否为01，确认为可偏向状态。</li>
<li>如果为可偏向状态，则测试线程ID是否指向当前线程，如果是，进入步骤5，否则进入步骤3。</li>
<li>如果线程ID并未指向当前线程，则通过CAS操作竞争锁。如果竞争成功，则将Mark Word中线程ID设置为当前线程ID，然后执行5；如果竞争失败，执行4。</li>
<li>如果CAS获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the word）</li>
<li>执行同步代码。</li>
</ol>
<blockquote>
<p>注意：第四步中到达安全点safepoint会导致stop the word，时间很短。</p>
</blockquote>
<h5 id="偏向锁的释放">偏向锁的释放：</h5>
<p>偏向锁的撤销在上述第四步骤中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。</p>
<h4 id="偏向锁的适用场景">偏向锁的适用场景</h4>
<p>始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the word操作；<br>
在有锁的竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降，这种情况下应当禁用；</p>
<h5 id="查看停顿安全点停顿日志">查看停顿–安全点停顿日志</h5>
<p>要查看安全点停顿，可以打开安全点日志，通过设置JVM参数 -XX:+PrintGCApplicationStoppedTime 会打出系统停止的时间，添加-XX:+PrintSafepointStatistics -XX:PrintSafepointStatisticsCount=1 这两个参数会打印出详细信息，可以查看到使用偏向锁导致的停顿，时间非常短暂，但是争用严重的情况下，停顿次数也会非常多；</p>
<p>注意：安全点日志不能一直打开：<br>
\1. 安全点日志默认输出到stdout，一是stdout日志的整洁性，二是stdout所重定向的文件如果不在/dev/shm，可能被锁。<br>
\2. 对于一些很短的停顿，比如取消偏向锁，打印的消耗比停顿本身还大。<br>
\3. 安全点日志是在安全点内打印的，本身加大了安全点的停顿时间。</p>
<p>所以安全日志应该只在问题排查时打开。<br>
如果在生产系统上要打开，再再增加下面四个参数：<br>
-XX:+UnlockDiagnosticVMOptions -XX: -DisplayVMOutput -XX:+LogVMOutput -XX:LogFile=/dev/shm/vm.log<br>
打开Diagnostic（只是开放了更多的flag可选，不会主动激活某个flag），关掉输出VM日志到stdout，输出到独立文件,/dev/shm目录（内存文件系统）。</p>
<figure data-type="image" tabindex="3"><img src="https://daxinqqq.github.io/post-images/1641450751660.png" alt="" loading="lazy"></figure>
<p>此日志分三部分：<br>
第一部分是时间戳，VM Operation的类型<br>
第二部分是线程概况，被中括号括起来<br>
total: 安全点里的总线程数<br>
initially_running: 安全点开始时正在运行状态的线程数<br>
wait_to_block: 在VM Operation开始前需要等待其暂停的线程数</p>
<p>第三部分是到达安全点时的各个阶段以及执行操作所花的时间，其中最重要的是vmop</p>
<ul>
<li>spin: 等待线程响应safepoint号召的时间；</li>
<li>block: 暂停所有线程所用的时间；</li>
<li>sync: 等于 spin+block，这是从开始到进入安全点所耗的时间，可用于判断进入安全点耗时；</li>
<li>cleanup: 清理所用时间；</li>
<li>vmop: 真正执行VM Operation的时间。</li>
</ul>
<p>可见，那些很多但又很短的安全点，全都是RevokeBias， 高并发的应用会禁用掉偏向锁。</p>
<h4 id="jvm开启关闭偏向锁">jvm开启/关闭偏向锁</h4>
<ul>
<li>开启偏向锁：-XX:+UseBiasedLocking -XX:BiasedLockingStartupDelay=0</li>
<li>关闭偏向锁：-XX:-UseBiasedLocking</li>
</ul>
<h3 id="轻量级锁">轻量级锁</h3>
<p>轻量级锁是由偏向所升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁；<br>
轻量级锁的加锁过程：</p>
<ol>
<li>
<p>在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。这时候线程堆栈与对象头的状态如图：</p>
<figure data-type="image" tabindex="4"><img src="https://daxinqqq.github.io/post-images/1641450775376.jpeg" alt="" loading="lazy"></figure>
</li>
<li>
<p>拷贝对象头中的Mark Word复制到锁记录中；</p>
</li>
<li>
<p>拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock record里的owner指针指向object mark word。如果更新成功，则执行步骤4，否则执行步骤5。</p>
</li>
<li>
<p>如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态，这时候线程堆栈与对象头的状态如图所示。</p>
<figure data-type="image" tabindex="5"><img src="https://daxinqqq.github.io/post-images/1641450798760.jpeg" alt="" loading="lazy"></figure>
</li>
<li>
<p>如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，轻量级锁就要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。 而当前线程便尝试使用自旋来获取锁，自旋就是为了不让线程阻塞，而采用循环去获取锁的过程。</p>
</li>
</ol>
<h4 id="轻量级锁的释放">轻量级锁的释放</h4>
<p><strong>释放锁线程视角</strong>：由轻量锁切换到重量锁，是发生在轻量锁释放锁的期间，之前在获取锁的时候它拷贝了锁对象头的markword，在释放锁的时候如果它发现在它持有锁的期间有其他线程来尝试获取锁了，并且该线程对markword做了修改，两者比对发现不一致，则切换到重量锁。</p>
<p>因为重量级锁被修改了，所有display mark word和原来的markword不一样了。</p>
<p>怎么补救，就是进入mutex前，compare一下obj的markword状态。确认该markword是否被其他线程持有。</p>
<p>此时如果线程已经释放了markword，那么通过CAS后就可以直接进入线程，无需进入mutex，就这个作用。</p>
<p><strong>尝试获取锁线程视角</strong>：如果线程尝试获取锁的时候，轻量锁正被其他线程占有，那么它就会修改markword，修改重量级锁，表示该进入重量锁了。</p>
<p>还有一个注意点：等待轻量锁的线程不会阻塞，它会一直自旋等待锁，并如上所说修改markword。</p>
<p>这就是自旋锁，尝试获取锁的线程，在没有获得锁的时候，不被挂起，而转而去执行一个空循环，即自旋。在若干个自旋后，如果还没有获得锁，则才被挂起，获得锁，则执行代码。</p>
<h2 id="总结">总结</h2>
<figure data-type="image" tabindex="6"><img src="https://daxinqqq.github.io/post-images/1641450824461.jpeg" alt="" loading="lazy"></figure>
<p>synchronized的执行过程：</p>
<ol>
<li>
<p>检测Mark Word里面是不是当前线程的ID，如果是，表示当前线程处于偏向锁</p>
</li>
<li>
<p>如果不是，则使用CAS将当前线程的ID替换Mard Word，如果成功则表示当前线程获得偏向锁，置偏向标志位1</p>
</li>
<li>
<p>如果失败，则说明发生竞争，撤销偏向锁，进而升级为轻量级锁。</p>
</li>
<li>
<p>当前线程使用CAS将对象头的Mark Word替换为锁记录指针，如果成功，当前线程获得锁</p>
</li>
<li>
<p>如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。</p>
</li>
<li>
<p>如果自旋成功则依然处于轻量级状态。</p>
</li>
<li>
<p>如果自旋失败，则升级为重量级锁。</p>
</li>
</ol>
<p>上面几种锁都是JVM自己内部实现，当我们执行synchronized同步块的时候jvm会根据启用的锁和当前线程的争用情况，决定如何执行同步操作；</p>
<p>在所有的锁都启用的情况下线程进入临界区时会先去获取偏向锁，如果已经存在偏向锁了，则会尝试获取轻量级锁，启用自旋锁，如果自旋也没有获取到锁，则使用重量级锁，没有获取到锁的线程阻塞挂起，直到持有锁的线程执行完同步块唤醒他们；</p>
<p>偏向锁是在无锁争用的情况下使用的，也就是同步开在当前线程没有执行完之前，没有其它线程会执行该同步块，一旦有了第二个线程的争用，偏向锁就会升级为轻量级锁，如果轻量级锁自旋到达阈值后，没有获取到锁，就会升级为重量级锁；</p>
<p>如果线程争用激烈，那么应该禁用偏向锁。</p>
<h1 id="锁优化">锁优化</h1>
<p>以上介绍的锁不是我们代码中能够控制的，但是借鉴上面的思想，我们可以优化我们自己线程的加锁操作；</p>
<h2 id="减少锁的时间">减少锁的时间</h2>
<p>不需要同步执行的代码，能不放在同步快里面执行就不要放在同步快内，可以让锁尽快释放；</p>
<h2 id="减少锁的粒度">减少锁的粒度</h2>
<p>**它的思想是将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。**它的思想也是用空间来换时间；</p>
<p>java中很多数据结构都是采用这种方法提高并发操作的效率：</p>
<h3 id="concurrenthashmap">ConcurrentHashMap</h3>
<p>java中的ConcurrentHashMap在jdk1.8之前的版本，使用一个Segment 数组</p>
<pre><code class="language-java">Segment&lt; K,V &gt;[] segments1
</code></pre>
<p>Segment继承自ReenTrantLock，所以每个Segment就是个可重入锁，每个Segment 有一个HashEntry&lt; K,V &gt;数组用来存放数据，put操作时，先确定往哪个Segment放数据，只需要锁定这个Segment，执行put，其它的Segment不会被锁定；所以数组中有多少个Segment就允许同一时刻多少个线程存放数据，这样增加了并发能力。</p>
<h3 id="longadder">LongAdder</h3>
<p>LongAdder 实现思路也类似ConcurrentHashMap，LongAdder有一个根据当前并发状况动态改变的Cell数组，Cell对象里面有一个long类型的value用来存储值;<br>
开始没有并发争用的时候或者是cells数组正在初始化的时候，会使用cas来将值累加到成员变量的base上，在并发争用的情况下，LongAdder会初始化cells数组，在Cell数组中选定一个Cell加锁，数组有多少个cell，就允许同时有多少线程进行修改，最后将数组中每个Cell中的value相加，在加上base的值，就是最终的值；cell数组还能根据当前线程争用情况进行扩容，初始长度为2，每次扩容会增长一倍，直到扩容到大于等于cpu数量就不再扩容，这也就是为什么LongAdder比cas和AtomicInteger效率要高的原因，后面两者都是volatile+cas实现的，他们的竞争维度是1，LongAdder的竞争维度为“Cell个数+1”为什么要+1？因为它还有一个base，如果竞争不到锁还会尝试将数值加到base上；</p>
<h3 id="linkedblockingqueue">LinkedBlockingQueue</h3>
<p>LinkedBlockingQueue也体现了这样的思想，在队列头入队，在队列尾出队，入队和出队使用不同的锁，相对于LinkedBlockingArray只有一个锁效率要高；</p>
<p>*<strong>拆锁的粒度不能无限拆，最多可以将一个锁拆为当前cup数量个锁即可；*</strong></p>
<h2 id="锁粗化">锁粗化</h2>
<p>大部分情况下我们是要让锁的粒度最小化，锁的粗化则是要增大锁的粒度;<br>
在以下场景下需要粗化锁的粒度：<br>
假如有一个循环，循环内的操作需要加锁，我们应该把锁放到循环外面，否则每次进出循环，都进出一次临界区，效率是非常差的；</p>
<h2 id="使用读写锁">使用读写锁</h2>
<p>ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可以并发读，写操作使用写锁，只能单线程写；</p>
<h2 id="读写分离">读写分离</h2>
<p>CopyOnWriteArrayList 、CopyOnWriteArraySet<br>
CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。<br>
　CopyOnWrite并发容器用于读多写少的并发场景，因为，读的时候没有锁，但是对其进行更改的时候是会加锁的，否则会导致多个线程同时复制出多个副本，各自修改各自的；</p>
<h2 id="使用cas">使用cas</h2>
<p>如果需要同步的操作执行速度非常快，并且线程竞争并不激烈，这时候使用cas效率会更高，因为加锁会导致线程的上下文切换，如果上下文切换的耗时比同步操作本身更耗时，且线程对资源的竞争不激烈，使用volatiled+cas操作会是非常高效的选择；</p>
<h2 id="消除缓存行的伪共享">消除缓存行的伪共享</h2>
<p>除了我们在代码中使用的同步锁和jvm自己内置的同步锁外，还有一种隐藏的锁就是缓存行，它也被称为性能杀手。<br>
在多核cup的处理器中，每个cup都有自己独占的一级缓存、二级缓存，甚至还有一个共享的三级缓存，为了提高性能，cpu读写数据是以缓存行为最小单元读写的；32位的cpu缓存行为32字节，64位cup的缓存行为64字节，这就导致了一些问题。<br>
例如，多个不需要同步的变量因为存储在连续的32字节或64字节里面，当需要其中的一个变量时，就将它们作为一个缓存行一起加载到某个cup-1私有的缓存中（虽然只需要一个变量，但是cpu读取会以缓存行为最小单位，将其相邻的变量一起读入），被读入cpu缓存的变量相当于是对主内存变量的一个拷贝，也相当于变相的将在同一个缓存行中的几个变量加了一把锁，这个缓存行中任何一个变量发生了变化，当cup-2需要读取这个缓存行时，就需要先将cup-1中被改变了的整个缓存行更新回主存（即使其它变量没有更改），然后cup-2才能够读取，而cup-2可能需要更改这个缓存行的变量与cpu-1已经更改的缓存行中的变量是不一样的，所以这相当于给几个毫不相关的变量加了一把同步锁；<br>
为了防止伪共享，不同jdk版本实现方式是不一样的：</p>
<ol>
<li>
<p>在jdk1.7之前会 将需要独占缓存行的变量前后添加一组long类型的变量，依靠这些无意义的数组的填充做到一个变量自己独占一个缓存行；</p>
</li>
<li>
<p>在jdk1.7因为jvm会将这些没有用到的变量优化掉，所以采用继承一个声明了好多long变量的类的方式来实现；</p>
</li>
<li>
<p>在jdk1.8中通过添加sun.misc.Contended注解来解决这个问题，若要使该注解有效必须在jvm中添加以下参数：<br>
-XX:-RestrictContended</p>
</li>
</ol>
<p>sun.misc.Contended注解会在变量<strong>前面</strong>添加<strong>128字节</strong>的padding将当前变量与其他变量进行隔离；<br>
关于什么是缓存行，jdk是如何避免缓存行的，网上有非常多的解释，在这里就不再深入讲解了；</p>
<p>其它方式等待着大家一起补充</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[一整套Java线上故障排查技巧]]></title>
        <id>https://daxinqqq.github.io/post/yi-zheng-tao-java-xian-shang-gu-zhang-pai-cha-ji-qiao/</id>
        <link href="https://daxinqqq.github.io/post/yi-zheng-tao-java-xian-shang-gu-zhang-pai-cha-ji-qiao/">
        </link>
        <updated>2022-01-04T08:33:30.000Z</updated>
        <content type="html"><![CDATA[<p><strong>线上故障主要会包括 CPU、磁盘、内存以及网络问题，而大多数故障可能会包含不止一个层面的问题，所以进行排查时候尽量四个方面依次排查一遍。</strong></p>
<p>同时例如 jstack、jmap 等工具也是不囿于一个方面的问题的，基本上出问题就是 df、free、top 三连，然后依次 jstack、jmap 伺候，具体问题具体分析即可。</p>
<h3 id="cpu">CPU</h3>
<p>一般来讲我们首先会排查 CPU 方面的问题。CPU 异常往往还是比较好定位的。原因包括业务逻辑问题(死循环)、频繁 GC 以及上下文切换过多。</p>
<p>而最常见的往往是业务逻辑(或者框架逻辑)导致的，可以使用 jstack 来分析对应的堆栈情况。</p>
<p><strong>①使用 jstack 分析 CPU 问题</strong></p>
<p>我们先用 ps 命令找到对应进程的 pid（如果你有好几个目标进程，可以先用 top 看一下哪个占用比较高）。</p>
<p>接着用top -H -p pid来找到 CPU 使用率比较高的一些线程：</p>
<figure data-type="image" tabindex="1"><img src="https://daxinqqq.github.io/post-images/1641288338395.png" alt="" loading="lazy"></figure>
<p>然后将占用最高的 pid 转换为 16 进制 printf '%x\n' pid 得到 nid：</p>
<figure data-type="image" tabindex="2"><img src="https://daxinqqq.github.io/post-images/1641288379259.png" alt="" loading="lazy"></figure>
<p>接着直接在 jstack 中找到相应的堆栈信息 jstack pid |grep 'nid' -C5 –color：</p>
<figure data-type="image" tabindex="3"><img src="https://daxinqqq.github.io/post-images/1641288405011.png" alt="" loading="lazy"></figure>
<p>可以看到我们已经找到了 nid 为 0x42 的堆栈信息，接着只要仔细分析一番即可。</p>
<p>当然更常见的是我们对整个 jstack 文件进行分析，通常我们会比较关注 WAITING 和 TIMED_WAITING 的部分，BLOCKED 就不用说了。</p>
<p>我们可以使用命令 cat jstack.log | grep &quot;java.lang.Thread.State&quot; | sort -nr | uniq -c 来对 jstack 的状态有一个整体的把握，如果 WAITING 之类的特别多，那么多半是有问题啦。</p>
<figure data-type="image" tabindex="4"><img src="https://daxinqqq.github.io/post-images/1641288447244.png" alt="" loading="lazy"></figure>
<p><strong>②频繁 GC</strong></p>
<p>当然我们还是会使用 jstack 来分析问题，但有时候我们可以先确定下 GC 是不是太频繁。</p>
<p>使用 jstat -gc pid 1000 命令来对 GC 分代变化情况进行观察，1000 表示采样间隔（ms），S0C/S1C、S0U/S1U、EC/EU、OC/OU、MC/MU 分别代表两个 Survivor 区、Eden 区、老年代、元数据区的容量和使用量。</p>
<p>YGC/YGT、FGC/FGCT、GCT 则代表 YoungGc、FullGc 的耗时和次数以及总耗时。</p>
<p>如果看到 GC 比较频繁，再针对 GC 方面做进一步分析，具体可以参考一下 GC章节的描述。</p>
<figure data-type="image" tabindex="5"><img src="https://daxinqqq.github.io/post-images/1641288507015.png" alt="" loading="lazy"></figure>
<p><strong>③上下文切换</strong></p>
<p>针对频繁上下文问题，我们可以使用 vmstat 命令来进行查看：</p>
<figure data-type="image" tabindex="6"><img src="https://daxinqqq.github.io/post-images/1641288529713.png" alt="" loading="lazy"></figure>
<p>cs（context switch）一列则代表了上下文切换的次数。如果我们希望对特定的 pid 进行监控那么可以使用 pidstat -w pid 命令，cswch 和 nvcswch 表示自愿及非自愿切换。</p>
<figure data-type="image" tabindex="7"><img src="https://daxinqqq.github.io/post-images/1641288582244.png" alt="" loading="lazy"></figure>
<h3 id="磁盘">磁盘</h3>
<p>磁盘问题和 CPU 一样是属于比较基础的。首先是磁盘空间方面，我们直接使用 df -hl 来查看文件系统状态：</p>
<figure data-type="image" tabindex="8"><img src="https://daxinqqq.github.io/post-images/1641288624060.png" alt="" loading="lazy"></figure>
<p>更多时候，磁盘问题还是性能上的问题。我们可以通过 iostat iostat -d -k -x 来进行分析：</p>
<figure data-type="image" tabindex="9"><img src="https://daxinqqq.github.io/post-images/1641288662211.png" alt="" loading="lazy"></figure>
<p>最后一列 %util 可以看到每块磁盘写入的程度，而 rrqpm/s 以及 wrqm/s 分别表示读写速度，一般就能帮助定位到具体哪块磁盘出现问题了。</p>
<p>另外我们还需要知道是哪个进程在进行读写，一般来说开发自己心里有数，或者用 iotop 命令来进行定位文件读写的来源。</p>
<figure data-type="image" tabindex="10"><img src="https://daxinqqq.github.io/post-images/1641288700829.png" alt="" loading="lazy"></figure>
<p>不过这边拿到的是 tid，我们要转换成 pid，可以通过 readlink 来找到 pidreadlink -f /proc/*/task/tid/../..。</p>
<figure data-type="image" tabindex="11"><img src="https://daxinqqq.github.io/post-images/1641288744880.png" alt="" loading="lazy"></figure>
<p>找到 pid 之后就可以看这个进程具体的读写情况 cat /proc/pid/io：</p>
<figure data-type="image" tabindex="12"><img src="https://daxinqqq.github.io/post-images/1641288783733.png" alt="" loading="lazy"></figure>
<p>我们还可以通过 lsof 命令来确定具体的文件读写情况 lsof -p pid：</p>
<figure data-type="image" tabindex="13"><img src="https://daxinqqq.github.io/post-images/1641288822982.png" alt="" loading="lazy"></figure>
<h3 id="内存">内存</h3>
<p>内存问题排查起来相对比 CPU 麻烦一些，场景也比较多。主要包括 OOM、GC 问题和堆外内存。</p>
<p>一般来讲，我们会先用 free 命令先来检查一发内存的各种情况：</p>
<figure data-type="image" tabindex="14"><img src="https://daxinqqq.github.io/post-images/1641288864352.png" alt="" loading="lazy"></figure>
<p><strong>堆内内存</strong></p>
<p>内存问题大多还都是堆内内存问题。表象上主要分为 OOM 和 Stack Overflow。</p>
<p><strong>①OOM</strong></p>
<p>JMV 中的内存不足，OOM 大致可以分为以下几种：</p>
<p><strong>Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: unable to create new native thread</strong></p>
<p>这个意思是没有足够的内存空间给线程分配 Java 栈，基本上还是线程池代码写的有问题，比如说忘记 shutdown，所以说应该首先从代码层面来寻找问题，使用 jstack 或者 jmap。</p>
<p>如果一切都正常，JVM 方面可以通过指定 Xss 来减少单个 thread stack 的大小。</p>
<p>另外也可以在系统层面，可以通过修改 /etc/security/limits.confnofile 和 nproc 来增大 os 对线程的限制。</p>
<figure data-type="image" tabindex="15"><img src="https://daxinqqq.github.io/post-images/1641289064759.png" alt="" loading="lazy"></figure>
<p><strong>Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space</strong></p>
<p>这个意思是堆的内存占用已经达到 -Xmx 设置的最大值，应该是最常见的的 OOM 错误了。</p>
<p>解决思路仍然是先应该在代码中找，怀疑存在内存泄漏，通过 jstack 和 jmap 去定位问题。如果说一切都正常，才需要通过调整 Xmx 的值来扩大内存。</p>
<p><strong>Caused by: java.lang.OutOfMemoryError: Meta space</strong></p>
<p>这个意思是元数据区的内存占用已经达到 XX:MaxMetaspaceSize 设置的最大值，排查思路和上面的一致，参数方面可以通过 XX:MaxPermSize 来进行调整（这里就不说 1.8 以前的永久代了）。</p>
<p><strong>②Stack Overflow</strong></p>
<p>栈内存溢出，这个大家见到也比较多。</p>
<p><strong>Exception in thread &quot;main&quot; java.lang.StackOverflowError</strong></p>
<p>表示线程栈需要的内存大于 Xss 值，同样也是先进行排查，参数方面通过Xss来调整，但调整的太大可能又会引起 OOM。</p>
<p><strong>③使用 JMAP 定位代码内存泄漏</strong></p>
<p>上述关于 OOM 和 Stack Overflow 的代码排查方面，我们一般使用 JMAP jmap -dump:format=b,file=filename pid 来导出 dump 文件：</p>
<figure data-type="image" tabindex="16"><img src="https://daxinqqq.github.io/post-images/1641289649992.png" alt="" loading="lazy"></figure>
<p>通过 mat（Eclipse Memory Analysis Tools）导入 dump 文件进行分析，内存泄漏问题一般我们直接选 Leak Suspects 即可，mat 给出了内存泄漏的建议。</p>
<p>另外也可以选择 Top Consumers 来查看最大对象报告。和线程相关的问题可以选择 thread overview 进行分析。</p>
<p>除此之外就是选择 Histogram 类概览来自己慢慢分析，大家可以搜搜 mat 的相关教程。</p>
<figure data-type="image" tabindex="17"><img src="https://daxinqqq.github.io/post-images/1641289695960.png" alt="" loading="lazy"></figure>
<p>日常开发中，代码产生内存泄漏是比较常见的事，并且比较隐蔽，需要开发者更加关注细节。</p>
<p>比如说每次请求都 new 对象，导致大量重复创建对象；进行文件流操作但未正确关闭；手动不当触发 GC；ByteBuffer 缓存分配不合理等都会造成代码 OOM。</p>
<p>另一方面，我们可以在启动参数中指定 -XX:+HeapDumpOnOutOfMemoryError 来保存 OOM 时的 dump 文件。</p>
<p><strong>④GC 问题和线程</strong></p>
<p>GC 问题除了影响 CPU 也会影响内存，排查思路也是一致的。一般先使用 jstat 来查看分代变化情况，比如 youngGC 或者 FullGC 次数是不是太多呀；EU、OU 等指标增长是不是异常呀等。</p>
<p>线程的话太多而且不被及时 GC 也会引发 OOM，大部分就是之前说的 unable to create new native thread。</p>
<p>除了 jstack 细细分析 dump 文件外，我们一般先会看下总体线程，通过 pstreee -p pid |wc -l。</p>
<figure data-type="image" tabindex="18"><img src="https://daxinqqq.github.io/post-images/1641289740445.png" alt="" loading="lazy"></figure>
<p>或者直接通过查看 /proc/pid/task 的数量即为线程数量。</p>
<figure data-type="image" tabindex="19"><img src="https://daxinqqq.github.io/post-images/1641289780280.png" alt="" loading="lazy"></figure>
<p><strong>堆外内存</strong></p>
<p>如果碰到堆外内存溢出，那可真是太不幸了。首先堆外内存溢出表现就是物理常驻内存增长快，报错的话视使用方式都不确定。</p>
<p>如果由于使用 Netty 导致的，那错误日志里可能会出现 OutOfDirectMemoryError 错误，如果直接是 DirectByteBuffer，那会报 OutOfMemoryError: Direct buffer memory。</p>
<p>堆外内存溢出往往是和 NIO 的使用相关，一般我们先通过 pmap 来查看下进程占用的内存情况 pmap -x pid | sort -rn -k3 | head -30，这段意思是查看对应 pid 倒序前 30 大的内存段。</p>
<p>这边可以再一段时间后再跑一次命令看看内存增长情况，或者和正常机器比较可疑的内存段在哪里。</p>
<figure data-type="image" tabindex="20"><img src="https://daxinqqq.github.io/post-images/1641289821014.png" alt="" loading="lazy"></figure>
<p>我们如果确定有可疑的内存端，需要通过 gdb 来分析 gdb --batch --pid {pid} -ex &quot;dump memory filename.dump {内存起始地址} {内存起始地址+内存块大小}&quot;。</p>
<figure data-type="image" tabindex="21"><img src="https://daxinqqq.github.io/post-images/1641289861916.png" alt="" loading="lazy"></figure>
<p>获取 dump 文件后可用 heaxdump 进行查看 hexdump -C filename | less，不过大多数看到的都是二进制乱码。</p>
<p>NMT 是 Java7U40 引入的 HotSpot 新特性，配合 jcmd 命令我们就可以看到具体内存组成了。</p>
<p>需要在启动参数中加入 -XX:NativeMemoryTracking=summary 或者 -XX:NativeMemoryTracking=detail，会有略微性能损耗。</p>
<p>一般对于堆外内存缓慢增长直到爆炸的情况来说，可以先设一个基线 jcmd pid VM.native_memory baseline。</p>
<figure data-type="image" tabindex="22"><img src="https://daxinqqq.github.io/post-images/1641289917384.png" alt="" loading="lazy"></figure>
<p>然后等放一段时间后再去看看内存增长的情况，通过 jcmd pid VM.native_memory detail.diff(summary.diff) 做一下 summary 或者 detail 级别的 diff。</p>
<figure data-type="image" tabindex="23"><img src="https://daxinqqq.github.io/post-images/1641289958069.png" alt="" loading="lazy"></figure>
<figure data-type="image" tabindex="24"><img src="https://daxinqqq.github.io/post-images/1641290000036.png" alt="" loading="lazy"></figure>
<p>可以看到 jcmd 分析出来的内存十分详细，包括堆内、线程以及 GC（所以上述其他内存异常其实都可以用 nmt 来分析），这边堆外内存我们重点关注 Internal 的内存增长，如果增长十分明显的话那就是有问题了。</p>
<p>detail 级别的话还会有具体内存段的增长情况，如下图：</p>
<figure data-type="image" tabindex="25"><img src="https://daxinqqq.github.io/post-images/1641290040155.png" alt="" loading="lazy"></figure>
<p>此外在系统层面，我们还可以使用 strace 命令来监控内存分配 strace -f -e &quot;brk,mmap,munmap&quot; -p pid。</p>
<p>这边内存分配信息主要包括了 pid 和内存地址：</p>
<figure data-type="image" tabindex="26"><img src="https://daxinqqq.github.io/post-images/1641290081032.jpeg" alt="" loading="lazy"></figure>
<p>不过其实上面那些操作也很难定位到具体的问题点，关键还是要看错误日志栈，找到可疑的对象，搞清楚它的回收机制，然后去分析对应的对象。</p>
<p>比如 DirectByteBuffer 分配内存的话，是需要 Full GC 或者手动 system.gc 来进行回收的（所以最好不要使用-XX:+DisableExplicitGC）。</p>
<p>那么其实我们可以跟踪一下 DirectByteBuffer 对象的内存情况，通过 jmap -histo:live pid 手动触发 Full GC 来看看堆外内存有没有被回收。</p>
<p>如果被回收了，那么大概率是堆外内存本身分配的太小了，通过 -XX:MaxDirectMemorySize 进行调整。</p>
<p>如果没有什么变化，那就要使用 jmap 去分析那些不能被 GC 的对象，以及和 DirectByteBuffer 之间的引用关系了。</p>
<h3 id="gc-问题">GC 问题</h3>
<p>堆内内存泄漏总是和 GC 异常相伴。不过 GC 问题不只是和内存问题相关，还有可能引起 CPU 负载、网络问题等系列并发症，只是相对来说和内存联系紧密些，所以我们在此单独总结一下 GC 相关问题。</p>
<p>我们在 CPU 章介绍了使用 jstat 来获取当前 GC 分代变化信息。</p>
<p>而更多时候，我们是通过 GC 日志来排查问题的，在启动参数中加上 -verbose:gc，-XX:+PrintGCDetails，-XX:+PrintGCDateStamps，-XX:+PrintGCTimeStamps 来开启 GC 日志。</p>
<p>常见的 Young GC、Full GC 日志含义在此就不做赘述了。针对 GC 日志，我们就能大致推断出 youngGC 与 Full GC 是否过于频繁或者耗时过长，从而对症下药。</p>
<p>我们下面将对 G1 垃圾收集器来做分析，这边也建议大家使用 G1-XX:+UseG1GC。</p>
<p><strong>①youngGC 过频繁</strong></p>
<p>youngGC 频繁一般是短周期小对象较多，先考虑是不是 Eden 区/新生代设置的太小了，看能否通过调整 -Xmn、-XX:SurvivorRatio 等参数设置来解决问题。</p>
<p>如果参数正常，但是 youngGC 频率还是太高，就需要使用 Jmap 和 MAT 对 dump 文件进行进一步排查了。</p>
<p><strong>②youngGC 耗时过长</strong></p>
<p>耗时过长问题就要看 GC 日志里耗时耗在哪一块了。以 G1 日志为例，可以关注 Root Scanning、Object Copy、Ref Proc 等阶段。</p>
<p>Ref Proc 耗时长，就要注意引用相关的对象。Root Scanning 耗时长，就要注意线程数、跨代引用。</p>
<p>Object Copy 则需要关注对象生存周期。而且耗时分析它需要横向比较，就是和其他项目或者正常时间段的耗时比较。</p>
<p>比如说图中的 Root Scanning 和正常时间段比增长较多，那就是起的线程太多了。</p>
<figure data-type="image" tabindex="27"><img src="https://daxinqqq.github.io/post-images/1641290136784.png" alt="" loading="lazy"></figure>
<p>③<strong>触发 Full GC</strong></p>
<p>G1 中更多的还是 mixedGC，但 mixedGC 可以和 youngGC 思路一样去排查。</p>
<p>触发 Full GC 了一般都会有问题，G1 会退化使用 Serial 收集器来完成垃圾的清理工作，暂停时长达到秒级别，可以说是半跪了。</p>
<p>FullGC 的原因可能包括以下这些，以及参数调整方面的一些思路：</p>
<ul>
<li>
<p><strong>并发阶段失败：</strong> 在并发标记阶段，MixGC 之前老年代就被填满了，那么这时候 G1 就会放弃标记周期。</p>
<p>这种情况，可能就需要增加堆大小，或者调整并发标记线程数 -XX:ConcGCThreads。</p>
</li>
<li>
<p><strong>晋升失败：</strong> 在 GC 的时候没有足够的内存供存活/晋升对象使用，所以触发了 Full GC。</p>
<p>这时候可以通过 -XX:G1ReservePercent 来增加预留内存百分比，减少 -XX:InitiatingHeapOccupancyPercent 来提前启动标记，-XX:ConcGCThreads 来增加标记线程数也是可以的。</p>
</li>
<li>
<p><strong>大对象分配失败：</strong> 大对象找不到合适的 Region 空间进行分配，就会进行 Full GC，这种情况下可以增大内存或者增大 -XX:G1HeapRegionSize。</p>
</li>
<li>
<p><strong>程序主动执行 System.gc()：</strong> 不要随便写就对了。</p>
</li>
</ul>
<p>另外，我们可以在启动参数中配置 -XX:HeapDumpPath=/xxx/dump.hprof 来 dump fullGC 相关的文件，并通过 jinfo 来进行 GC 前后的 dump：</p>
<pre><code>jinfo -flag +HeapDumpBeforeFullGC pid 
jinfo -flag +HeapDumpAfterFullGC pid
</code></pre>
<p>这样得到两份 dump 文件，对比后主要关注被 GC 掉的问题对象来定位问题。</p>
<h3 id="网络">网络</h3>
<p>涉及到网络层面的问题一般都比较复杂，场景多，定位难，成为了大多数开发的噩梦，应该是最复杂的了。</p>
<p>这里会举一些例子，并从 TCP 层、应用层以及工具的使用等方面进行阐述。</p>
<p><strong>①超时</strong></p>
<p>超时错误大部分处在应用层面，所以这块着重理解概念。超时大体可以分为连接超时和读写超时，某些使用连接池的客户端框架还会存在获取连接超时和空闲连接清理超时。</p>
<p><strong>读写超时：</strong> readTimeout/writeTimeout，有些框架叫做 so_timeout 或者 socketTimeout，均指的是数据读写超时。</p>
<p>注意这边的超时大部分是指逻辑上的超时。soa 的超时指的也是读超时。读写超时一般都只针对客户端设置。</p>
<p><strong>连接超时：</strong> connectionTimeout，客户端通常指与服务端建立连接的最大时间。</p>
<p>服务端这边 connectionTimeout 就有些五花八门了，Jetty 中表示空闲连接清理时间，Tomcat 则表示连接维持的最大时间。</p>
<p><strong>其他：</strong> 包括连接获取超时 connectionAcquireTimeout 和空闲连接清理超时 idleConnectionTimeout。多用于使用连接池或队列的客户端或服务端框架。</p>
<p>我们在设置各种超时时间中，需要确认的是尽量保持客户端的超时小于服务端的超时，以保证连接正常结束。</p>
<p>在实际开发中，我们关心最多的应该是接口的读写超时了。如何设置合理的接口超时是一个问题。</p>
<p>如果接口超时设置的过长，那么有可能会过多地占用服务端的 TCP 连接。而如果接口设置的过短，那么接口超时就会非常频繁。</p>
<p>服务端接口明明 RT 降低，但客户端仍然一直超时又是另一个问题。这个问题其实很简单，客户端到服务端的链路包括网络传输、排队以及服务处理等，每一个环节都可能是耗时的原因。</p>
<p><strong>②TCP 队列溢出</strong></p>
<p>TCP 队列溢出是个相对底层的错误，它可能会造成超时、RST 等更表层的错误。因此错误也更隐蔽，所以我们单独说一说。</p>
<figure data-type="image" tabindex="28"><img src="https://daxinqqq.github.io/post-images/1641290190768.jpeg" alt="" loading="lazy"></figure>
<p>如上图所示，这里有两个队列：</p>
<ul>
<li><strong>syns queue（半连接队列）</strong></li>
<li><strong>accept queue（全连接队列）</strong></li>
</ul>
<p>三次握手，在 server 收到 client 的 syn 后，把消息放到 syns queue，回复 syn+ack 给 client，server 收到 client 的 ack。</p>
<p>如果这时 accept queue 没满，那就从 syns queue 拿出暂存的信息放入 accept queue 中，否则按 tcp_abort_on_overflow 指示的执行。</p>
<p>tcp_abort_on_overflow 0 表示如果三次握手第三步的时候 accept queue 满了那么 server 扔掉 client 发过来的 ack。</p>
<p>tcp_abort_on_overflow 1 则表示第三步的时候如果全连接队列满了，server 发送一个 RST 包给 client，表示废掉这个握手过程和这个连接，意味着日志里可能会有很多 connection reset/connection reset by peer。</p>
<p>那么在实际开发中，我们怎么能快速定位到 TCP 队列溢出呢？</p>
<p>netstat 命令，执行 netstat -s | egrep &quot;listen|LISTEN&quot;：</p>
<figure data-type="image" tabindex="29"><img src="https://daxinqqq.github.io/post-images/1641290389359.jpeg" alt="" loading="lazy"></figure>
<p>如上图所示，overflowed 表示全连接队列溢出的次数，sockets dropped 表示半连接队列溢出的次数。</p>
<p>ss 命令，执行 ss -lnt：</p>
<figure data-type="image" tabindex="30"><img src="https://daxinqqq.github.io/post-images/1641290466177.jpeg" alt="" loading="lazy"></figure>
<p>上面看到 Send-Q 表示第三列的 Listen 端口上的全连接队列最大为 5，第一列 Recv-Q 为全连接队列当前使用了多少。</p>
<p><strong>接着我们看看怎么设置全连接、半连接队列大小吧：</strong> 全连接队列的大小取决于 min（backlog，somaxconn）。</p>
<p>Backlog 是在 Socket 创建的时候传入的，somaxconn 是一个 OS 级别的系统参数。而半连接队列的大小取决于 max（64, /proc/sys/net/ipv4/tcp_max_syn_backlog）。</p>
<p>在日常开发中，我们往往使用 Servlet 容器作为服务端，所以我们有时候也需要关注容器的连接队列大小。</p>
<p>在 Tomcat 中 backlog 叫做 acceptCount，在 Jetty 里面则是 acceptQueueSize。</p>
<p><strong>③RST 异常</strong></p>
<p>RST 包表示连接重置，用于关闭一些无用的连接，通常表示异常关闭，区别于四次挥手。</p>
<p>在实际开发中，我们往往会看到 connection reset/connection reset by peer 错误，这种情况就是 RST 包导致的。</p>
<p><strong>端口不存在：</strong> 如果像不存在的端口发出建立连接 SYN 请求，那么服务端发现自己并没有这个端口则会直接返回一个 RST 报文，用于中断连接。</p>
<p><strong>主动代替 FIN 终止连接：</strong> 一般来说，正常的连接关闭都是需要通过 FIN 报文实现，然而我们也可以用 RST 报文来代替 FIN，表示直接终止连接。</p>
<p>实际开发中，可设置 SO_LINGER 数值来控制，这种往往是故意的，来跳过 TIMED_WAIT，提供交互效率，不闲就慎用。</p>
<p><strong>客户端或服务端有一边发生了异常，该方向对端发送 RST 以告知关闭连接：</strong> 我们上面讲的 TCP 队列溢出发送 RST 包其实也是属于这一种。</p>
<p>这种往往是由于某些原因，一方无法再能正常处理请求连接了（比如程序崩了，队列满了），从而告知另一方关闭连接。</p>
<p><strong>接收到的 TCP 报文不在已知的 TCP 连接内：</strong> 比如，一方机器由于网络实在太差 TCP 报文失踪了，另一方关闭了该连接，然后过了许久收到了之前失踪的 TCP 报文，但由于对应的 TCP 连接已不存在，那么会直接发一个 RST 包以便开启新的连接。</p>
<p>一方长期未收到另一方的确认报文，在一定时间或重传次数后发出 RST 报文</p>
<p>这种大多也和网络环境相关了，网络环境差可能会导致更多的 RST 报文。</p>
<p>之前说过 RST 报文多会导致程序报错，在一个已关闭的连接上读操作会报 connection reset，而在一个已关闭的连接上写操作则会报 connection reset by peer。</p>
<p>通常我们可能还会看到 broken pipe 错误，这是管道层面的错误，表示对已关闭的管道进行读写，往往是在收到 RST，报出 connection reset 错后继续读写数据报的错，这个在 glibc 源码注释中也有介绍。</p>
<p>我们在排查故障时候怎么确定有 RST 包的存在呢？当然是使用 tcpdump 命令进行抓包，并使用 wireshark 进行简单分析了。</p>
<p>tcpdump -i en0 tcp -w xxx.cap，en0 表示监听的网卡：</p>
<figure data-type="image" tabindex="31"><img src="https://daxinqqq.github.io/post-images/1641290633798.jpeg" alt="" loading="lazy"></figure>
<p>接下来我们通过 wireshark 打开抓到的包，可能就能看到如下图所示，红色的就表示 RST 包了。</p>
<figure data-type="image" tabindex="32"><img src="https://daxinqqq.github.io/post-images/1641290661781.jpeg" alt="" loading="lazy"></figure>
<p><strong>④TIME_WAIT 和 CLOSE_WAIT</strong></p>
<p>TIME_WAIT 和 CLOSE_WAIT 是啥意思相信大家都知道。</p>
<p>在线上时，我们可以直接用命令 netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'来查看 time-wait 和 close_wait 的数量。</p>
<p>用 ss 命令会更快 ss -ant | awk '{++S[$1]} END {for(a in S) print a, S[a]}'：</p>
<figure data-type="image" tabindex="33"><img src="https://daxinqqq.github.io/post-images/1641290690851.png" alt="" loading="lazy"></figure>
<p><strong>TIME_WAIT：</strong>  time_wait 的存在一是为了丢失的数据包被后面连接复用，二是为了在 2MSL 的时间范围内正常关闭连接。</p>
<p>它的存在其实会大大减少 RST 包的出现。过多的 time_wait 在短连接频繁的场景比较容易出现。</p>
<p>这种情况可以在服务端做一些内核参数调优：</p>
<pre><code>#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭
net.ipv4.tcp_tw_reuse = 1
#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭
net.ipv4.tcp_tw_recycle = 1
</code></pre>
<p>当然我们不要忘记在 NAT 环境下因为时间戳错乱导致数据包被拒绝的坑了，另外的办法就是改小 tcp_max_tw_buckets，超过这个数的 time_wait 都会被干掉，不过这也会导致报 time wait bucket table overflow 的错。</p>
<p><strong>CLOSE_WAIT：</strong> close_wait 往往都是因为应用程序写的有问题，没有在 ACK 后再次发起 FIN 报文。</p>
<p>close_wait 出现的概率甚至比 time_wait 要更高，后果也更严重。往往是由于某个地方阻塞住了，没有正常关闭连接，从而渐渐地消耗完所有的线程。</p>
<p>想要定位这类问题，最好是通过 jstack 来分析线程堆栈来排查问题，具体可参考上述章节。这里仅举一个例子。</p>
<p>开发同学说应用上线后 CLOSE_WAIT 就一直增多，直到挂掉为止，jstack 后找到比较可疑的堆栈是大部分线程都卡在了 countdownlatch.await 方法。</p>
<p>找开发同学了解后得知使用了多线程但是确没有 catch 异常，修改后发现异常仅仅是最简单的升级 SDK 后常出现的 class not found。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[对比Java标准NIO库，Netty如何实现更高性能？]]></title>
        <id>https://daxinqqq.github.io/post/dui-bi-java-biao-zhun-nio-ku-netty-ru-he-shi-xian-geng-gao-xing-neng/</id>
        <link href="https://daxinqqq.github.io/post/dui-bi-java-biao-zhun-nio-ku-netty-ru-he-shi-xian-geng-gao-xing-neng/">
        </link>
        <updated>2021-03-12T09:43:57.000Z</updated>
        <content type="html"><![CDATA[<p>从性能角度，Netty在基础的NIO等类库上进行了很多改进：</p>
<ul>
<li>更优雅的Reactor模式实现、灵活的线程模型、利用EventLoop等创新性的机制可以非常高效的管理成百上千的Channel。</li>
<li>充分利用了Java的Zero-Copy机制，并且从多角度降低内存分配和回收的开销。例如，使用池化的Direct Buffer等技术，提高IO性能的同时，减少了对象的创建和销毁；利用反射等技术直接操纵SelectionKey，使用数组而非Java容器等。</li>
<li>使用更多本地代码。例如，直接利用JNI调用OPEN SSL等方式，获得比Java内建SSL引擎更好的性能。</li>
<li>在通信协议，序列化等其他角度的优化。</li>
</ul>
<p>总结，Netty并没有Java核心类库那些强烈的通用性、跨平台等各种负担，针对性能等特定目标和Linux等特定环境，采取了一些极致的优化手段。</p>
<h2 id="扩展">扩展：</h2>
<h3 id="netty">Netty:</h3>
<p>​	Netty是一个异步的，基于事件Client/Server的网络框架，目标是提供一种简单、快速构建网络应用的方式，同时保证高吞吐量、低延时、高可靠性。</p>
<h3 id="与java-nio框架对比">与Java NIO框架对比：</h3>
<p>​	Java的标准类库，由于其基础性、通用性的定位，往往更关注于技术模型上的抽象，而不是从一线开发者角度思考。Java NIO的设计也是，开发者需要深入掌握线程、IO、网络等相关概念，学习、开发成本大。</p>
<p>​	Netty通过精巧设计的事件机制，将业务逻辑与无关技术逻辑进行隔离，并通过抽象，一定程度的填补了基础平台和业务开发的鸿沟，更有利于最佳实践的普及。</p>
<p>除了核心的事件机制，Netty还提供了其他的功能：</p>
<ul>
<li>从网络协议的角度，Netty除了支持传输层的UDP、TCP、SCTP协议，也支持HTTP(S)、WebSocket等多种应用层协议，并不是单一协议的API。</li>
<li>在应用中，需要将数据从Java对象转换成各种应用的数据格式，或者进行反向转换，Netty提供了一系列扩展的编解码框架，与应用场景无缝衔接，并且性能良好。</li>
<li>它扩展了Java NIO Buffer，提供了自己的ByteBuf实现，并且深度支持Direct Buffer等技术，甚至hack了Java内部对Direct Buffer的分配和销毁等。同时，Netty也提供了更加完善的Scatter/Gather机制实现。</li>
</ul>
<p>可以看到，Netty的能力范围大大超过了Java核心类库中的NIO等API，可以说是一个从应用视角出发的产物。</p>
<h3 id="netty入门代码浅析">Netty入门代码浅析：</h3>
<figure data-type="image" tabindex="1"><img src="https://daxinqqq.github.io/post-images/1615542476300.png" alt="" loading="lazy"></figure>
<ul>
<li><strong>ServerBootstrap</strong>：服务器端程序的入口，这是Netty为简化网络程序配置和关闭等生命周期管理，所引入的Bootstrapping机制。通常我们要做的创建Channel、绑定端口、注册Handler等，都可以通过这个统一的入口，以Fluent API等形式完成，简化了API使用。与之对应，Bootstrap则是客户端的入口。</li>
<li><strong>Channel</strong>：作为一个基于NIO的扩展框架，Channel和Selector等概念仍然是Netty的基础组件，但是针对应用开发需求，提供了相对易用的抽象。</li>
<li><strong>EventLoop</strong>：这是Netty处理事件的核心机制。例子使用了EventLoopGroup。在NIO中通常要做的几件事，如注册感兴趣的事件，调度相应的Handler等，都是EventLoop负责。</li>
<li><strong>ChannelFuture</strong>：这是Netty实现异步IO的基础之一，保证了同一个Channel操作的调用顺序。Netty扩展了Java标准的Future，提供了针对自己场景特有的Future定义。</li>
<li><strong>ChannelHandler</strong>：这是应用开发者<strong>放置业务逻辑的主要地方</strong>。</li>
<li><strong>ChannelPipeline</strong>：它是ChannelHandler链条的容器，每个Channel创建后，自动被分配到一个ChannelPipeline。在上面的代码中，通过ServerBootstrap注册了ChannelInitializer，并且实现了initChannel方法，在该方法中承担了向ChannelPipeline安装其他Channel的任务。</li>
</ul>
<p><strong>可以参考下图，忽略InBound/OutBound Handler的细节，理解这几个基本单元的操作流程和对应关系：</strong><br>
<img src="https://daxinqqq.github.io/post-images/1615542389163.png" alt="" loading="lazy"></p>
<p>对比Java标准NIO的代码，Netty提供了相对高层次的封装，减少了对Selector等细节的操作，而EventLoop、Pipeline等机制简化了编程模型，开发者不用担心并发等问题，一定程度上简化了应用代码的开发。并且这一切并没有以可靠性、可扩展性为代价，反而将其大幅度提高。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[MySQL数据库设计开发规范]]></title>
        <id>https://daxinqqq.github.io/post/mysql-shu-ju-ku-she-ji-kai-fa-gui-fan/</id>
        <link href="https://daxinqqq.github.io/post/mysql-shu-ju-ku-she-ji-kai-fa-gui-fan/">
        </link>
        <updated>2021-03-11T10:45:07.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1-规范背景与目的"><strong>1. 规范背景与目的</strong></h2>
<p>MySQL数据库与 Oracle、 SQL Server 等数据库相比，有其内核上的优势与劣势。我们在使用MySQL数据库的时候需要遵循一定规范，扬长避短。本规范旨在帮助或指导RD、QA、OP等技术人员做出适合线上业务的数据库设计。在数据库变更和处理流程、数据库表设计、SQL编写等方面予以规范，从而为公司业务系统稳定、健康地运行提供保障。</p>
<h2 id="2-设计规范"><strong>2. 设计规范</strong></h2>
<h3 id="21-数据库设计"><strong>2.1 数据库设计</strong></h3>
<p>以下所有规范会按照【高危】、【强制】、【建议】三个级别进行标注，遵守优先级从高到低。<br>
对于不满足【高危】和【强制】两个级别的设计，DBA会强制打回要求修改。</p>
<h3 id="211-库名"><strong>2.1.1 库名</strong></h3>
<ol>
<li>【强制】库的名称必须控制在32个字符以内，相关模块的表名与表名之间尽量提现join的关系，如user表和user_login表。</li>
<li>【强制】库的名称格式：业务系统名称_子系统名，同一模块使用的表名尽量使用统一前缀。</li>
<li>【强制】一般分库名称命名格式是库通配名_编号，编号从0开始递增，比如db_goods _001以时间进行分库的名称格式是&quot;库通配名_时间&quot;</li>
<li>【强制】创建数据库时必须显式指定字符集，并且字符集只能是utf8或者utf8mb4。创建数据库SQL举例：create database db1 default character set utf8;。</li>
</ol>
<h3 id="212-表结构"><strong>2.1.2 表结构</strong></h3>
<ol>
<li>【强制】表和列的名称必须控制在32个字符以内，表名只能使用字母、数字和下划线，一律小写。</li>
<li>【强制】表名要求模块名强相关，如师资系统采用&quot;sz&quot;作为前缀，渠道系统采用&quot;qd&quot;作为前缀等。</li>
<li>【强制】创建表时必须显式指定字符集为utf8或utf8mb4。</li>
<li>【强制】创建表时必须显式指定表存储引擎类型，如无特殊需求，一律为InnoDB。当需要使用除InnoDB/MyISAM/Memory以外的存储引擎时，必须通过DBA审核才能在生产环境中使用。因为Innodb表支持事务、行锁、宕机恢复、MVCC等关系型数据库重要特性，为业界使用最多的MySQL存储引擎。而这是其他大多数存储引擎不具备的，因此首推InnoDB。</li>
<li>【强制】建表必须有comment</li>
<li>【建议】建表时关于主键：(1)强制要求主键为id，类型为int或bigint，且为auto_increment(2)，建议设为其他字段如user_id，order_id建立unique key索引。因为如果设为主键且主键值为随机插入，则会导致innodb内部page分裂和大量随机I/O，性能下降。</li>
<li>【强制】核心表（如用户表，金钱相关的表）必须有行数据的创建时间字段create_time和最后更新时间字段update_time，便于查问题。</li>
<li>【建议】表中所有字段必须都是NOT NULL属性，业务可以根据需要定义DEFAULT值。因为使用NULL值会存在每一行都会占用额外存储空间、数据迁移容易出错、聚合函数计算结果偏差等问题。</li>
<li>【建议】建议对表里的blob、text等大字段，垂直拆分到其他表里，仅在需要读这些对象的时候才去select。</li>
<li>【建议】反范式设计：把经常需要join查询的字段，在其他表里冗余一份。如user_name属性在user_account，user_login_log等表里冗余一份，减少join查询。</li>
<li>【强制】中间表用于保留中间结果集，名称必须以tmp_开头。备份表用于备份或抓取源表快照，名称必须以bak_开头。中间表和备份表定期清理。</li>
<li>【强制】对于超过100W行的大表进行alter table，必须经过DBA审核，并在业务低峰期执行。因为alter table会产生表锁，期间阻塞对于该表的所有写入，对于业务可能会产生极大影响。</li>
</ol>
<h3 id="213-列数据类型优化"><strong>2.1.3 列数据类型优化</strong></h3>
<ol>
<li>【建议】表中的自增列（auto_increment属性），推荐使用bigint类型。因为无符号int存储范围为-2147483648~2147483647（大约21亿左右），溢出后会导致报错。</li>
<li>【建议】业务中选择性很少的状态status、类型type等字段推荐使用tinytint或者smallint类型节省存储空间。</li>
<li>【建议】业务中IP地址字段推荐使用int类型，不推荐用char(15)。因为int只占4字节，可以用如下函数相互转换，而char(15)占用至少15字节。一旦表数据行数到了1亿，那么要多用1.1G存储空间。 SQL：select inet_aton('192.168.2.12'); select inet_ntoa(3232236044); PHP: ip2long('192.168.2.12'); long2ip(3530427185);</li>
<li>【建议】不推荐使用enum，set。 因为它们浪费空间，且枚举值写死了，变更不方便。推荐使用tinyint或smallint。</li>
<li>【建议】不推荐使用blob，text等类型。它们都比较浪费硬盘和内存空间。在加载表数据时，会读取大字段到内存里从而浪费内存空间，影响系统性能。建议和PM、RD沟通，是否真的需要这么大字段。Innodb中当一行记录超过8098字节时，会将该记录中选取最长的一个字段将其768字节放在原始page里，该字段余下内容放在overflow-page里。不幸的是在compact行格式下，原始page和overflow-page都会加载。</li>
<li>【强制】存储金钱的字段，强制使用decimal类型。</li>
<li>【建议】文本数据尽量用varchar存储。因为varchar是变长存储，比char更省空间。MySQL server层规定一行所有文本最多存65535字节，因此在utf8字符集下最多存21844个字符，超过会自动转换为mediumtext字段。而text在utf8字符集下最多存21844个字符，mediumtext最多存2<sup>24/3个字符，longtext最多存2</sup>32个字符。一般建议用varchar类型，字符数不要超过2700。</li>
<li>【建议】时间类型尽量选取timestamp。因为datetime占用8字节，timestamp仅占用4字节，但是范围为1970-01-01 00:00:01到2038-01-01 00:00:00。更为高阶的方法，选用int来存储时间，使用SQL函数unix_timestamp()和from_unixtime()来进行转换。</li>
</ol>
<p>详细存储大小参加下图：<br>
<img src="https://cf.jd.com/download/attachments/222235418/worddav383b50cba105e8be3ca04216dba26386.png?version=1&amp;modificationDate=1571024595000&amp;api=v2" alt="img" loading="lazy"></p>
<h3 id="214-索引设计"><strong>2.1.4 索引设计</strong></h3>
<ol>
<li>【强制】InnoDB表必须主键为id int/bigint auto_increment,且主键值禁止被更新。</li>
<li>【建议】主键的名称以&quot;pk_&quot;开头，唯一键以&quot;uk_&quot;或&quot;uq_&quot;开头，普通索引以&quot;idx_&quot;开头，一律使用小写格式，以表名/字段的名称或缩写作为后缀。</li>
<li>【强制】InnoDB和MyISAM存储引擎表，索引类型必须为BTREE；MEMORY表可以根据需要选择HASH或者BTREE类型索引。</li>
<li>【强制】单个索引中每个索引记录的长度不能超过64KB。</li>
<li>【建议】单个表上的索引个数不能超过7个。</li>
<li>【建议】在建立索引时，多考虑建立联合索引，并把区分度最高的字段放在最前面。如列userid的区分度可由select count(distinct userid)计算出来。</li>
<li>【建议】在多表join的SQL里，保证被驱动表的连接列上有索引，这样join执行效率最高。</li>
<li>【建议】建表或加索引时，保证表里互相不存在冗余索引。对于MySQL来说，如果表里已经存在key(a,b)，则key(a)为冗余索引，需要删除。</li>
</ol>
<h3 id="215-分库分表-分区表"><strong>2.1.5 分库分表、分区表</strong></h3>
<ol>
<li>【强制】分区表的分区字段（partition-key）必须有索引，或者是组合索引的首列。</li>
<li>【强制】单个分区表中的分区（包括子分区）个数不能超过1024。</li>
<li>【强制】上线前RD或者DBA必须指定分区表的创建、清理策略。</li>
<li>【强制】访问分区表的SQL必须包含分区键。</li>
<li>【建议】单个分区文件不超过2G，总大小不超过50G。建议总分区数不超过20个。</li>
<li>【强制】对于分区表执行alter table操作，必须在业务低峰期执行。</li>
<li>【强制】采用分库策略的，库的数量不能超过1024</li>
<li>【强制】采用分表策略的，表的数量不能超过4096</li>
<li>【建议】单个分表不超过500W行，ibd文件大小不超过2G，这样才能让数据分布式变得性能更佳。</li>
<li>【建议】水平分表尽量用取模方式，日志、报表类数据建议采用日期进行分表。</li>
</ol>
<h3 id="216-字符集"><strong>2.1.6 字符集</strong></h3>
<ol>
<li>【强制】数据库本身库、表、列所有字符集必须保持一致，为utf8或utf8mb4。</li>
<li>【强制】前端程序字符集或者环境变量中的字符集，与数据库、表的字符集必须一致，统一为utf8。</li>
</ol>
<h3 id="217-程序层dao设计建议"><strong>2.1.7 程序层DAO设计建议</strong></h3>
<ol>
<li>【建议】新的代码不要用model，推荐使用手动拼SQL+绑定变量传入参数的方式。因为model虽然可以使用面向对象的方式操作db，但是其使用不当很容易造成生成的SQL非常复杂，且model层自己做的强制类型转换性能较差，最终导致数据库性能下降。</li>
<li>【建议】前端程序连接MySQL或者redis，必须要有连接超时和失败重连机制，且失败重试必须有间隔时间。</li>
<li>【建议】前端程序报错里尽量能够提示MySQL或redis原生态的报错信息，便于排查错误。</li>
<li>【建议】对于有连接池的前端程序，必须根据业务需要配置初始、最小、最大连接数，超时时间以及连接回收机制，否则会耗尽数据库连接资源，造成线上事故。</li>
<li>【建议】对于log或history类型的表，随时间增长容易越来越大，因此上线前RD或者DBA必须建立表数据清理或归档方案。</li>
<li>【建议】在应用程序设计阶段，RD必须考虑并规避数据库中主从延迟对于业务的影响。尽量避免从库短时延迟（20秒以内）对业务造成影响，建议强制一致性的读开启事务走主库，或更新后过一段时间再去读从库。</li>
<li>【建议】多个并发业务逻辑访问同一块数据（innodb表）时，会在数据库端产生行锁甚至表锁导致并发下降，因此建议更新类SQL尽量基于主键去更新。</li>
<li>【建议】业务逻辑之间加锁顺序尽量保持一致，否则会导致死锁。</li>
<li>【建议】对于单表读写比大于10:1的数据行或单个列，可以将热点数据放在缓存里（如mecache或redis），加快访问速度，降低MySQL压力。</li>
</ol>
<h3 id="218-一个规范的建表语句示例"><strong>2.1.8 一个规范的建表语句示例</strong></h3>
<p>一个较为规范的建表语句为：<br>
CREATE TABLE tt_test_user_1225_bk (<br>
<code>id</code> bigint(11) NOT NULL AUTO_INCREMENT COMMENT '主键id',<br>
<code>user_id</code> bigint(11) NOT NULL COMMENT '用户id',<br>
<code>username</code> varchar(45) NOT NULL COMMENT '真实姓名',<br>
<code>email</code> varchar(30) NOT NULL COMMENT '用户邮箱',<br>
<code>nickname</code> varchar(45) NOT NULL COMMENT '昵称',<br>
<code>avatar</code> int(11) NOT NULL COMMENT '头像',<br>
<code>birthday</code> date NOT NULL COMMENT '生日',<br>
<code>sex</code> tinyint(4) DEFAULT '0' COMMENT '性别',<br>
<code>short_introduce</code> varchar(150) DEFAULT NULL COMMENT '一句话介绍自己，最多50个汉字',<br>
<code>user_resume</code> varchar(300) NOT NULL COMMENT '用户提交的简历存放地址',<br>
<code>user_register_ip</code> int NOT NULL COMMENT '用户注册时的源ip',<br>
<code>create_time</code> timestamp NULL DEFAULT CURRENT_TIMESTAMP COMMENT '用户记录创建的时间',<br>
<code>update_time</code> timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '用户资料修改的时间',<br>
<code>user_review_status</code> tinyint NOT NULL COMMENT '用户资料审核状态，1为通过，2为审核中，3为未通过，4为还未提交审核',<br>
PRIMARY KEY (<code>id</code>),<br>
UNIQUE KEY <code>uq_idx_user_id</code> (<code>user_id</code>),<br>
KEY <code>idx_username</code>(<code>username</code>),<br>
KEY <code>idx_create_time</code>(<code>create_time</code>,<code>user_review_status</code>)<br>
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='网站用户基本信息';</p>
<h2 id="22-sql编写"><strong>2.2 SQL编写</strong></h2>
<h3 id="221-dml语句"><strong>2.2.1 DML语句</strong></h3>
<ol>
<li>【强制】SELECT语句必须指定具体字段名称，禁止写成*。因为select *会将不该读的数据也从MySQL里读出来，造成网卡压力。且表字段一旦更新，但model层没有来得及更新的话，系统会报错。</li>
<li>【强制】insert语句指定具体字段名称，不要写成insert into t1 values(…)，道理同上。</li>
<li>【建议】insert into…values(XX),(XX),(XX)…。这里XX的值不要超过5000个。值过多虽然上线很很快，但会引起主从同步延迟。</li>
<li>【建议】SELECT语句不要使用UNION，推荐使用UNION ALL，并且UNION子句个数限制在5个以内。因为union all不需要去重，节省数据库资源，提高性能。</li>
<li>【建议】in值列表限制在500以内。例如select… where userid in(….500个以内…)，这么做是为了减少底层扫描，减轻数据库压力从而加速查询。</li>
<li>【建议】事务里批量更新数据需要控制数量，进行必要的sleep，做到少量多次。</li>
<li>【强制】事务涉及的表必须全部是innodb表。否则一旦失败不会全部回滚，且易造成主从库同步中断。</li>
<li>【强制】写入和事务发往主库，只读SQL发往从库。</li>
<li>【强制】除静态表或小表（100行以内），DML语句必须有where条件，且使用索引查找。</li>
<li>【强制】生产环境禁止使用hint，如sql_no_cache，force index，ignore key，straight join等。因为hint是用来强制SQL按照某个执行计划来执行，但随着数据量变化我们无法保证自己当初的预判是正确的，因此我们要相信MySQL优化器！</li>
<li>【强制】where条件里等号左右字段类型必须一致，否则无法利用索引。</li>
<li>【建议】SELECT|UPDATE|DELETE|REPLACE要有WHERE子句，且WHERE子句的条件必需使用索引查找。</li>
<li>【强制】生产数据库中强烈不推荐大表上发生全表扫描，但对于100行以下的静态表可以全表扫描。查询数据量不要超过表行数的25%，否则不会利用索引。</li>
<li>【强制】WHERE 子句中禁止只使用全模糊的LIKE条件进行查找，必须有其他等值或范围查询条件，否则无法利用索引。</li>
<li>【建议】索引列不要使用函数或表达式，否则无法利用索引。如where length(name)='Admin'或where user_id+2=10023。</li>
<li>【建议】减少使用or语句，可将or语句优化为union，然后在各个where条件上建立索引。如where a=1 or b=2优化为where a=1… union …where b=2, key(a),key(b)(a和b为非主键列)。</li>
<li>【建议】分页查询，当limit起点较高时，可先用过滤条件进行过滤。如select a,b,c from t1 limit 10000,20;优化为: select a,b,c from t1 where id&gt;10000 limit 20;。</li>
</ol>
<h3 id="222-多表连接"><strong>2.2.2 多表连接</strong></h3>
<ol>
<li>【强制】禁止跨db的join语句。因为这样可以减少模块间耦合，为数据库拆分奠定坚实基础。</li>
<li>【强制】禁止在业务的更新类SQL语句中使用join，比如update t1 join t2…。</li>
<li>【建议】不建议使用子查询，建议将子查询SQL拆开结合程序多次查询，或使用join来代替子查询。</li>
<li>【强制】线上环境，禁止多表join。</li>
<li>【建议】多表连接查询推荐使用别名，且SELECT列表中要用别名引用字段，数据库.表格式，如select a from db1.table1 alias1 where …。</li>
<li>【建议】在多表join中，尽量选取结果集较小的表作为驱动表，来join其他表。</li>
</ol>
<h3 id="223-事务"><strong>2.2.3 事务</strong></h3>
<ol>
<li>【建议】事务中INSERT|UPDATE|DELETE|REPLACE语句操作的行数控制在2000以内，以及WHERE子句中IN列表的传参个数控制在500以内。</li>
<li>【建议】批量操作数据时，需要控制事务处理间隔时间，进行必要的sleep，一般建议值5-10秒。</li>
<li>【建议】对于有auto_increment属性字段的表的插入操作，并发需要控制在200以内。</li>
<li>【强制】程序设计必须考虑&quot;数据库事务隔离级别&quot;带来的影响，包括脏读、不可重复读和幻读。线上建议事务隔离级别为repeatable-read。</li>
<li>【建议】事务里包含SQL不超过5个（支付业务除外）。因为过长的事务会导致锁数据较久，MySQL内部缓存、连接消耗过多等雪崩问题。</li>
<li>【建议】事务里更新语句尽量基于主键或unique key，如update … where id=XX; 否则会产生 间隙锁，内部扩大锁定范围，导致系统性能下降，产生死锁。</li>
<li>【建议】尽量把一些典型外部调用移出事务，如调用webservice，访问文件存储等，从而避免事务过长。</li>
<li>【建议】对于MySQL主从延迟严格敏感的select语句，请开启事务强制访问主库。</li>
</ol>
<h3 id="224-排序和分组"><strong>2.2.4 排序和分组</strong></h3>
<ol>
<li>【建议】减少使用order by，和业务沟通能不排序就不排序，或将排序放到程序端去做。order by、group by、distinct这些语句较为耗费CPU，数据库的CPU资源是极其宝贵的。</li>
<li>【建议】order by、group by、distinct这些SQL尽量利用索引直接检索出排序好的数据。如where a=1 order by可以利用key(a,b)。</li>
<li>【建议】包含了order by、group by、distinct这些查询的语句，where条件过滤出来的结果集请保持在1000行以内，否则SQL会很慢。</li>
</ol>
<h3 id="225-线上禁止使用的sql语句"><strong>2.2.5 线上禁止使用的SQL语句</strong></h3>
<ol>
<li>【高危】禁用update|delete t1 … where a=XX limit XX; 这种带limit的更新语句。因为会导致主从不一致，导致数据错乱。建议加上order by PK。</li>
<li>【高危】禁止使用关联子查询，如update t1 set … where name in(select name from user where…);效率极其低下。</li>
<li>【强制】禁用procedure、function、trigger、views、event、外键约束。因为他们消耗数据库资源，降低数据库实例可扩展性。推荐都在程序端实现。</li>
<li>【强制】禁用insert into …on duplicate key update…在高并发环境下，会造成主从不一致。</li>
<li>【强制】禁止联表更新语句，如update t1,t2 where t1.id=t2.id…。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[常用的分布式ID设计方案]]></title>
        <id>https://daxinqqq.github.io/post/chang-yong-de-fen-bu-shi-id-she-ji-fang-an/</id>
        <link href="https://daxinqqq.github.io/post/chang-yong-de-fen-bu-shi-id-she-ji-fang-an/">
        </link>
        <updated>2021-03-11T10:10:16.000Z</updated>
        <content type="html"><![CDATA[<h2 id="分布式id定义">分布式ID定义：</h2>
<ul>
<li>全局唯一，区别于单点系统的唯一，全局要求分布式系统内唯一。</li>
<li>有序性，通常需要保证生成的ID是有序递增的。例如，数据库存储等场景中，有序ID便于确定数据位置，往往更加高效。</li>
</ul>
<h2 id="典型方案">典型方案：</h2>
<ul>
<li>
<p>基于数据库自增序列实现。好处是简单易用，但在扩展性和可靠性等方面存在局限。</p>
</li>
<li>
<p>基于Twitter早期开源的Snowflake的实现，以及相关改动方案。其结构定义：整体长度通常为64（1+41+10+12=64）位，适合使用long类型存储。</p>
<ul>
<li>
<p>头部是1位的正负标识位。</p>
</li>
<li>
<p>紧跟的高位标识是41位时间戳，通常使用System.currentTimeMillis()。</p>
</li>
<li>
<p>后面是10位的workerID，标准定义是5位数据中心+5位机器ID组成了机器编号，以区分不同的机器节点。</p>
</li>
<li>
<p>最后的12位就是单位毫秒内可生成的序列号的数目的理论极限。</p>
</li>
</ul>
</li>
<li>
<p>Redis、Zookeeper、MongoDB等中间件，也都有各种唯一ID解决方案。其中一些设计也可以算作是Snowflake方案的变种。例如，MongoDB的ObjectId提供了一个12 byte（96位）的ID定义，其中32位用于记录以秒为单位的事件，机器ID则为24位，16位用作进程ID，24位随机起始的计数序列。</p>
</li>
<li>
<p>国内大厂开源的一些分布式ID实现。</p>
</li>
</ul>
<p><strong>注：Snowflake并不受冬令时切换影响。Snowflake算法的Java实现，大都是依赖于System.currentTimeMillis()，这个函数会返回当前时间和1970年1月1号UTC事件相差的毫秒数，这个数值与夏/冬令时并没有关系。</strong></p>
<h2 id="扩展">扩展：</h2>
<h3 id="除了唯一和有序分布式系统通常还会额外希望分布式id保证">除了唯一和有序，分布式系统通常还会额外希望分布式ID保证：</h3>
<ul>
<li>有意义，包含更多信息，例如时间、业务等信息。这点和有序性存在一定关联，如果ID中包含时间，本身就可以保证一定的顺序。ID中包含额外信息，在分布式数据存储等场合中，有助于进一步优化数据访问的效率。</li>
<li>高可用性，这是分布式系统的必然要求，上面的方案中，有的是真正意义的分布式，有的还是传统主从的思路，这一点取决于我们业务对扩展性和性能等方面的要求。</li>
<li>紧凑性，ID的大小可能受到实际应用的制约，例如数据库存储往往对长ID不友好，太长的ID会降低Mysql等数据库索引的性能；编程语言在处理时也可能受数据类型长度限制。</li>
</ul>
<p>在具体生产环境中，还有可能提出对QPS等方面的具体要求，尤其是在国内一线大厂的业务规模下，更是需要考虑峰值业务场景的数量级层次要求。</p>
<h3 id="主流方案优缺点分析">主流方案优缺点分析：</h3>
<p>​	对于数据库自增方案，除了实现简单，它生成的ID还能够保证固定步长的递增，使用很方便。</p>
<p>​	但是，每获取一个ID就会触发数据库的写请求，是一个代价高昂的操作，构建高扩展性、高性能解决方案比较复杂，更不要说扩容等场景的难度了。同时，保证数据库高可用性也存在挑战，数据库可能发生宕机，即使采取主从热备等措施，也可能出现ID重复等问题。</p>
<p>​	实际大厂往往构建了多层的复合架构，例如美团公开的数据库方案Leaf-Segment，引入了起到缓存等作用的Leaf层，对数据库操作则是通过数据库中间件提供的批量操作，这样既能保证性能、扩展性，也能保证高可用。但是，这种方案对基础架构层面的要求很多，未必适合普通业务规模的需求。</p>
<p>​	与其相比，Snowflake的好处是算法简单，依赖也很少，生成的序列可预测，性能也非常好，Twetter的峰值超过10w/s。但是，它也存在一些不足：</p>
<ul>
<li>
<p>时钟偏斜问题（Clock Skew）：普通的计算机系统时钟并不能保证长久的一致性，可能发生时钟回拨等问题，这就会导致时间戳不准确，进而产生重复ID。针对这一点，Twetter曾经在文档中建议开启NTP。个人建议可以考虑同时将stepback设置为0，以禁止回调。从设计编码角度考虑，可以缓存历史时间戳，然后在序列生成之前进行校验，针对不合理情况进行重试、等待或报错。</p>
</li>
<li>
<p>序列号的可预测性是把双刃剑，虽然简化了一些工程问题，但很多场景不适合可预测的ID。很容易被黑客猜测并利用。</p>
</li>
<li>
<p>ID设计阶段需要谨慎考虑暴露出的信息。例如，Erlang版本的flake实现基于MAC地址计算WorkerID，在安全敏感的领域往往是不被允许的。</p>
</li>
<li>
<p>从理论上说，类似Snowflake的方案由于时间数据位数的限制，存在与2038年问题相似的理论极限。</p>
</li>
</ul>
]]></content>
    </entry>
</feed>